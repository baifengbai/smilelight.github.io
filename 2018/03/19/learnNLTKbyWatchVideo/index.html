<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  <title>learnNLTKbyWatchVideo | lightsmile&#39;s Blog</title>
  
  <meta name="keywords" content="Python,哲学,NLP,自然语言处理,lightsmile,李德方">
  
  
  <meta name="description" content="this is a description">
  

  <link rel="alternate" href="/atom.xml" title="lightsmile's Blog">

  <meta name="HandheldFriendly" content="True" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  
  
  <meta name="theme-color" content="#f24e32">
  
  <meta name="msapplication-TileColor" content="#f24e32">
  
  <meta name="msapplication-config" content="https://cdn.jsdelivr.net/gh/xaoxuu/assets@18.12.27/favicon/favicons/browserconfig.xml">
  
  
  <!-- link -->
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.6.3/css/all.min.css">

  
  
  <link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@18.12.27/favicon/favicon.ico"
   type="image/x-icon"
  
  
  
  >
  
  <link rel="icon" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@18.12.27/favicon/favicons/favicon-32x32.png"
   type="image/x-icon"
   sizes="32x32"
  
  
  >
  
  <link rel="apple-touch-icon" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@18.12.27/favicon/favicons/apple-touch-icon.png"
   type="image/png"
   sizes="180x180"
  
  
  >
  
  <link rel="mask-icon" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@18.12.27/favicon/favicons/safari-pinned-tab.svg"
  
  
  
  
   color="#f24e32">
  
  <link rel="manifest" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@18.12.27/favicon/favicons/site.webmanifest"
  
  
  
  
  >
  
  

  
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@1.0/css/style.css">
    
  

  



  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
    <!-- ga -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-131799461-1', 'www.iamlightsmile.com');
      ga('send', 'pageview');
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  
  
</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="loading-bar-wrapper">
  <div id="loading-bar" class="pure"></div>
</div>

    <script>setLoadingBarProgress(20)</script>
    <header class="l_header pure">
	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" href='/' >
        
          lightsmile's Blog
        
      </a>
			<div class='menu'>
				<ul class='h-list'>
          
  					
  						<li>
								<a id="https:www.iamlightsmile.com"
								 class="nav flat-box" href="https://www.iamlightsmile.com/">
									<i class='fas fa-home fa-fw'></i>&nbsp;主页
								</a>
							</li>
      			
  						<li>
								<a id="home"
								 class="nav flat-box" href="/">
									<i class='fas fa-rss fa-fw'></i>&nbsp;博客
								</a>
							</li>
      			
  						<li>
								<a id="archives"
								 class="nav flat-box" href="/archives/">
									<i class='fas fa-archive fa-fw'></i>&nbsp;归档
								</a>
							</li>
      			
  						<li>
								<a id="friends"
								 class="nav flat-box" href="/friends/">
									<i class='fas fa-users fa-fw'></i>&nbsp;朋友
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="搜索" />
						<span class="icon"><i class="fas fa-search fa-fw"></i></span>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" href='javascript:void(0)'></a></li>
				<li class='s-toc'><a class="flat-btn fas fa-list fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu">
      <ul>
          
              
                  <li>
										<a id="https:www.iamlightsmile.com" class="nav flat-box" href="https://www.iamlightsmile.com/">
											<i class='fas fa-home fa-fw'></i>&nbsp;主页
										</a>
                  </li>
              
                  <li>
										<a id="home" class="nav flat-box" href="/">
											<i class='fas fa-rss fa-fw'></i>&nbsp;博客
										</a>
                  </li>
              
                  <li>
										<a id="archives" class="nav flat-box" href="/archives/">
											<i class='fas fa-archive fa-fw'></i>&nbsp;归档
										</a>
                  </li>
              
                  <li>
										<a id="friends" class="nav flat-box" href="/friends/">
											<i class='fas fa-users fa-fw'></i>&nbsp;朋友
										</a>
                  </li>
              
       
      </ul>
		</nav>
    </header>
	</aside>

    <script>setLoadingBarProgress(40);</script>
    <div class="l_body">
    <div class='container clearfix'>
        <div class='l_main'>
            <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
  
<section class='meta'>
  
  <div class="meta" id="header-meta">
    
      
          <h1 class="title">learnNLTKbyWatchVideo</h1>
      
    

    
      <time class="metatag time">
        <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;2018-03-19
      </time>
    

    
      
    
    <div class='metatag cats'>
        <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;<a class="categories" href="/categories/计算机/">计算机</a>
    </div>


    

    
      
        <div class="metatag browse busuanzi"><i class="fas fa-eye fa-fw" aria-hidden="true"></i>
          &nbsp;<span id="busuanzi_value_page_pv"><i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span>
        </div>
      
    

    

  </div>
</section>

    <section class="article typo">
      <div class="article-entry" itemprop="articleBody">
        <h1 id="The-following-is-learning-from-the-video-NLTK-with-Python-3-for-Natural-Language-Processing"><a href="#The-following-is-learning-from-the-video-NLTK-with-Python-3-for-Natural-Language-Processing" class="headerlink" title="The following is learning from the video:NLTK with Python 3 for Natural Language Processing."></a>The following is learning from the video:NLTK with Python 3 for Natural Language Processing.</h1><p>You can watch the videos in YouTube,iliibili and the author’s website: <a href="http://pythonprogramming.net" target="_blank" rel="noopener">pythonprogramming.net</a></p>
<p>I use jupyter notebook to write and run the python code,the python version is 3.4.4.</p>
<p>Frist,we need to import the <code>nltk</code> module to use it</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> sent_tokenize,word_tokenize</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">r"hello,how are you! I am lightsmile. My github link is www.github.com/smilelight. My persoanl website is www.iamlightsmile.com"</span></span><br></pre></td></tr></table></figure>
<h3 id="1-Tokenizing-words-and-entences-分词和分句"><a href="#1-Tokenizing-words-and-entences-分词和分句" class="headerlink" title="1. Tokenizing words and entences(分词和分句)"></a>1. Tokenizing words and entences(分词和分句)</h3><p>use the <code>sent_tokenize</code> method to tokenize the texts to sentenses(分句)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sent_tokenize(text)</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;hello,how are you!&apos;,
 &apos;I am lightsmile.&apos;,
 &apos;My github link is www.github.com/smilelight.&apos;,
 &apos;My persoanl website is www.iamlightsmile.com&apos;]
</code></pre><p>use the <code>word_tokenize</code> method to tokenize the texts to words(分词)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">word_tokenize(text)</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;hello&apos;,
 &apos;,&apos;,
 &apos;how&apos;,
 &apos;are&apos;,
 &apos;you&apos;,
 &apos;!&apos;,
 &apos;I&apos;,
 &apos;am&apos;,
 &apos;lightsmile&apos;,
 &apos;.&apos;,
 &apos;My&apos;,
 &apos;github&apos;,
 &apos;link&apos;,
 &apos;is&apos;,
 &apos;www.github.com/smilelight&apos;,
 &apos;.&apos;,
 &apos;My&apos;,
 &apos;persoanl&apos;,
 &apos;website&apos;,
 &apos;is&apos;,
 &apos;www.iamlightsmile.com&apos;]
</code></pre><h3 id="2-Stop-Words-停用词"><a href="#2-Stop-Words-停用词" class="headerlink" title="2. Stop Words(停用词)"></a>2. Stop Words(停用词)</h3><p>Then,import the <code>stopwords</code>(停用词) from the <code>nltk.corpus</code> module</p>
<p>The stopwords are the words which are used commonly in the daliy life but usefulless for we to analyze the texts,so we need to remove them from the texts before we do the next steps.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">example_sentense = <span class="string">"This is an example showing off stop word filtration"</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">filter_sentense = [w <span class="keyword">for</span> w <span class="keyword">in</span> word_tokenize(example_sentense) <span class="keyword">if</span>  w <span class="keyword">not</span> <span class="keyword">in</span> stopwords.words(<span class="string">'english'</span>)]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">filter_sentense</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;This&apos;, &apos;example&apos;, &apos;showing&apos;, &apos;stop&apos;, &apos;word&apos;, &apos;filtration&apos;]
</code></pre><h3 id="3-Stemming-提取词干"><a href="#3-Stemming-提取词干" class="headerlink" title="3. Stemming(提取词干)"></a>3. Stemming(提取词干)</h3><p>Use <code>PorterStemmer()</code> to get the stems of words(提取词干)</p>
<p>In some situations there are different expressions which have the same meanings.For example,the words:good,better,well have the similar meanings in the most situations.So,on the purpose to simplify the texts,we can get the stems of words in the texts. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> PorterStemmer</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ps = PorterStemmer()</span><br><span class="line">example_words = [<span class="string">"python"</span>,<span class="string">"pythoner"</span>,<span class="string">"pythoning"</span>,<span class="string">"pythoned"</span>,<span class="string">"pythonly"</span>]</span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> example_words:</span><br><span class="line">    print(ps.stem(w))</span><br></pre></td></tr></table></figure>
<pre><code>python
python
python
python
pythonli
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">new_text = <span class="string">"It is very important to be pythonly while you are pythoning with python. All pythoners have pythoned poorly at least once."</span></span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> word_tokenize(new_text):</span><br><span class="line">    print(ps.stem(w))</span><br></pre></td></tr></table></figure>
<pre><code>It
is
veri
import
to
be
pythonli
while
you
are
python
with
python
.
all
python
have
python
poorli
at
least
onc
.
</code></pre><h3 id="4-Part-of-speech-tagging-词性标注"><a href="#4-Part-of-speech-tagging-词性标注" class="headerlink" title="4. Part of speech tagging(词性标注)"></a>4. Part of speech tagging(词性标注)</h3><p>Use pos_tag method to do part of speech tagging(词性标注)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tagged = nltk.pos_tag(word_tokenize(new_text))</span><br><span class="line">print(tagged)</span><br></pre></td></tr></table></figure>
<pre><code>[(&apos;It&apos;, &apos;PRP&apos;), (&apos;is&apos;, &apos;VBZ&apos;), (&apos;very&apos;, &apos;RB&apos;), (&apos;important&apos;, &apos;JJ&apos;), (&apos;to&apos;, &apos;TO&apos;), (&apos;be&apos;, &apos;VB&apos;), (&apos;pythonly&apos;, &apos;RB&apos;), (&apos;while&apos;, &apos;IN&apos;), (&apos;you&apos;, &apos;PRP&apos;), (&apos;are&apos;, &apos;VBP&apos;), (&apos;pythoning&apos;, &apos;VBG&apos;), (&apos;with&apos;, &apos;IN&apos;), (&apos;python&apos;, &apos;NN&apos;), (&apos;.&apos;, &apos;.&apos;), (&apos;All&apos;, &apos;DT&apos;), (&apos;pythoners&apos;, &apos;NNS&apos;), (&apos;have&apos;, &apos;VBP&apos;), (&apos;pythoned&apos;, &apos;VBN&apos;), (&apos;poorly&apos;, &apos;RB&apos;), (&apos;at&apos;, &apos;IN&apos;), (&apos;least&apos;, &apos;JJS&apos;), (&apos;once&apos;, &apos;RB&apos;), (&apos;.&apos;, &apos;.&apos;)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[w <span class="keyword">for</span> w,t <span class="keyword">in</span> tagged <span class="keyword">if</span> t == <span class="string">'RB'</span> ]</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;very&apos;, &apos;pythonly&apos;, &apos;poorly&apos;, &apos;once&apos;]
</code></pre><h3 id="5-Chunking-短语识别"><a href="#5-Chunking-短语识别" class="headerlink" title="5. Chunking(短语识别)"></a>5. Chunking(短语识别)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chunkGram = <span class="string">r"""Chunk: &#123;&lt;RB.?&gt;*&lt;VB.?&gt;*&lt;NNP&gt;*&lt;NN&gt;&#125;"""</span></span><br><span class="line">chunkParser = nltk.RegexpParser(chunkGram)</span><br><span class="line">chunked = chunkParser.parse(tagged)</span><br><span class="line">print(chunked)</span><br></pre></td></tr></table></figure>
<pre><code>(S
  It/PRP
  is/VBZ
  very/RB
  important/JJ
  to/TO
  be/VB
  pythonly/RB
  while/IN
  you/PRP
  are/VBP
  pythoning/VBG
  with/IN
  (Chunk python/NN)
  ./.
  All/DT
  pythoners/NNS
  have/VBP
  pythoned/VBN
  poorly/RB
  at/IN
  least/JJS
  once/RB
  ./.)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chunked.draw()</span><br></pre></td></tr></table></figure>
<h3 id="6-Chinking-短语排除"><a href="#6-Chinking-短语排除" class="headerlink" title="6. Chinking(短语排除)"></a>6. Chinking(短语排除)</h3><p>The chinking is used to chunk something expect the chinking things.It’s effect is to remove something.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">chinkGram = <span class="string">r"""Chunk: &#123;&lt;.*&gt;&#125;</span></span><br><span class="line"><span class="string">                                           Chink: &#125;&lt;NN&gt;&#123;"""</span></span><br><span class="line">chinkParser = nltk.RegexpParser(chinkGram)</span><br><span class="line">chinked = chinkParser.parse(tagged)</span><br><span class="line">print(chinked)</span><br></pre></td></tr></table></figure>
<pre><code>(S
  (Chunk It/PRP)
  (Chunk is/VBZ)
  (Chunk very/RB)
  (Chunk important/JJ)
  (Chunk to/TO)
  (Chunk be/VB)
  (Chunk pythonly/RB)
  (Chunk while/IN)
  (Chunk you/PRP)
  (Chunk are/VBP)
  (Chunk pythoning/VBG)
  (Chunk with/IN)
  (Chunk python/NN)
  (Chunk ./.)
  (Chunk All/DT)
  (Chunk pythoners/NNS)
  (Chunk have/VBP)
  (Chunk pythoned/VBN)
  (Chunk poorly/RB)
  (Chunk at/IN)
  (Chunk least/JJS)
  (Chunk once/RB)
  (Chunk ./.))
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chinked.draw()</span><br></pre></td></tr></table></figure>
<h3 id="7-Named-Entity-Recognition-命名实体识别"><a href="#7-Named-Entity-Recognition-命名实体识别" class="headerlink" title="7. Named Entity Recognition(命名实体识别)"></a>7. Named Entity Recognition(命名实体识别)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">new_text2 = <span class="string">"The Obama,president of the United States,is walking by the Danube with his families.They'll go back home at 7:00 a.m.."</span></span><br><span class="line">tagged2 = nltk.pos_tag(word_tokenize(new_text2))</span><br><span class="line">nameEnt = nltk.ne_chunk(tagged2)</span><br><span class="line">nameEnt.draw()</span><br></pre></td></tr></table></figure>
<h3 id="8-Lemmatizing-词形还原"><a href="#8-Lemmatizing-词形还原" class="headerlink" title="8. Lemmatizing(词形还原)"></a>8. Lemmatizing(词形还原)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line">lemmatizer = WordNetLemmatizer()</span><br><span class="line">entities = [<span class="string">"cats"</span>,<span class="string">"body"</span>,<span class="string">"shoes"</span>,<span class="string">"python"</span>,<span class="string">"shit"</span>,<span class="string">"park"</span>]</span><br><span class="line"><span class="keyword">for</span> entity <span class="keyword">in</span> entities:</span><br><span class="line">    print(lemmatizer.lemmatize(entity))</span><br></pre></td></tr></table></figure>
<pre><code>cat
body
shoe
python
shit
park
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nltk.__file__</span><br></pre></td></tr></table></figure>
<pre><code>&apos;C:\\Program Files\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py&apos;
</code></pre><h3 id="9-NLTK-Corpora-语料库"><a href="#9-NLTK-Corpora-语料库" class="headerlink" title="9. NLTK Corpora(语料库)"></a>9. NLTK Corpora(语料库)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> gutenberg</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> sent_tokenize</span><br><span class="line">sample = gutenberg.raw(<span class="string">'bible-kjv.txt'</span>)</span><br><span class="line">tok = sent_tokenize(sample)</span><br><span class="line">tok[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;[The King James Bible]\n\nThe Old Testament of the King James Bible\n\nThe First Book of Moses:  Called Genesis\n\n\n1:1 In the beginning God created the heaven and the earth.&apos;,
 &apos;1:2 And the earth was without form, and void; and darkness was upon\nthe face of the deep.&apos;,
 &apos;And the Spirit of God moved upon the face of the\nwaters.&apos;,
 &apos;1:3 And God said, Let there be light: and there was light.&apos;,
 &apos;1:4 And God saw the light, that it was good: and God divided the light\nfrom the darkness.&apos;]
</code></pre><h3 id="10-WordNet-一个英语词汇数据库"><a href="#10-WordNet-一个英语词汇数据库" class="headerlink" title="10. WordNet(一个英语词汇数据库)"></a>10. WordNet(一个英语词汇数据库)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> wordnet</span><br><span class="line">syns = wordnet.synsets(<span class="string">"program"</span>)</span><br><span class="line">syns</span><br></pre></td></tr></table></figure>
<pre><code>[Synset(&apos;plan.n.01&apos;),
 Synset(&apos;program.n.02&apos;),
 Synset(&apos;broadcast.n.02&apos;),
 Synset(&apos;platform.n.02&apos;),
 Synset(&apos;program.n.05&apos;),
 Synset(&apos;course_of_study.n.01&apos;),
 Synset(&apos;program.n.07&apos;),
 Synset(&apos;program.n.08&apos;),
 Synset(&apos;program.v.01&apos;),
 Synset(&apos;program.v.02&apos;)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">word = wordnet.synsets(<span class="string">'boy'</span>)</span><br><span class="line">synonyms =[]</span><br><span class="line">antonyms = []</span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> word:</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> w.lemmas():</span><br><span class="line">        synonyms.append(l.name())</span><br><span class="line">        <span class="keyword">if</span> l.antonyms():</span><br><span class="line">            <span class="keyword">for</span> a <span class="keyword">in</span> l.antonyms():</span><br><span class="line">                antonyms.append(a.name())</span><br><span class="line">print(set(synonyms))</span><br><span class="line">print(set(antonyms))</span><br></pre></td></tr></table></figure>
<pre><code>{&apos;male_child&apos;, &apos;son&apos;, &apos;boy&apos;}
{&apos;female_child&apos;, &apos;daughter&apos;, &apos;girl&apos;}
</code></pre><p>Use list comprehension(列表推导式)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">synonyms2 = set([l.name() <span class="keyword">for</span> w <span class="keyword">in</span> word <span class="keyword">for</span> l <span class="keyword">in</span> w.lemmas()])</span><br><span class="line">antonyms2 = set([a.name() <span class="keyword">for</span> w <span class="keyword">in</span> word <span class="keyword">for</span> l <span class="keyword">in</span> w.lemmas() <span class="keyword">for</span> a <span class="keyword">in</span> l.antonyms()])</span><br><span class="line">print(synonyms2)</span><br><span class="line">print(antonyms2)</span><br></pre></td></tr></table></figure>
<pre><code>{&apos;male_child&apos;, &apos;son&apos;, &apos;boy&apos;}
{&apos;female_child&apos;, &apos;daughter&apos;, &apos;girl&apos;}
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">word[<span class="number">0</span>][<span class="string">"boy"</span>].antosyns()</span><br></pre></td></tr></table></figure>
<pre><code>---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

&lt;ipython-input-77-93678c6743d6&gt; in &lt;module&gt;()
----&gt; 1 word[0][&quot;boy&quot;].antosyns()


TypeError: &apos;Synset&apos; object is not subscriptable
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat = wordnet.synset(<span class="string">"cat.n.01"</span>)</span><br><span class="line">dog = wordnet.synset(<span class="string">"dog.n.01"</span>)</span><br><span class="line">dog.wup_similarity(cat)</span><br></pre></td></tr></table></figure>
<pre><code>0.8571428571428571
</code></pre><h3 id="11-Text-Classfication-文本分类"><a href="#11-Text-Classfication-文本分类" class="headerlink" title="11. Text Classfication(文本分类)"></a>11. Text Classfication(文本分类)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> movie_reviews</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">documents = [(list(movie_reviews.words(fileid)),category)</span><br><span class="line">              <span class="keyword">for</span> category <span class="keyword">in</span> movie_reviews.categories()</span><br><span class="line">             <span class="keyword">for</span> fileid <span class="keyword">in</span> movie_reviews.fileids(category)]</span><br><span class="line">random.shuffle(documents)</span><br><span class="line"></span><br><span class="line">documents[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<pre><code>([&apos;did&apos;,
  &apos;you&apos;,
  &apos;ever&apos;,
  &apos;wonder&apos;,
  &apos;if&apos;,
  &apos;dennis&apos;,
  &apos;rodman&apos;,
  &apos;was&apos;,
  &apos;actually&apos;,
  &apos;from&apos;,
  &apos;this&apos;,
  &apos;planet&apos;,
  &apos;?&apos;,
  &apos;or&apos;,
  &apos;if&apos;,
  &apos;sylvester&apos;,
  &apos;stallone&apos;,
  &apos;was&apos;,
  &apos;some&apos;,
  &apos;kind&apos;,
  &apos;of&apos;,
  &apos;weird&apos;,
  &apos;extra&apos;,
  &apos;-&apos;,
  &apos;terrestrial&apos;,
  &apos;?&apos;,
  &apos;i&apos;,
  &apos;used&apos;,
  &apos;to&apos;,
  &apos;think&apos;,
  &apos;that&apos;,
  &apos;about&apos;,
  &apos;my&apos;,
  &apos;7th&apos;,
  &apos;grade&apos;,
  &apos;english&apos;,
  &apos;teacher&apos;,
  &apos;,&apos;,
  &apos;ms&apos;,
  &apos;.&apos;,
  &apos;carey&apos;,
  &apos;.&apos;,
  &apos;but&apos;,
  &apos;after&apos;,
  &apos;seeing&apos;,
  &apos;this&apos;,
  &apos;movie&apos;,
  &apos;,&apos;,
  &apos;they&apos;,
  &apos;may&apos;,
  &apos;have&apos;,
  &apos;confirmed&apos;,
  &apos;my&apos;,
  &apos;suspicions&apos;,
  &apos;.&apos;,
  &apos;as&apos;,
  &apos;the&apos;,
  &apos;story&apos;,
  &apos;goes&apos;,
  &apos;,&apos;,
  &apos;at&apos;,
  &apos;any&apos;,
  &apos;time&apos;,
  &apos;,&apos;,
  &apos;there&apos;,
  &apos;are&apos;,
  &apos;over&apos;,
  &apos;a&apos;,
  &apos;thousand&apos;,
  &apos;aliens&apos;,
  &apos;living&apos;,
  &apos;among&apos;,
  &apos;us&apos;,
  &apos;here&apos;,
  &apos;on&apos;,
  &apos;earth&apos;,
  &apos;.&apos;,
  &apos;the&apos;,
  &apos;men&apos;,
  &apos;in&apos;,
  &apos;black&apos;,
  &apos;(&apos;,
  &apos;mib&apos;,
  &apos;)&apos;,
  &apos;are&apos;,
  &apos;the&apos;,
  &apos;watchdogs&apos;,
  &apos;that&apos;,
  &apos;oversee&apos;,
  &apos;the&apos;,
  &apos;cosmic&apos;,
  &apos;citizens&apos;,
  &apos;,&apos;,
  &apos;guardians&apos;,
  &apos;of&apos;,
  &apos;our&apos;,
  &apos;beloved&apos;,
  &apos;planet&apos;,
  &apos;from&apos;,
  &apos;nasty&apos;,
  &apos;-&apos;,
  &apos;tempered&apos;,
  &apos;aliens&apos;,
  &apos;,&apos;,
  &apos;and&apos;,
  &apos;secret&apos;,
  &apos;service&apos;,
  &apos;to&apos;,
  &apos;the&apos;,
  &apos;stars&apos;,
  &apos;.&apos;,
  &apos;based&apos;,
  &apos;in&apos;,
  &apos;new&apos;,
  &apos;york&apos;,
  &apos;city&apos;,
  &apos;(&apos;,
  &apos;where&apos;,
  &apos;weird&apos;,
  &apos;is&apos;,
  &apos;the&apos;,
  &apos;norm&apos;,
  &apos;)&apos;,
  &apos;,&apos;,
  &apos;the&apos;,
  &apos;mib&apos;,
  &apos;organization&apos;,
  &apos;gives&apos;,
  &apos;human&apos;,
  &apos;form&apos;,
  &apos;to&apos;,
  &apos;our&apos;,
  &apos;space&apos;,
  &apos;-&apos;,
  &apos;faring&apos;,
  &apos;emigrants&apos;,
  &apos;so&apos;,
  &apos;that&apos;,
  &apos;they&apos;,
  &apos;may&apos;,
  &apos;walk&apos;,
  &apos;and&apos;,
  &apos;live&apos;,
  &apos;among&apos;,
  &apos;us&apos;,
  &apos;unnoticed&apos;,
  &apos;.&apos;,
  &apos;but&apos;,
  &apos;to&apos;,
  &apos;enforce&apos;,
  &apos;the&apos;,
  &apos;laws&apos;,
  &apos;of&apos;,
  &apos;earth&apos;,
  &apos;,&apos;,
  &apos;the&apos;,
  &apos;mib&apos;,
  &apos;carry&apos;,
  &apos;weapons&apos;,
  &apos;that&apos;,
  &apos;are&apos;,
  &apos;powerful&apos;,
  &apos;enough&apos;,
  &apos;to&apos;,
  &apos;meet&apos;,
  &apos;or&apos;,
  &apos;exceed&apos;,
  &apos;destruction&apos;,
  &apos;quotas&apos;,
  &apos;in&apos;,
  &apos;one&apos;,
  &apos;single&apos;,
  &apos;blast&apos;,
  &apos;.&apos;,
  &apos;they&apos;,
  &apos;carry&apos;,
  &apos;other&apos;,
  &apos;-&apos;,
  &apos;worldly&apos;,
  &apos;technology&apos;,
  &apos;to&apos;,
  &apos;erase&apos;,
  &apos;people&apos;,
  &quot;&apos;&quot;,
  &apos;s&apos;,
  &apos;short&apos;,
  &apos;-&apos;,
  &apos;term&apos;,
  &apos;memory&apos;,
  &apos;when&apos;,
  &apos;common&apos;,
  &apos;folk&apos;,
  &apos;see&apos;,
  &apos;the&apos;,
  &apos;mib&apos;,
  &apos;in&apos;,
  &apos;action&apos;,
  &apos;.&apos;,
  &apos;and&apos;,
  &apos;their&apos;,
  &apos;best&apos;,
  &apos;leads&apos;,
  &apos;on&apos;,
  &apos;cosmic&apos;,
  &apos;things&apos;,
  &apos;-&apos;,
  &apos;gone&apos;,
  &apos;-&apos;,
  &apos;awry&apos;,
  &apos;are&apos;,
  &apos;the&apos;,
  &apos;supermarket&apos;,
  &apos;tabloids&apos;,
  &apos;.&apos;,
  &apos;little&apos;,
  &apos;do&apos;,
  &apos;we&apos;,
  &apos;know&apos;,
  &apos;that&apos;,
  &apos;there&apos;,
  &apos;are&apos;,
  &apos;much&apos;,
  &apos;stronger&apos;,
  &apos;battles&apos;,
  &apos;of&apos;,
  &apos;good&apos;,
  &apos;v&apos;,
  &apos;.&apos;,
  &apos;evil&apos;,
  &apos;going&apos;,
  &apos;on&apos;,
  &apos;in&apos;,
  &apos;the&apos;,
  &apos;depths&apos;,
  &apos;of&apos;,
  &apos;space&apos;,
  &apos;.&apos;,
  &apos;one&apos;,
  &apos;of&apos;,
  &apos;the&apos;,
  &apos;aliens&apos;,
  &apos;-&apos;,
  &apos;as&apos;,
  &apos;-&apos;,
  &apos;human&apos;,
  &apos;on&apos;,
  &apos;this&apos;,
  &apos;planet&apos;,
  &apos;is&apos;,
  &apos;an&apos;,
  &apos;important&apos;,
  &apos;diplomat&apos;,
  &apos;that&apos;,
  &apos;is&apos;,
  &apos;carrying&apos;,
  &apos;something&apos;,
  &apos;very&apos;,
  &apos;precious&apos;,
  &apos;.&apos;,
  &apos;it&apos;,
  &apos;holds&apos;,
  &apos;the&apos;,
  &quot;&apos;&quot;,
  &apos;key&apos;,
  &quot;&apos;&quot;,
  &apos;,&apos;,
  &apos;literally&apos;,
  &apos;,&apos;,
  &apos;to&apos;,
  &apos;universal&apos;,
  &apos;peace&apos;,
  &apos;.&apos;,
  &apos;a&apos;,
  &apos;giant&apos;,
  &apos;cockroach&apos;,
  &apos;-&apos;,
  &apos;like&apos;,
  &apos;alien&apos;,
  &apos;soon&apos;,
  &apos;arrives&apos;,
  &apos;on&apos;,
  &apos;the&apos;,
  &apos;planet&apos;,
  &apos;and&apos;,
  &apos;steals&apos;,
  &apos;this&apos;,
  &quot;&apos;&quot;,
  &apos;key&apos;,
  &quot;&apos;&quot;,
  &apos;.&apos;,
  &apos;in&apos;,
  &apos;the&apos;,
  &apos;wrong&apos;,
  &apos;alien&apos;,
  &apos;hands&apos;,
  &apos;(&apos;,
  &apos;flippers&apos;,
  &apos;?&apos;,
  &apos;mandibles&apos;,
  &apos;?&apos;,
  &apos;tentacles&apos;,
  &apos;?&apos;,
  &apos;)&apos;,
  &apos;,&apos;,
  &apos;it&apos;,
  &apos;can&apos;,
  &apos;be&apos;,
  &apos;used&apos;,
  &apos;as&apos;,
  &apos;a&apos;,
  &apos;weapon&apos;,
  &apos;.&apos;,
  &apos;therefore&apos;,
  &apos;,&apos;,
  &apos;it&apos;,
  &apos;must&apos;,
  &apos;be&apos;,
  &apos;recovered&apos;,
  &apos;and&apos;,
  &apos;returned&apos;,
  &apos;to&apos;,
  &apos;it&apos;,
  &quot;&apos;&quot;,
  &apos;s&apos;,
  &apos;rightful&apos;,
  &apos;owners&apos;,
  &apos;.&apos;,
  &apos;otherwise&apos;,
  &apos;,&apos;,
  &apos;to&apos;,
  &apos;ensure&apos;,
  &apos;universal&apos;,
  &apos;safety&apos;,
  &apos;,&apos;,
  &apos;earth&apos;,
  &apos;will&apos;,
  &apos;be&apos;,
  &apos;destroyed&apos;,
  &apos;,&apos;,
  &apos;along&apos;,
  &apos;with&apos;,
  &apos;the&apos;,
  &quot;&apos;&quot;,
  &apos;key&apos;,
  &quot;&apos;&quot;,
  &apos;.&apos;,
  &apos;now&apos;,
  &apos;,&apos;,
  &apos;it&apos;,
  &quot;&apos;&quot;,
  &apos;s&apos;,
  &apos;the&apos;,
  &apos;mib&apos;,
  &apos;who&apos;,
  &apos;must&apos;,
  &apos;prevent&apos;,
  &apos;this&apos;,
  &apos;catastrophe&apos;,
  &apos;.&apos;,
  &apos;the&apos;,
  &apos;mib&apos;,
  &apos;agents&apos;,
  &apos;on&apos;,
  &apos;the&apos;,
  &apos;case&apos;,
  &apos;are&apos;,
  &apos;&quot;&apos;,
  &apos;k&apos;,
  &apos;&quot;&apos;,
  &apos;,&apos;,
  &apos;played&apos;,
  &apos;by&apos;,
  &apos;tommy&apos;,
  &apos;lee&apos;,
  &apos;jones&apos;,
  &apos;.&apos;,
  &apos;he&apos;,
  &apos;is&apos;,
  &apos;crustier&apos;,
  &apos;than&apos;,
  &apos;burnt&apos;,
  &apos;toast&apos;,
  &apos;and&apos;,
  &apos;even&apos;,
  &apos;more&apos;,
  &apos;serious&apos;,
  &apos;than&apos;,
  &apos;al&apos;,
  &apos;gore&apos;,
  &apos;.&apos;,
  &apos;the&apos;,
  &apos;stars&apos;,
  &apos;in&apos;,
  &apos;the&apos;,
  &apos;sky&apos;,
  &apos;no&apos;,
  &apos;longer&apos;,
  &apos;spark&apos;,
  &apos;wonder&apos;,
  &apos;in&apos;,
  &apos;his&apos;,
  &apos;eyes&apos;,
  &apos;.&apos;,
  &apos;he&apos;,
  &apos;is&apos;,
  &apos;accompanied&apos;,
  &apos;by&apos;,
  &apos;a&apos;,
  &apos;flippant&apos;,
  &apos;rookie&apos;,
  &apos;,&apos;,
  &apos;&quot;&apos;,
  &apos;j&apos;,
  &apos;&quot;&apos;,
  &apos;,&apos;,
  &apos;played&apos;,
  &apos;by&apos;,
  &apos;will&apos;,
  &apos;smith&apos;,
  &apos;.&apos;,
  &apos;but&apos;,
  &apos;,&apos;,
  &apos;despite&apos;,
  &apos;this&apos;,
  &apos;shoot&apos;,
  &apos;-&apos;,
  &apos;em&apos;,
  &apos;-&apos;,
  &apos;up&apos;,
  &apos;,&apos;,
  &apos;protect&apos;,
  &apos;-&apos;,
  &apos;earth&apos;,
  &apos;-&apos;,
  &apos;from&apos;,
  &apos;-&apos;,
  &apos;destruction&apos;,
  &apos;premise&apos;,
  &apos;,&apos;,
  &apos;this&apos;,
  &apos;is&apos;,
  &apos;nothing&apos;,
  &apos;at&apos;,
  &apos;all&apos;,
  &apos;like&apos;,
  &apos;a&apos;,
  &apos;typical&apos;,
  &apos;summer&apos;,
  &apos;action&apos;,
  &apos;movie&apos;,
  &apos;.&apos;,
  &apos;and&apos;,
  &apos;,&apos;,
  &apos;this&apos;,
  &apos;isn&apos;,
  &quot;&apos;&quot;,
  &apos;t&apos;,
  &apos;an&apos;,
  &apos;independence&apos;,
  &apos;day&apos;,
  &apos;knockoff&apos;,
  &apos;.&apos;,
  &apos;rather&apos;,
  &apos;,&apos;,
  &apos;this&apos;,
  &apos;is&apos;,
  &apos;a&apos;,
  &apos;stylishly&apos;,
  &apos;offbeat&apos;,
  &apos;sci&apos;,
  &apos;-&apos;,
  &apos;fi&apos;,
  &apos;comedy&apos;,
  &apos;that&apos;,
  &apos;pokes&apos;,
  &apos;fun&apos;,
  &apos;at&apos;,
  &apos;what&apos;,
  &apos;the&apos;,
  &apos;government&apos;,
  &apos;always&apos;,
  &apos;denies&apos;,
  &apos;?&apos;,
  &apos;that&apos;,
  &apos;there&apos;,
  &apos;are&apos;,
  &apos;real&apos;,
  &apos;aliens&apos;,
  &apos;that&apos;,
  &apos;live&apos;,
  &apos;here&apos;,
  &apos;,&apos;,
  &apos;and&apos;,
  &apos;that&apos;,
  &apos;the&apos;,
  &apos;government&apos;,
  &apos;does&apos;,
  &apos;its&apos;,
  &apos;darndest&apos;,
  &apos;to&apos;,
  &apos;cover&apos;,
  &apos;them&apos;,
  &apos;up&apos;,
  &apos;.&apos;,
  &apos;but&apos;,
  &apos;to&apos;,
  &apos;give&apos;,
  &apos;it&apos;,
  &apos;some&apos;,
  &apos;sense&apos;,
  &apos;of&apos;,
  &apos;excitement&apos;,
  &apos;and&apos;,
  &apos;to&apos;,
  &apos;keep&apos;,
  &apos;it&apos;,
  &apos;within&apos;,
  &apos;the&apos;,
  &apos;parameters&apos;,
  &apos;of&apos;,
  &apos;the&apos;,
  &apos;summer&apos;,
  &apos;movie&apos;,
  &apos;recipe&apos;,
  &apos;,&apos;,
  &apos;there&apos;,
  &apos;must&apos;,
  &apos;be&apos;,
  &apos;some&apos;,
  &apos;kind&apos;,
  &apos;of&apos;,
  &apos;earth&apos;,
  &apos;-&apos;,
  &apos;hangs&apos;,
  &apos;-&apos;,
  &apos;in&apos;,
  &apos;-&apos;,
  &apos;the&apos;,
  &apos;-&apos;,
  &apos;balance&apos;,
  &apos;scenario&apos;,
  &apos;.&apos;,
  &apos;yet&apos;,
  &apos;,&apos;,
  &apos;this&apos;,
  &apos;movie&apos;,
  &apos;is&apos;,
  &apos;very&apos;,
  &apos;appealing&apos;,
  &apos;.&apos;,
  &apos;the&apos;,
  &apos;abundance&apos;,
  &apos;of&apos;,
  &apos;wierdness&apos;,
  &apos;(&apos;,
  &apos;talking&apos;,
  &apos;aliens&apos;,
  &apos;,&apos;,
  &apos;pee&apos;,
  &apos;-&apos;,
  &apos;wee&apos;,
  &apos;atomizers&apos;,
  &apos;,&apos;,
  &apos;a&apos;,
  &apos;mortician&apos;,
  &apos;who&apos;,
  &quot;&apos;&quot;,
  &apos;lives&apos;,
  &quot;&apos;&quot;,
  &apos;for&apos;,
  &apos;her&apos;,
  &apos;work&apos;,
  &apos;,&apos;,
  &apos;and&apos;,
  &apos;lots&apos;,
  &apos;of&apos;,
  &apos;yucky&apos;,
  &apos;bugs&apos;,
  &apos;and&apos;,
  &apos;slime&apos;,
  &apos;-&apos;,
  &apos;splattering&apos;,
  &apos;galore&apos;,
  &apos;)&apos;,
  &apos;,&apos;,
  &apos;is&apos;,
  &apos;played&apos;,
  &apos;straight&apos;,
  &apos;,&apos;,
  &apos;like&apos;,
  &apos;as&apos;,
  &apos;if&apos;,
  &apos;this&apos;,
  &apos;were&apos;,
  &apos;normal&apos;,
  &apos;(&apos;,
  &apos;of&apos;,
  &apos;course&apos;,
  &apos;,&apos;,
  &apos;we&apos;,
  &apos;are&apos;,
  &apos;in&apos;,
  &apos;nyc&apos;,
  &apos;)&apos;,
  &apos;.&apos;,
  &apos;it&apos;,
  &apos;gives&apos;,
  &apos;it&apos;,
  &apos;a&apos;,
  &apos;deadpan&apos;,
  &apos;feel&apos;,
  &apos;,&apos;,
  &apos;which&apos;,
  &apos;makes&apos;,
  &apos;it&apos;,
  &apos;all&apos;,
  &apos;the&apos;,
  &apos;more&apos;,
  &apos;funnier&apos;,
  &apos;and&apos;,
  &apos;odder&apos;,
  &apos;.&apos;,
  &apos;jones&apos;,
  &apos;plays&apos;,
  &apos;the&apos;,
  &apos;venerable&apos;,
  &apos;seen&apos;,
  &apos;-&apos;,
  &apos;it&apos;,
  &apos;-&apos;,
  &apos;all&apos;,
  &apos;agent&apos;,
  &apos;with&apos;,
  &apos;seriousness&apos;,
  &apos;and&apos;,
  &apos;maturity&apos;,
  &apos;.&apos;,
  &apos;smith&apos;,
  &apos;is&apos;,
  &apos;likeable&apos;,
  &apos;and&apos;,
  &apos;makes&apos;,
  &apos;a&apos;,
  &apos;great&apos;,
  &apos;comic&apos;,
  &apos;partner&apos;,
  &apos;to&apos;,
  &apos;jones&apos;,
  &quot;&apos;&quot;,
  &apos;straight&apos;,
  &apos;man&apos;,
  &apos;routine&apos;,
  &apos;.&apos;,
  &apos;they&apos;,
  &apos;click&apos;,
  &apos;like&apos;,
  &apos;dorothy&apos;,
  &quot;&apos;&quot;,
  &apos;s&apos;,
  &apos;ruby&apos;,
  &apos;red&apos;,
  &apos;shoes&apos;,
  &apos;.&apos;,
  &apos;the&apos;,
  &apos;look&apos;,
  &apos;and&apos;,
  &apos;feel&apos;,
  &apos;of&apos;,
  &apos;the&apos;,
  &apos;movie&apos;,
  &apos;is&apos;,
  &apos;made&apos;,
  &apos;even&apos;,
  &apos;better&apos;,
  &apos;with&apos;,
  &apos;direction&apos;,
  &apos;from&apos;,
  &apos;barry&apos;,
  &apos;sonnenfeld&apos;,
  &apos;(&apos;,
  &apos;the&apos;,
  &apos;addam&apos;,
  &quot;&apos;&quot;,
  &apos;s&apos;,
  &apos;family&apos;,
  &apos;)&apos;,
  &apos;.&apos;,
  &apos;this&apos;,
  &apos;guy&apos;,
  &apos;has&apos;,
  &apos;a&apos;,
  &apos;knack&apos;,
  &apos;for&apos;,
  &quot;&apos;&quot;,
  &apos;gothic&apos;,
  &quot;&apos;&quot;,
  &apos;comedy&apos;,
  &apos;,&apos;,
  &apos;and&apos;,
  &apos;successfully&apos;,
  &apos;transfers&apos;,
  &apos;his&apos;,
  &apos;macabre&apos;,
  &apos;sense&apos;,
  &apos;of&apos;,
  &apos;humor&apos;,
  &apos;onto&apos;,
  &apos;the&apos;,
  &apos;screen&apos;,
  &apos;.&apos;,
  &apos;and&apos;,
  &apos;,&apos;,
  &apos;an&apos;,
  &apos;appropriate&apos;,
  &apos;dose&apos;,
  &apos;of&apos;,
  &apos;special&apos;,
  &apos;effects&apos;,
  &apos;helps&apos;,
  &apos;to&apos;,
  &apos;bolster&apos;,
  &apos;the&apos;,
  &apos;oddness&apos;,
  &apos;of&apos;,
  &apos;their&apos;,
  &apos;task&apos;,
  &apos;without&apos;,
  &apos;diverting&apos;,
  &apos;attention&apos;,
  &apos;from&apos;,
  &apos;the&apos;,
  &apos;human&apos;,
  &apos;actors&apos;,
  &apos;.&apos;,
  &apos;the&apos;,
  &apos;story&apos;,
  &apos;moves&apos;,
  &apos;well&apos;,
  &apos;,&apos;,
  &apos;and&apos;,
  &apos;before&apos;,
  &apos;you&apos;,
  &apos;know&apos;,
  &apos;it&apos;,
  &apos;,&apos;,
  &apos;the&apos;,
  &apos;end&apos;,
  &apos;credits&apos;,
  &apos;are&apos;,
  &apos;already&apos;,
  &apos;rolling&apos;,
  &apos;!&apos;,
  &apos;the&apos;,
  &apos;result&apos;,
  &apos;is&apos;,
  &apos;100&apos;,
  &apos;minutes&apos;,
  &apos;worth&apos;,
  &apos;of&apos;,
  &apos;fun&apos;,
  &apos;in&apos;,
  &apos;the&apos;,
  &apos;form&apos;,
  &apos;of&apos;,
  &apos;ewwwws&apos;,
  &apos;and&apos;,
  &apos;blechhhs&apos;,
  &apos;,&apos;,
  &apos;aaaahhhs&apos;,
  &apos;and&apos;,
  &apos;wows&apos;,
  &apos;.&apos;,
  &apos;let&apos;,
  &apos;the&apos;,
  &apos;men&apos;,
  &apos;in&apos;,
  &apos;black&apos;,
  &apos;protect&apos;,
  &apos;and&apos;,
  &apos;color&apos;,
  &apos;your&apos;,
  &apos;world&apos;,
  &apos;.&apos;],
 &apos;pos&apos;)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_words = [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> movie_reviews.words()]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_words</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;plot&apos;,
 &apos;:&apos;,
 &apos;two&apos;,
 &apos;teen&apos;,
 &apos;couples&apos;,
 &apos;go&apos;,
 &apos;to&apos;,
 &apos;a&apos;,
 &apos;church&apos;,
 &apos;party&apos;,
 &apos;,&apos;,
 &apos;drink&apos;,
 &apos;and&apos;,
 &apos;then&apos;,
 &apos;drive&apos;,
 &apos;.&apos;,
 &apos;they&apos;,
 &apos;get&apos;,
 &apos;into&apos;,
 &apos;an&apos;,
 &apos;accident&apos;,
 &apos;.&apos;,
 &apos;one&apos;,
 &apos;of&apos;,
 &apos;the&apos;,
 &apos;guys&apos;,
 &apos;dies&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;his&apos;,
 &apos;girlfriend&apos;,
 &apos;continues&apos;,
 &apos;to&apos;,
 &apos;see&apos;,
 &apos;him&apos;,
 &apos;in&apos;,
 &apos;her&apos;,
 &apos;life&apos;,
 &apos;,&apos;,
 &apos;and&apos;,
 &apos;has&apos;,
 &apos;nightmares&apos;,
 &apos;.&apos;,
 &apos;what&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;the&apos;,
 &apos;deal&apos;,
 &apos;?&apos;,
 &apos;watch&apos;,
 &apos;the&apos;,
 &apos;movie&apos;,
 &apos;and&apos;,
 &apos;&quot;&apos;,
 &apos;sorta&apos;,
 &apos;&quot;&apos;,
 &apos;find&apos;,
 &apos;out&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;critique&apos;,
 &apos;:&apos;,
 &apos;a&apos;,
 &apos;mind&apos;,
 &apos;-&apos;,
 &apos;fuck&apos;,
 &apos;movie&apos;,
 &apos;for&apos;,
 &apos;the&apos;,
 &apos;teen&apos;,
 &apos;generation&apos;,
 &apos;that&apos;,
 &apos;touches&apos;,
 &apos;on&apos;,
 &apos;a&apos;,
 &apos;very&apos;,
 &apos;cool&apos;,
 &apos;idea&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;presents&apos;,
 &apos;it&apos;,
 &apos;in&apos;,
 &apos;a&apos;,
 &apos;very&apos;,
 &apos;bad&apos;,
 &apos;package&apos;,
 &apos;.&apos;,
 &apos;which&apos;,
 &apos;is&apos;,
 &apos;what&apos;,
 &apos;makes&apos;,
 &apos;this&apos;,
 &apos;review&apos;,
 &apos;an&apos;,
 &apos;even&apos;,
 &apos;harder&apos;,
 &apos;one&apos;,
 &apos;to&apos;,
 &apos;write&apos;,
 &apos;,&apos;,
 &apos;since&apos;,
 &apos;i&apos;,
 &apos;generally&apos;,
 &apos;applaud&apos;,
 &apos;films&apos;,
 &apos;which&apos;,
 &apos;attempt&apos;,
 &apos;to&apos;,
 &apos;break&apos;,
 &apos;the&apos;,
 &apos;mold&apos;,
 &apos;,&apos;,
 &apos;mess&apos;,
 &apos;with&apos;,
 &apos;your&apos;,
 &apos;head&apos;,
 &apos;and&apos;,
 &apos;such&apos;,
 &apos;(&apos;,
 &apos;lost&apos;,
 &apos;highway&apos;,
 &apos;&amp;&apos;,
 &apos;memento&apos;,
 &apos;)&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;good&apos;,
 &apos;and&apos;,
 &apos;bad&apos;,
 &apos;ways&apos;,
 &apos;of&apos;,
 &apos;making&apos;,
 &apos;all&apos;,
 &apos;types&apos;,
 &apos;of&apos;,
 &apos;films&apos;,
 &apos;,&apos;,
 &apos;and&apos;,
 &apos;these&apos;,
 &apos;folks&apos;,
 &apos;just&apos;,
 &apos;didn&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;snag&apos;,
 &apos;this&apos;,
 &apos;one&apos;,
 &apos;correctly&apos;,
 &apos;.&apos;,
 &apos;they&apos;,
 &apos;seem&apos;,
 &apos;to&apos;,
 &apos;have&apos;,
 &apos;taken&apos;,
 &apos;this&apos;,
 &apos;pretty&apos;,
 &apos;neat&apos;,
 &apos;concept&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;executed&apos;,
 &apos;it&apos;,
 &apos;terribly&apos;,
 &apos;.&apos;,
 &apos;so&apos;,
 &apos;what&apos;,
 &apos;are&apos;,
 &apos;the&apos;,
 &apos;problems&apos;,
 &apos;with&apos;,
 &apos;the&apos;,
 &apos;movie&apos;,
 &apos;?&apos;,
 &apos;well&apos;,
 &apos;,&apos;,
 &apos;its&apos;,
 &apos;main&apos;,
 &apos;problem&apos;,
 &apos;is&apos;,
 &apos;that&apos;,
 &apos;it&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;simply&apos;,
 &apos;too&apos;,
 &apos;jumbled&apos;,
 &apos;.&apos;,
 &apos;it&apos;,
 &apos;starts&apos;,
 &apos;off&apos;,
 &apos;&quot;&apos;,
 &apos;normal&apos;,
 &apos;&quot;&apos;,
 &apos;but&apos;,
 &apos;then&apos;,
 &apos;downshifts&apos;,
 &apos;into&apos;,
 &apos;this&apos;,
 &apos;&quot;&apos;,
 &apos;fantasy&apos;,
 &apos;&quot;&apos;,
 &apos;world&apos;,
 &apos;in&apos;,
 &apos;which&apos;,
 &apos;you&apos;,
 &apos;,&apos;,
 &apos;as&apos;,
 &apos;an&apos;,
 &apos;audience&apos;,
 &apos;member&apos;,
 &apos;,&apos;,
 &apos;have&apos;,
 &apos;no&apos;,
 &apos;idea&apos;,
 &apos;what&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;going&apos;,
 &apos;on&apos;,
 &apos;.&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;dreams&apos;,
 &apos;,&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;characters&apos;,
 &apos;coming&apos;,
 &apos;back&apos;,
 &apos;from&apos;,
 &apos;the&apos;,
 &apos;dead&apos;,
 &apos;,&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;others&apos;,
 &apos;who&apos;,
 &apos;look&apos;,
 &apos;like&apos;,
 &apos;the&apos;,
 &apos;dead&apos;,
 &apos;,&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;strange&apos;,
 &apos;apparitions&apos;,
 &apos;,&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;disappearances&apos;,
 &apos;,&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;a&apos;,
 &apos;looooot&apos;,
 &apos;of&apos;,
 &apos;chase&apos;,
 &apos;scenes&apos;,
 &apos;,&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;tons&apos;,
 &apos;of&apos;,
 &apos;weird&apos;,
 &apos;things&apos;,
 &apos;that&apos;,
 &apos;happen&apos;,
 &apos;,&apos;,
 &apos;and&apos;,
 &apos;most&apos;,
 &apos;of&apos;,
 &apos;it&apos;,
 &apos;is&apos;,
 &apos;simply&apos;,
 &apos;not&apos;,
 &apos;explained&apos;,
 &apos;.&apos;,
 &apos;now&apos;,
 &apos;i&apos;,
 &apos;personally&apos;,
 &apos;don&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;mind&apos;,
 &apos;trying&apos;,
 &apos;to&apos;,
 &apos;unravel&apos;,
 &apos;a&apos;,
 &apos;film&apos;,
 &apos;every&apos;,
 &apos;now&apos;,
 &apos;and&apos;,
 &apos;then&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;when&apos;,
 &apos;all&apos;,
 &apos;it&apos;,
 &apos;does&apos;,
 &apos;is&apos;,
 &apos;give&apos;,
 &apos;me&apos;,
 &apos;the&apos;,
 &apos;same&apos;,
 &apos;clue&apos;,
 &apos;over&apos;,
 &apos;and&apos;,
 &apos;over&apos;,
 &apos;again&apos;,
 &apos;,&apos;,
 &apos;i&apos;,
 &apos;get&apos;,
 &apos;kind&apos;,
 &apos;of&apos;,
 &apos;fed&apos;,
 &apos;up&apos;,
 &apos;after&apos;,
 &apos;a&apos;,
 &apos;while&apos;,
 &apos;,&apos;,
 &apos;which&apos;,
 &apos;is&apos;,
 &apos;this&apos;,
 &apos;film&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;biggest&apos;,
 &apos;problem&apos;,
 &apos;.&apos;,
 &apos;it&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;obviously&apos;,
 &apos;got&apos;,
 &apos;this&apos;,
 &apos;big&apos;,
 &apos;secret&apos;,
 &apos;to&apos;,
 &apos;hide&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;it&apos;,
 &apos;seems&apos;,
 &apos;to&apos;,
 &apos;want&apos;,
 &apos;to&apos;,
 &apos;hide&apos;,
 &apos;it&apos;,
 &apos;completely&apos;,
 &apos;until&apos;,
 &apos;its&apos;,
 &apos;final&apos;,
 &apos;five&apos;,
 &apos;minutes&apos;,
 &apos;.&apos;,
 &apos;and&apos;,
 &apos;do&apos;,
 &apos;they&apos;,
 &apos;make&apos;,
 &apos;things&apos;,
 &apos;entertaining&apos;,
 &apos;,&apos;,
 &apos;thrilling&apos;,
 &apos;or&apos;,
 &apos;even&apos;,
 &apos;engaging&apos;,
 &apos;,&apos;,
 &apos;in&apos;,
 &apos;the&apos;,
 &apos;meantime&apos;,
 &apos;?&apos;,
 &apos;not&apos;,
 &apos;really&apos;,
 &apos;.&apos;,
 &apos;the&apos;,
 &apos;sad&apos;,
 &apos;part&apos;,
 &apos;is&apos;,
 &apos;that&apos;,
 &apos;the&apos;,
 &apos;arrow&apos;,
 &apos;and&apos;,
 &apos;i&apos;,
 &apos;both&apos;,
 &apos;dig&apos;,
 &apos;on&apos;,
 &apos;flicks&apos;,
 &apos;like&apos;,
 &apos;this&apos;,
 &apos;,&apos;,
 &apos;so&apos;,
 &apos;we&apos;,
 &apos;actually&apos;,
 &apos;figured&apos;,
 &apos;most&apos;,
 &apos;of&apos;,
 &apos;it&apos;,
 &apos;out&apos;,
 &apos;by&apos;,
 &apos;the&apos;,
 &apos;half&apos;,
 &apos;-&apos;,
 &apos;way&apos;,
 &apos;point&apos;,
 &apos;,&apos;,
 &apos;so&apos;,
 &apos;all&apos;,
 &apos;of&apos;,
 &apos;the&apos;,
 &apos;strangeness&apos;,
 &apos;after&apos;,
 &apos;that&apos;,
 &apos;did&apos;,
 &apos;start&apos;,
 &apos;to&apos;,
 &apos;make&apos;,
 &apos;a&apos;,
 &apos;little&apos;,
 &apos;bit&apos;,
 &apos;of&apos;,
 &apos;sense&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;it&apos;,
 &apos;still&apos;,
 &apos;didn&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;the&apos;,
 &apos;make&apos;,
 &apos;the&apos;,
 &apos;film&apos;,
 &apos;all&apos;,
 &apos;that&apos;,
 &apos;more&apos;,
 &apos;entertaining&apos;,
 &apos;.&apos;,
 &apos;i&apos;,
 &apos;guess&apos;,
 &apos;the&apos;,
 &apos;bottom&apos;,
 &apos;line&apos;,
 &apos;with&apos;,
 &apos;movies&apos;,
 &apos;like&apos;,
 &apos;this&apos;,
 &apos;is&apos;,
 &apos;that&apos;,
 &apos;you&apos;,
 &apos;should&apos;,
 &apos;always&apos;,
 &apos;make&apos;,
 &apos;sure&apos;,
 &apos;that&apos;,
 &apos;the&apos;,
 &apos;audience&apos;,
 &apos;is&apos;,
 &apos;&quot;&apos;,
 &apos;into&apos;,
 &apos;it&apos;,
 &apos;&quot;&apos;,
 &apos;even&apos;,
 &apos;before&apos;,
 &apos;they&apos;,
 &apos;are&apos;,
 &apos;given&apos;,
 &apos;the&apos;,
 &apos;secret&apos;,
 &apos;password&apos;,
 &apos;to&apos;,
 &apos;enter&apos;,
 &apos;your&apos;,
 &apos;world&apos;,
 &apos;of&apos;,
 &apos;understanding&apos;,
 &apos;.&apos;,
 &apos;i&apos;,
 &apos;mean&apos;,
 &apos;,&apos;,
 &apos;showing&apos;,
 &apos;melissa&apos;,
 &apos;sagemiller&apos;,
 &apos;running&apos;,
 &apos;away&apos;,
 &apos;from&apos;,
 &apos;visions&apos;,
 &apos;for&apos;,
 &apos;about&apos;,
 &apos;20&apos;,
 &apos;minutes&apos;,
 &apos;throughout&apos;,
 &apos;the&apos;,
 &apos;movie&apos;,
 &apos;is&apos;,
 &apos;just&apos;,
 &apos;plain&apos;,
 &apos;lazy&apos;,
 &apos;!&apos;,
 &apos;!&apos;,
 &apos;okay&apos;,
 &apos;,&apos;,
 &apos;we&apos;,
 &apos;get&apos;,
 &apos;it&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;people&apos;,
 &apos;chasing&apos;,
 &apos;her&apos;,
 &apos;and&apos;,
 &apos;we&apos;,
 &apos;don&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;know&apos;,
 &apos;who&apos;,
 &apos;they&apos;,
 &apos;are&apos;,
 &apos;.&apos;,
 &apos;do&apos;,
 &apos;we&apos;,
 &apos;really&apos;,
 &apos;need&apos;,
 &apos;to&apos;,
 &apos;see&apos;,
 &apos;it&apos;,
 &apos;over&apos;,
 &apos;and&apos;,
 &apos;over&apos;,
 &apos;again&apos;,
 &apos;?&apos;,
 &apos;how&apos;,
 &apos;about&apos;,
 &apos;giving&apos;,
 &apos;us&apos;,
 &apos;different&apos;,
 &apos;scenes&apos;,
 &apos;offering&apos;,
 &apos;further&apos;,
 &apos;insight&apos;,
 &apos;into&apos;,
 &apos;all&apos;,
 &apos;of&apos;,
 &apos;the&apos;,
 &apos;strangeness&apos;,
 &apos;going&apos;,
 &apos;down&apos;,
 &apos;in&apos;,
 &apos;the&apos;,
 &apos;movie&apos;,
 &apos;?&apos;,
 &apos;apparently&apos;,
 &apos;,&apos;,
 &apos;the&apos;,
 &apos;studio&apos;,
 &apos;took&apos;,
 &apos;this&apos;,
 &apos;film&apos;,
 &apos;away&apos;,
 &apos;from&apos;,
 &apos;its&apos;,
 &apos;director&apos;,
 &apos;and&apos;,
 &apos;chopped&apos;,
 &apos;it&apos;,
 &apos;up&apos;,
 &apos;themselves&apos;,
 &apos;,&apos;,
 &apos;and&apos;,
 &apos;it&apos;,
 &apos;shows&apos;,
 &apos;.&apos;,
 &apos;there&apos;,
 &apos;might&apos;,
 &quot;&apos;&quot;,
 &apos;ve&apos;,
 &apos;been&apos;,
 &apos;a&apos;,
 &apos;pretty&apos;,
 &apos;decent&apos;,
 &apos;teen&apos;,
 &apos;mind&apos;,
 &apos;-&apos;,
 &apos;fuck&apos;,
 &apos;movie&apos;,
 &apos;in&apos;,
 &apos;here&apos;,
 &apos;somewhere&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;i&apos;,
 &apos;guess&apos;,
 &apos;&quot;&apos;,
 &apos;the&apos;,
 &apos;suits&apos;,
 &apos;&quot;&apos;,
 &apos;decided&apos;,
 &apos;that&apos;,
 &apos;turning&apos;,
 &apos;it&apos;,
 &apos;into&apos;,
 &apos;a&apos;,
 &apos;music&apos;,
 &apos;video&apos;,
 &apos;with&apos;,
 &apos;little&apos;,
 &apos;edge&apos;,
 &apos;,&apos;,
 &apos;would&apos;,
 &apos;make&apos;,
 &apos;more&apos;,
 &apos;sense&apos;,
 &apos;.&apos;,
 &apos;the&apos;,
 &apos;actors&apos;,
 &apos;are&apos;,
 &apos;pretty&apos;,
 &apos;good&apos;,
 &apos;for&apos;,
 &apos;the&apos;,
 &apos;most&apos;,
 &apos;part&apos;,
 &apos;,&apos;,
 &apos;although&apos;,
 &apos;wes&apos;,
 &apos;bentley&apos;,
 &apos;just&apos;,
 &apos;seemed&apos;,
 &apos;to&apos;,
 &apos;be&apos;,
 &apos;playing&apos;,
 &apos;the&apos;,
 &apos;exact&apos;,
 &apos;same&apos;,
 &apos;character&apos;,
 &apos;that&apos;,
 &apos;he&apos;,
 &apos;did&apos;,
 &apos;in&apos;,
 &apos;american&apos;,
 &apos;beauty&apos;,
 &apos;,&apos;,
 &apos;only&apos;,
 &apos;in&apos;,
 &apos;a&apos;,
 &apos;new&apos;,
 &apos;neighborhood&apos;,
 &apos;.&apos;,
 &apos;but&apos;,
 &apos;my&apos;,
 &apos;biggest&apos;,
 &apos;kudos&apos;,
 &apos;go&apos;,
 &apos;out&apos;,
 &apos;to&apos;,
 &apos;sagemiller&apos;,
 &apos;,&apos;,
 &apos;who&apos;,
 &apos;holds&apos;,
 &apos;her&apos;,
 &apos;own&apos;,
 &apos;throughout&apos;,
 &apos;the&apos;,
 &apos;entire&apos;,
 &apos;film&apos;,
 &apos;,&apos;,
 &apos;and&apos;,
 &apos;actually&apos;,
 &apos;has&apos;,
 &apos;you&apos;,
 &apos;feeling&apos;,
 &apos;her&apos;,
 &apos;character&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;unraveling&apos;,
 &apos;.&apos;,
 &apos;overall&apos;,
 &apos;,&apos;,
 &apos;the&apos;,
 &apos;film&apos;,
 &apos;doesn&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;stick&apos;,
 &apos;because&apos;,
 &apos;it&apos;,
 &apos;doesn&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;entertain&apos;,
 &apos;,&apos;,
 &apos;it&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;confusing&apos;,
 &apos;,&apos;,
 &apos;it&apos;,
 &apos;rarely&apos;,
 &apos;excites&apos;,
 &apos;and&apos;,
 &apos;it&apos;,
 &apos;feels&apos;,
 &apos;pretty&apos;,
 &apos;redundant&apos;,
 &apos;for&apos;,
 &apos;most&apos;,
 &apos;of&apos;,
 &apos;its&apos;,
 &apos;runtime&apos;,
 &apos;,&apos;,
 &apos;despite&apos;,
 &apos;a&apos;,
 &apos;pretty&apos;,
 &apos;cool&apos;,
 &apos;ending&apos;,
 &apos;and&apos;,
 &apos;explanation&apos;,
 &apos;to&apos;,
 &apos;all&apos;,
 &apos;of&apos;,
 &apos;the&apos;,
 &apos;craziness&apos;,
 &apos;that&apos;,
 &apos;came&apos;,
 &apos;before&apos;,
 &apos;it&apos;,
 &apos;.&apos;,
 &apos;oh&apos;,
 &apos;,&apos;,
 &apos;and&apos;,
 &apos;by&apos;,
 &apos;the&apos;,
 &apos;way&apos;,
 &apos;,&apos;,
 &apos;this&apos;,
 &apos;is&apos;,
 &apos;not&apos;,
 &apos;a&apos;,
 &apos;horror&apos;,
 &apos;or&apos;,
 &apos;teen&apos;,
 &apos;slasher&apos;,
 &apos;flick&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;it&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;just&apos;,
 &apos;packaged&apos;,
 &apos;to&apos;,
 &apos;look&apos;,
 &apos;that&apos;,
 &apos;way&apos;,
 &apos;because&apos;,
 &apos;someone&apos;,
 &apos;is&apos;,
 &apos;apparently&apos;,
 &apos;assuming&apos;,
 &apos;that&apos;,
 &apos;the&apos;,
 &apos;genre&apos;,
 &apos;is&apos;,
 &apos;still&apos;,
 &apos;hot&apos;,
 &apos;with&apos;,
 &apos;the&apos;,
 &apos;kids&apos;,
 &apos;.&apos;,
 &apos;it&apos;,
 &apos;also&apos;,
 &apos;wrapped&apos;,
 &apos;production&apos;,
 &apos;two&apos;,
 &apos;years&apos;,
 &apos;ago&apos;,
 &apos;and&apos;,
 &apos;has&apos;,
 &apos;been&apos;,
 &apos;sitting&apos;,
 &apos;on&apos;,
 &apos;the&apos;,
 &apos;shelves&apos;,
 &apos;ever&apos;,
 &apos;since&apos;,
 &apos;.&apos;,
 &apos;whatever&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;skip&apos;,
 &apos;it&apos;,
 &apos;!&apos;,
 &apos;where&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;joblo&apos;,
 &apos;coming&apos;,
 &apos;from&apos;,
 &apos;?&apos;,
 &apos;a&apos;,
 &apos;nightmare&apos;,
 &apos;of&apos;,
 &apos;elm&apos;,
 &apos;street&apos;,
 &apos;3&apos;,
 &apos;(&apos;,
 &apos;7&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;blair&apos;,
 &apos;witch&apos;,
 &apos;2&apos;,
 &apos;(&apos;,
 &apos;7&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;the&apos;,
 &apos;crow&apos;,
 &apos;(&apos;,
 &apos;9&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;the&apos;,
 &apos;crow&apos;,
 &apos;:&apos;,
 &apos;salvation&apos;,
 &apos;(&apos;,
 &apos;4&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;lost&apos;,
 &apos;highway&apos;,
 &apos;(&apos;,
 &apos;10&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;memento&apos;,
 &apos;(&apos;,
 &apos;10&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;the&apos;,
 &apos;others&apos;,
 &apos;(&apos;,
 &apos;9&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;stir&apos;,
 &apos;of&apos;,
 &apos;echoes&apos;,
 &apos;(&apos;,
 &apos;8&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;the&apos;,
 &apos;happy&apos;,
 &apos;bastard&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;quick&apos;,
 &apos;movie&apos;,
 &apos;review&apos;,
 &apos;damn&apos;,
 &apos;that&apos;,
 &apos;y2k&apos;,
 &apos;bug&apos;,
 &apos;.&apos;,
 &apos;it&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;got&apos;,
 &apos;a&apos;,
 &apos;head&apos;,
 &apos;start&apos;,
 &apos;in&apos;,
 &apos;this&apos;,
 &apos;movie&apos;,
 &apos;starring&apos;,
 &apos;jamie&apos;,
 &apos;lee&apos;,
 &apos;curtis&apos;,
 &apos;and&apos;,
 &apos;another&apos;,
 &apos;baldwin&apos;,
 &apos;brother&apos;,
 &apos;(&apos;,
 &apos;william&apos;,
 &apos;this&apos;,
 &apos;time&apos;,
 &apos;)&apos;,
 &apos;in&apos;,
 &apos;a&apos;,
 &apos;story&apos;,
 &apos;regarding&apos;,
 &apos;a&apos;,
 &apos;crew&apos;,
 &apos;of&apos;,
 &apos;a&apos;,
 &apos;tugboat&apos;,
 &apos;that&apos;,
 &apos;comes&apos;,
 &apos;across&apos;,
 &apos;a&apos;,
 &apos;deserted&apos;,
 &apos;russian&apos;,
 &apos;tech&apos;,
 &apos;ship&apos;,
 &apos;that&apos;,
 &apos;has&apos;,
 &apos;a&apos;,
 &apos;strangeness&apos;,
 &apos;to&apos;,
 &apos;it&apos;,
 &apos;when&apos;,
 &apos;they&apos;,
 &apos;kick&apos;,
 &apos;the&apos;,
 &apos;power&apos;,
 &apos;back&apos;,
 &apos;on&apos;,
 &apos;.&apos;,
 &apos;little&apos;,
 &apos;do&apos;,
 &apos;they&apos;,
 &apos;know&apos;,
 &apos;the&apos;,
 &apos;power&apos;,
 &apos;within&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;going&apos;,
 &apos;for&apos;,
 &apos;the&apos;,
 &apos;gore&apos;,
 &apos;and&apos;,
 &apos;bringing&apos;,
 &apos;on&apos;,
 &apos;a&apos;,
 &apos;few&apos;,
 &apos;action&apos;,
 &apos;sequences&apos;,
 &apos;here&apos;,
 &apos;and&apos;,
 &apos;there&apos;,
 &apos;,&apos;,
 &apos;virus&apos;,
 &apos;still&apos;,
 &apos;feels&apos;,
 &apos;very&apos;,
 &apos;empty&apos;,
 &apos;,&apos;,
 &apos;like&apos;,
 &apos;a&apos;,
 &apos;movie&apos;,
 &apos;going&apos;,
 &apos;for&apos;,
 &apos;all&apos;,
 &apos;flash&apos;,
 &apos;and&apos;,
 &apos;no&apos;,
 &apos;substance&apos;,
 &apos;.&apos;,
 &apos;we&apos;,
 &apos;don&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;know&apos;,
 &apos;why&apos;,
 &apos;the&apos;,
 &apos;crew&apos;,
 &apos;was&apos;,
 &apos;really&apos;,
 &apos;out&apos;,
 &apos;in&apos;,
 ...]
</code></pre><p><strong>Warning</strong>:At the begining, I just writed the follow codes like this:<code>new_all_words = [w for w in all_words if w not in nltk.corpus.stopwords.words(&#39;english&#39;)</code>,however the code couldn’t complite successfully even I had been waiting for several minites. Finally, I found that the I/O operations can be 1583820 times, and the operation system read data from the hark disk again and again without saying any thing,it was so stupid.So when we programming,we should set the I/O resources as a variable if it will be used for several times. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stopwords = nltk.corpus.stopwords.words(<span class="string">'english'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new_all_words = [w <span class="keyword">for</span> w <span class="keyword">in</span> all_words <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new_all_words = [w <span class="keyword">for</span> w <span class="keyword">in</span> new_all_words <span class="keyword">if</span> w.isalpha()]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(all_words)</span><br></pre></td></tr></table></figure>
<pre><code>1583820
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(nltk.corpus.stopwords.words(<span class="string">'english'</span>))</span><br></pre></td></tr></table></figure>
<pre><code>179
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nltk.corpus.stopwords.words(<span class="string">'english'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;i&apos;,
 &apos;me&apos;,
 &apos;my&apos;,
 &apos;myself&apos;,
 &apos;we&apos;,
 &apos;our&apos;,
 &apos;ours&apos;,
 &apos;ourselves&apos;,
 &apos;you&apos;,
 &quot;you&apos;re&quot;,
 &quot;you&apos;ve&quot;,
 &quot;you&apos;ll&quot;,
 &quot;you&apos;d&quot;,
 &apos;your&apos;,
 &apos;yours&apos;,
 &apos;yourself&apos;,
 &apos;yourselves&apos;,
 &apos;he&apos;,
 &apos;him&apos;,
 &apos;his&apos;,
 &apos;himself&apos;,
 &apos;she&apos;,
 &quot;she&apos;s&quot;,
 &apos;her&apos;,
 &apos;hers&apos;,
 &apos;herself&apos;,
 &apos;it&apos;,
 &quot;it&apos;s&quot;,
 &apos;its&apos;,
 &apos;itself&apos;,
 &apos;they&apos;,
 &apos;them&apos;,
 &apos;their&apos;,
 &apos;theirs&apos;,
 &apos;themselves&apos;,
 &apos;what&apos;,
 &apos;which&apos;,
 &apos;who&apos;,
 &apos;whom&apos;,
 &apos;this&apos;,
 &apos;that&apos;,
 &quot;that&apos;ll&quot;,
 &apos;these&apos;,
 &apos;those&apos;,
 &apos;am&apos;,
 &apos;is&apos;,
 &apos;are&apos;,
 &apos;was&apos;,
 &apos;were&apos;,
 &apos;be&apos;,
 &apos;been&apos;,
 &apos;being&apos;,
 &apos;have&apos;,
 &apos;has&apos;,
 &apos;had&apos;,
 &apos;having&apos;,
 &apos;do&apos;,
 &apos;does&apos;,
 &apos;did&apos;,
 &apos;doing&apos;,
 &apos;a&apos;,
 &apos;an&apos;,
 &apos;the&apos;,
 &apos;and&apos;,
 &apos;but&apos;,
 &apos;if&apos;,
 &apos;or&apos;,
 &apos;because&apos;,
 &apos;as&apos;,
 &apos;until&apos;,
 &apos;while&apos;,
 &apos;of&apos;,
 &apos;at&apos;,
 &apos;by&apos;,
 &apos;for&apos;,
 &apos;with&apos;,
 &apos;about&apos;,
 &apos;against&apos;,
 &apos;between&apos;,
 &apos;into&apos;,
 &apos;through&apos;,
 &apos;during&apos;,
 &apos;before&apos;,
 &apos;after&apos;,
 &apos;above&apos;,
 &apos;below&apos;,
 &apos;to&apos;,
 &apos;from&apos;,
 &apos;up&apos;,
 &apos;down&apos;,
 &apos;in&apos;,
 &apos;out&apos;,
 &apos;on&apos;,
 &apos;off&apos;,
 &apos;over&apos;,
 &apos;under&apos;,
 &apos;again&apos;,
 &apos;further&apos;,
 &apos;then&apos;,
 &apos;once&apos;,
 &apos;here&apos;,
 &apos;there&apos;,
 &apos;when&apos;,
 &apos;where&apos;,
 &apos;why&apos;,
 &apos;how&apos;,
 &apos;all&apos;,
 &apos;any&apos;,
 &apos;both&apos;,
 &apos;each&apos;,
 &apos;few&apos;,
 &apos;more&apos;,
 &apos;most&apos;,
 &apos;other&apos;,
 &apos;some&apos;,
 &apos;such&apos;,
 &apos;no&apos;,
 &apos;nor&apos;,
 &apos;not&apos;,
 &apos;only&apos;,
 &apos;own&apos;,
 &apos;same&apos;,
 &apos;so&apos;,
 &apos;than&apos;,
 &apos;too&apos;,
 &apos;very&apos;,
 &apos;s&apos;,
 &apos;t&apos;,
 &apos;can&apos;,
 &apos;will&apos;,
 &apos;just&apos;,
 &apos;don&apos;,
 &quot;don&apos;t&quot;,
 &apos;should&apos;,
 &quot;should&apos;ve&quot;,
 &apos;now&apos;,
 &apos;d&apos;,
 &apos;ll&apos;,
 &apos;m&apos;,
 &apos;o&apos;,
 &apos;re&apos;,
 &apos;ve&apos;,
 &apos;y&apos;,
 &apos;ain&apos;,
 &apos;aren&apos;,
 &quot;aren&apos;t&quot;,
 &apos;couldn&apos;,
 &quot;couldn&apos;t&quot;,
 &apos;didn&apos;,
 &quot;didn&apos;t&quot;,
 &apos;doesn&apos;,
 &quot;doesn&apos;t&quot;,
 &apos;hadn&apos;,
 &quot;hadn&apos;t&quot;,
 &apos;hasn&apos;,
 &quot;hasn&apos;t&quot;,
 &apos;haven&apos;,
 &quot;haven&apos;t&quot;,
 &apos;isn&apos;,
 &quot;isn&apos;t&quot;,
 &apos;ma&apos;,
 &apos;mightn&apos;,
 &quot;mightn&apos;t&quot;,
 &apos;mustn&apos;,
 &quot;mustn&apos;t&quot;,
 &apos;needn&apos;,
 &quot;needn&apos;t&quot;,
 &apos;shan&apos;,
 &quot;shan&apos;t&quot;,
 &apos;shouldn&apos;,
 &quot;shouldn&apos;t&quot;,
 &apos;wasn&apos;,
 &quot;wasn&apos;t&quot;,
 &apos;weren&apos;,
 &quot;weren&apos;t&quot;,
 &apos;won&apos;,
 &quot;won&apos;t&quot;,
 &apos;wouldn&apos;,
 &quot;wouldn&apos;t&quot;]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">words_freqlist = nltk.FreqDist(new_all_words)</span><br><span class="line">print(words_freqlist.most_common(<span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<pre><code>[(&apos;film&apos;, 9517), (&apos;one&apos;, 5852), (&apos;movie&apos;, 5771), (&apos;like&apos;, 3690), (&apos;even&apos;, 2565), (&apos;good&apos;, 2411), (&apos;time&apos;, 2411), (&apos;story&apos;, 2169), (&apos;would&apos;, 2109), (&apos;much&apos;, 2049)]
</code></pre><h3 id="12-Words-as-Features-for-Learning-用来学习的特征词汇"><a href="#12-Words-as-Features-for-Learning-用来学习的特征词汇" class="headerlink" title="12. Words as Features for Learning(用来学习的特征词汇)"></a>12. Words as Features for Learning(用来学习的特征词汇)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">word_features = list(words_freqlist.keys())[:<span class="number">3000</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_features</span><span class="params">(document)</span>:</span></span><br><span class="line">    words = set(document)</span><br><span class="line">    features = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> word_features:</span><br><span class="line">        features[w] = (w <span class="keyword">in</span> words)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> features</span><br><span class="line">featuresets = [(find_features(rev), category) <span class="keyword">for</span> (rev, category) <span class="keyword">in</span> documents]</span><br></pre></td></tr></table></figure>
<h3 id="13-Naive-Bayes-朴素贝叶斯"><a href="#13-Naive-Bayes-朴素贝叶斯" class="headerlink" title="13. Naive Bayes(朴素贝叶斯)"></a>13. Naive Bayes(朴素贝叶斯)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">training_set = featuresets[:<span class="number">1900</span>]</span><br><span class="line">testing_set = featuresets[<span class="number">1900</span>:]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">classifier = nltk.NaiveBayesClassifier.train(training_set)</span><br><span class="line">print(<span class="string">"Naive Bayes Algo accuracy:"</span>,(nltk.classify.accuracy(classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Naive Bayes Algo accuracy: 84.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classifier.show_most_informative_features(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Most Informative Features
                   sucks = True              neg : pos    =      8.7 : 1.0
                  annual = True              pos : neg    =      8.2 : 1.0
                 frances = True              pos : neg    =      8.2 : 1.0
           unimaginative = True              neg : pos    =      7.8 : 1.0
                 idiotic = True              neg : pos    =      7.3 : 1.0
              schumacher = True              neg : pos    =      7.1 : 1.0
                    mena = True              neg : pos    =      7.1 : 1.0
               atrocious = True              neg : pos    =      7.1 : 1.0
             silverstone = True              neg : pos    =      7.1 : 1.0
                  suvari = True              neg : pos    =      7.1 : 1.0
                  turkey = True              neg : pos    =      6.7 : 1.0
                  regard = True              pos : neg    =      6.5 : 1.0
                 kidding = True              neg : pos    =      6.4 : 1.0
                  crappy = True              neg : pos    =      6.4 : 1.0
                  shoddy = True              neg : pos    =      6.4 : 1.0
</code></pre><h3 id="14-Save-Classifier-with-Pickle-使用Pickle保存分类器"><a href="#14-Save-Classifier-with-Pickle-使用Pickle保存分类器" class="headerlink" title="14. Save Classifier with Pickle(使用Pickle保存分类器)"></a>14. Save Classifier with Pickle(使用Pickle保存分类器)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">'naivebayes.pickle'</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">classifier_f = open(<span class="string">'naivebayes.pickle'</span>,<span class="string">"rb"</span>)</span><br><span class="line">classifier = pickle.load(classifier_f)</span><br><span class="line">classifier_f.close()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Naive Bayes Algo accuracy:"</span>,(nltk.classify.accuracy(classifier,testing_set))*<span class="number">100</span>)</span><br><span class="line">classifier.show_most_informative_features(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Naive Bayes Algo accuracy: 84.0
Most Informative Features
                   sucks = True              neg : pos    =      8.7 : 1.0
                  annual = True              pos : neg    =      8.2 : 1.0
                 frances = True              pos : neg    =      8.2 : 1.0
           unimaginative = True              neg : pos    =      7.8 : 1.0
                 idiotic = True              neg : pos    =      7.3 : 1.0
              schumacher = True              neg : pos    =      7.1 : 1.0
                    mena = True              neg : pos    =      7.1 : 1.0
               atrocious = True              neg : pos    =      7.1 : 1.0
             silverstone = True              neg : pos    =      7.1 : 1.0
                  suvari = True              neg : pos    =      7.1 : 1.0
                  turkey = True              neg : pos    =      6.7 : 1.0
                  regard = True              pos : neg    =      6.5 : 1.0
                 kidding = True              neg : pos    =      6.4 : 1.0
                  crappy = True              neg : pos    =      6.4 : 1.0
                  shoddy = True              neg : pos    =      6.4 : 1.0
</code></pre><p>training again</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">random.shuffle(documents)</span><br><span class="line">all_words = [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> movie_reviews.words()]</span><br><span class="line">new_all_words = [w <span class="keyword">for</span> w <span class="keyword">in</span> all_words <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</span><br><span class="line">new_all_words = [w <span class="keyword">for</span> w <span class="keyword">in</span> new_all_words <span class="keyword">if</span> w.isalpha()]</span><br><span class="line">words_freqlist = nltk.FreqDist(new_all_words)</span><br><span class="line">word_features = list(words_freqlist.keys())[:<span class="number">3000</span>]</span><br><span class="line">training_set = featuresets[:<span class="number">1900</span>]</span><br><span class="line">testing_set = featuresets[<span class="number">1900</span>:]</span><br><span class="line">classifier = nltk.NaiveBayesClassifier.train(training_set)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Naive Bayes Algo accuracy:"</span>,(nltk.classify.accuracy(classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Naive Bayes Algo accuracy: 84.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">classifier_f = open(<span class="string">'naivebayes.pickle'</span>,<span class="string">"rb"</span>)</span><br><span class="line">classifier = pickle.load(classifier_f)</span><br><span class="line">classifier_f.close()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Naive Bayes Algo accuracy:"</span>,(nltk.classify.accuracy(classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Naive Bayes Algo accuracy: 84.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Naive Bayes Algo accuracy:"</span>,(nltk.classify.accuracy(classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Naive Bayes Algo accuracy: 84.0
</code></pre><h3 id="15-Scikit-Learn-incorporation"><a href="#15-Scikit-Learn-incorporation" class="headerlink" title="15. Scikit-Learn incorporation()"></a>15. Scikit-Learn incorporation()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.classify.scikitlearn <span class="keyword">import</span> SklearnClassifier</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB, GaussianNB, BernoulliNB</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MNB_classifier = SklearnClassifier(MultinomialNB())</span><br><span class="line">MNB_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"MNB_classifier accuracy percent:"</span>,(nltk.classify.accuracy(MNB_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>MNB_classifier accuracy percent: 82.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这段代码有问题，不可以运行。</span></span><br><span class="line">GNB_classifier = SklearnClassifier(GaussianNB())</span><br><span class="line">GNB_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"GNB_classifier accuracy percent:"</span>,(nltk.classify.accuracy(GNB_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

&lt;ipython-input-149-dbf69e211330&gt; in &lt;module&gt;()
      1 GNB_classifier = SklearnClassifier(GaussianNB())
----&gt; 2 GNB_classifier.train(training_set)
      3 print(&quot;GNB_classifier accuracy percent:&quot;,(nltk.classify.accuracy(GNB_classifier,testing_set))*100)


C:\Program Files\Anaconda3\lib\site-packages\nltk\classify\scikitlearn.py in train(self, labeled_featuresets)
    117         X = self._vectorizer.fit_transform(X)
    118         y = self._encoder.fit_transform(y)
--&gt; 119         self._clf.fit(X, y)
    120 
    121         return self


C:\Program Files\Anaconda3\lib\site-packages\sklearn\naive_bayes.py in fit(self, X, y, sample_weight)
    180             Returns self.
    181         &quot;&quot;&quot;
--&gt; 182         X, y = check_X_y(X, y)
    183         return self._partial_fit(X, y, np.unique(y), _refit=True,
    184                                  sample_weight=sample_weight)


C:\Program Files\Anaconda3\lib\site-packages\sklearn\utils\validation.py in check_X_y(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)
    519     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,
    520                     ensure_2d, allow_nd, ensure_min_samples,
--&gt; 521                     ensure_min_features, warn_on_dtype, estimator)
    522     if multi_output:
    523         y = check_array(y, &apos;csr&apos;, force_all_finite=True, ensure_2d=False,


C:\Program Files\Anaconda3\lib\site-packages\sklearn\utils\validation.py in check_array(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)
    378     if sp.issparse(array):
    379         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,
--&gt; 380                                       force_all_finite)
    381     else:
    382         array = np.array(array, dtype=dtype, order=order, copy=copy)


C:\Program Files\Anaconda3\lib\site-packages\sklearn\utils\validation.py in _ensure_sparse_format(spmatrix, accept_sparse, dtype, copy, force_all_finite)
    241     &quot;&quot;&quot;
    242     if accept_sparse in [None, False]:
--&gt; 243         raise TypeError(&apos;A sparse matrix was passed, but dense &apos;
    244                         &apos;data is required. Use X.toarray() to &apos;
    245                         &apos;convert to a dense numpy array.&apos;)


TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">BNB_classifier = SklearnClassifier(BernoulliNB())</span><br><span class="line">BNB_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"BNB_classifier accuracy percent:"</span>,(nltk.classify.accuracy(BNB_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>BNB_classifier accuracy percent: 84.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression, SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC, LinearSVC, NuSVC</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LogisticRegression_classifier = SklearnClassifier(LogisticRegression())</span><br><span class="line">LogisticRegression_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"LogisticRegression_classifier accuracy percent:"</span>,(nltk.classify.accuracy(LogisticRegression_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>LogisticRegression_classifier accuracy percent: 82.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SGDClassifier_classifier = SklearnClassifier(SGDClassifier())</span><br><span class="line">SGDClassifier_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"SGDClassifier_classifier accuracy percent:"</span>,(nltk.classify.accuracy(SGDClassifier_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>SGDClassifier_classifier accuracy percent: 82.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SVC_classifier = SklearnClassifier(SVC())</span><br><span class="line">SVC_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"SVC_classifier accuracy percent:"</span>,(nltk.classify.accuracy(SVC_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>SVC_classifier accuracy percent: 82.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LinearSVC_classifier = SklearnClassifier(LinearSVC())</span><br><span class="line">LinearSVC_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"LinearSVC_classifier accuracy percent:"</span>,(nltk.classify.accuracy(LinearSVC_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>LinearSVC_classifier accuracy percent: 80.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NuSVC_classifier = SklearnClassifier(NuSVC())</span><br><span class="line">NuSVC_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"NuSVC_classifier accuracy percent:"</span>,(nltk.classify.accuracy(NuSVC_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>NuSVC_classifier accuracy percent: 82.0
</code></pre><h3 id="16-Combining-Algos-with-a-Vote"><a href="#16-Combining-Algos-with-a-Vote" class="headerlink" title="16. Combining Algos with a Vote"></a>16. Combining Algos with a Vote</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.classify <span class="keyword">import</span> ClassifierI</span><br><span class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mode</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VoteClassifier</span><span class="params">(ClassifierI)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *classifiers)</span>:</span></span><br><span class="line">        self._classifiers = classifiers</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(self, features)</span>:</span></span><br><span class="line">        votes = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self._classifiers:</span><br><span class="line">            v = c.classify(features)</span><br><span class="line">            votes.append(v)</span><br><span class="line">        <span class="keyword">return</span> mode(votes)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">confidence</span><span class="params">(self,features)</span>:</span></span><br><span class="line">        votes = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self._classifiers:</span><br><span class="line">            v = c.classify(features)</span><br><span class="line">            votes.append(v)</span><br><span class="line">        </span><br><span class="line">        choice_votes = votes.count(mode(votes))</span><br><span class="line">        conf = choice_votes / len(votes)</span><br><span class="line">        <span class="keyword">return</span> conf</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">voted_classifier = VoteClassifier(classifier,</span><br><span class="line">                                  MNB_classifier,</span><br><span class="line">                                  BNB_classifier,</span><br><span class="line">                                  LogisticRegression_classifier,</span><br><span class="line">                                  SGDClassifier_classifier,</span><br><span class="line">                                 <span class="comment">#SVC_classifier,视频中没有这个，况且如果不注释掉就会报统计错误，说有两个相同的值。</span></span><br><span class="line">                                 <span class="comment">#如： http://blog.csdn.net/dongfuguo/article/details/50163757 中 mode错误一般</span></span><br><span class="line">                                 LinearSVC_classifier,</span><br><span class="line">                                 NuSVC_classifier)</span><br><span class="line">print(<span class="string">"voted_classifier accuracy percent:"</span>,(nltk.classify.accuracy(voted_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>voted_classifier accuracy percent: 81.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">0</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">0</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: neg Confidence %: 100.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">1</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">1</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: pos Confidence %: 100.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">2</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">2</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: pos Confidence %: 100.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">3</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">3</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: neg Confidence %: 87.5
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">4</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">4</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: pos Confidence %: 100.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">5</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">5</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: neg Confidence %: 75.0
</code></pre><h3 id="17-Investigating-Bias"><a href="#17-Investigating-Bias" class="headerlink" title="17. Investigating Bias()"></a>17. Investigating Bias()</h3><h3 id="18-Better-training-data"><a href="#18-Better-training-data" class="headerlink" title="18. Better training data()"></a>18. Better training data()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">short_pos = open(<span class="string">"short_reviews/positive.txt"</span>,<span class="string">"r"</span>,encoding=<span class="string">"unicode-escape"</span>).read()</span><br><span class="line">short_neg = open(<span class="string">"short_reviews/negative.txt"</span>,<span class="string">"r"</span>,encoding=<span class="string">"unicode-escape"</span>).read()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">short_pos[:<span class="number">300</span>]</span><br></pre></td></tr></table></figure>
<pre><code>&apos;the rock is destined to be the 21st century\&apos;s new &quot; conan &quot; and that he\&apos;s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \nthe gorgeously elaborate continuation of &quot; the lord of the rings &quot; trilogy is so huge that a column of words cannot adequ&apos;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">documents = []</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># map(lambda r : document.append(r,'pos'), [r for r in short_pos.split('\n')])</span></span><br><span class="line"><span class="comment"># 本来想通过类似foreach实现类似的功能，不过好像并不能成功，目前原因还不清楚。</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">documents.extend([(r,<span class="string">"pos"</span>) <span class="keyword">for</span> r <span class="keyword">in</span> short_pos.split(<span class="string">'\n'</span>)])</span><br><span class="line"><span class="comment"># 和下面语句的作用是一样的，不过不知道哪个效率更高一些</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> short_pos.split(<span class="string">'\n'</span>):</span><br><span class="line">    documents.append((r,<span class="string">'pos'</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">documents[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<pre><code>(&apos;the rock is destined to be the 21st century\&apos;s new &quot; conan &quot; and that he\&apos;s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . &apos;,
 &apos;pos&apos;)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">documents.extend([(r,<span class="string">"neg"</span>) <span class="keyword">for</span> r <span class="keyword">in</span> short_neg.split(<span class="string">'\n'</span>)])</span><br><span class="line"><span class="comment"># 和下面语句的作用是一样的，不过不知道哪个效率更高一些</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> short_neg.split(<span class="string">'\n'</span>):</span><br><span class="line">    documents.append(w.lower())</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="comment"># 这里之所以再次导入，仅仅是因为我是几次使用这个notebook，懒得运行前面的cell了。</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_words = []</span><br><span class="line">short_pos_words = nltk.word_tokenize(short_pos)</span><br><span class="line">short_neg_words = nltk.word_tokenize(short_neg)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_words.extend([w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> short_pos_words])</span><br><span class="line">all_words.extend([w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> short_neg_words])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以上代码应该也可以写成：</span></span><br><span class="line">all_words = [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> short_pos_words] + [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> short_pos_words]</span><br><span class="line"><span class="comment">#甚至是这样：</span></span><br><span class="line">all_words = [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> short_pos_words+short_neg_words]</span><br><span class="line"><span class="comment"># 不过如果先：</span></span><br><span class="line">all_words = short_pos_words + short_neg_words</span><br><span class="line"><span class="comment"># 再：</span></span><br><span class="line">all_words = [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> all_words]</span><br><span class="line"><span class="comment"># 可能效率更高一些吧？</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stopwords = nltk.corpus.stopwords.words(<span class="string">'english'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_words = [w <span class="keyword">for</span> w <span class="keyword">in</span> all_words <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</span><br><span class="line"><span class="comment"># 我自己添加的去除停用词等无关信息，以使得特征提取和训练的效率更高</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_words = nltk.FreqDist(all_words)</span><br><span class="line">word_features = list(all_words.keys())[:<span class="number">5000</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_features</span><span class="params">(document)</span>:</span></span><br><span class="line">    words = nltk.word_tokenize(document)</span><br><span class="line">    features = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> word_features:</span><br><span class="line">        features[w] = (w <span class="keyword">in</span> words)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> features</span><br><span class="line">featuresets = [(find_features(rev), category) <span class="keyword">for</span> (rev, category) <span class="keyword">in</span> documents]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">random.shuffle(featuresets)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">training_set = featuresets[:<span class="number">10000</span>]</span><br><span class="line">testing_set = featuresets[<span class="number">10000</span>:]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">classifier = nltk.NaiveBayesClassifier.train(training_set)</span><br><span class="line">print(<span class="string">"Naive Bayes Algo accuracy:"</span>,(nltk.classify.accuracy(classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Naive Bayes Algo accuracy: 68.82530120481928
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.classify.scikitlearn <span class="keyword">import</span> SklearnClassifier</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB, GaussianNB, BernoulliNB</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MNB_classifier = SklearnClassifier(MultinomialNB())</span><br><span class="line">MNB_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"MNB_classifier accuracy percent:"</span>,(nltk.classify.accuracy(MNB_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>MNB_classifier accuracy percent: 67.46987951807229
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这段代码有问题，不可以运行</span></span><br><span class="line">GNB_classifier = SklearnClassifier(GaussianNB())</span><br><span class="line">GNB_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"GNB_classifier accuracy percent:"</span>,(nltk.classify.accuracy(GNB_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">BNB_classifier = SklearnClassifier(BernoulliNB())</span><br><span class="line">BNB_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"BNB_classifier accuracy percent:"</span>,(nltk.classify.accuracy(BNB_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>BNB_classifier accuracy percent: 68.97590361445783
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression, SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC, LinearSVC, NuSVC</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LogisticRegression_classifier = SklearnClassifier(LogisticRegression())</span><br><span class="line">LogisticRegression_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"LogisticRegression_classifier accuracy percent:"</span>,(nltk.classify.accuracy(LogisticRegression_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>LogisticRegression_classifier accuracy percent: 70.78313253012048
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SGDClassifier_classifier = SklearnClassifier(SGDClassifier())</span><br><span class="line">SGDClassifier_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"SGDClassifier_classifier accuracy percent:"</span>,(nltk.classify.accuracy(SGDClassifier_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>SGDClassifier_classifier accuracy percent: 66.1144578313253
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SVC_classifier = SklearnClassifier(SVC())</span><br><span class="line">SVC_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"SVC_classifier accuracy percent:"</span>,(nltk.classify.accuracy(SVC_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>SVC_classifier accuracy percent: 49.096385542168676
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LinearSVC_classifier = SklearnClassifier(LinearSVC())</span><br><span class="line">LinearSVC_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"LinearSVC_classifier accuracy percent:"</span>,(nltk.classify.accuracy(LinearSVC_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>LinearSVC_classifier accuracy percent: 70.48192771084338
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NuSVC_classifier = SklearnClassifier(NuSVC())</span><br><span class="line">NuSVC_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"NuSVC_classifier accuracy percent:"</span>,(nltk.classify.accuracy(NuSVC_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>NuSVC_classifier accuracy percent: 69.7289156626506
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.classify <span class="keyword">import</span> ClassifierI</span><br><span class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mode</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VoteClassifier</span><span class="params">(ClassifierI)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *classifiers)</span>:</span></span><br><span class="line">        self._classifiers = classifiers</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(self, features)</span>:</span></span><br><span class="line">        votes = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self._classifiers:</span><br><span class="line">            v = c.classify(features)</span><br><span class="line">            votes.append(v)</span><br><span class="line">        <span class="keyword">return</span> mode(votes)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">confidence</span><span class="params">(self,features)</span>:</span></span><br><span class="line">        votes = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self._classifiers:</span><br><span class="line">            v = c.classify(features)</span><br><span class="line">            votes.append(v)</span><br><span class="line">        </span><br><span class="line">        choice_votes = votes.count(mode(votes))</span><br><span class="line">        conf = choice_votes / len(votes)</span><br><span class="line">        <span class="keyword">return</span> conf</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">voted_classifier = VoteClassifier(classifier,</span><br><span class="line">                                  MNB_classifier,</span><br><span class="line">                                  BNB_classifier,</span><br><span class="line">                                  LogisticRegression_classifier,</span><br><span class="line">                                  SGDClassifier_classifier,</span><br><span class="line">                                 <span class="comment">#SVC_classifier,视频中没有这个，况且如果不注释掉就会报统计错误，说有两个相同的值。</span></span><br><span class="line">                                 <span class="comment">#如： http://blog.csdn.net/dongfuguo/article/details/50163757 中 mode错误一般</span></span><br><span class="line">                                 LinearSVC_classifier,</span><br><span class="line">                                 NuSVC_classifier)</span><br><span class="line">print(<span class="string">"voted_classifier accuracy percent:"</span>,(nltk.classify.accuracy(voted_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>voted_classifier accuracy percent: 69.42771084337349
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">0</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">0</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: pos Confidence %: 100.0
</code></pre><h3 id="19-Sentiment-Analysis-Module"><a href="#19-Sentiment-Analysis-Module" class="headerlink" title="19. Sentiment Analysis Module()"></a>19. Sentiment Analysis Module()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_words = []</span><br><span class="line">documents = []</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allowed_word_types = [<span class="string">"J"</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> short_pos.split(<span class="string">'\n'</span>):</span><br><span class="line">    documents.append((p,<span class="string">"pos"</span>))</span><br><span class="line">    words = nltk.word_tokenize(p)</span><br><span class="line">    pos = nltk.pos_tag(words)</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> pos:</span><br><span class="line">        <span class="keyword">if</span> w[<span class="number">1</span>][<span class="number">0</span>] <span class="keyword">in</span> allowed_word_types:</span><br><span class="line">            all_words.append(w[<span class="number">0</span>].lower())</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> short_neg.split(<span class="string">'\n'</span>):</span><br><span class="line">    documents.append((p,<span class="string">"neg"</span>))</span><br><span class="line">    words = nltk.word_tokenize(p)</span><br><span class="line">    neg = nltk.pos_tag(words)</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> neg:</span><br><span class="line">        <span class="keyword">if</span> w[<span class="number">1</span>][<span class="number">0</span>] <span class="keyword">in</span> allowed_word_types:</span><br><span class="line">            all_words.append(w[<span class="number">0</span>].lower())</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br></pre></td></tr></table></figure>
<p>提醒一下：直接运行以下的cell 会报错，应该先创建一个pickled_algos文件夹，然后再运行cell</p>
<p>保存文档</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_documents = open(<span class="string">'pickled_algos/documents.pickle'</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(documents, save_documents)</span><br><span class="line">save_documents.close()</span><br></pre></td></tr></table></figure>
<p>保存文本特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_words = nltk.FreqDist(all_words)</span><br><span class="line">word_features = list(all_words.keys())[:<span class="number">5000</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_word_features = open(<span class="string">'pickled_algos/word_features5k.pickle'</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(word_features,save_word_features)</span><br><span class="line">save_word_features.close()</span><br></pre></td></tr></table></figure>
<p>保存朴素贝叶斯算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">"pickled_algos/originalnaivebayes5k.pickle"</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<p>保存MultinomialNB算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">"pickled_algos/MNB_classifier5k.pickle"</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(MNB_classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<p>保存BernoulliNB算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">"pickled_algos/BNB_classifier5k.pickle"</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(BNB_classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<p>保存LogisticRegression算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">"pickled_algos/LogisticRegression_classifier5k.pickle"</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(LogisticRegression_classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<p>保存LinearSVC算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">"pickled_algos/LinearSVC_classifier5k.pickle"</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(LinearSVC_classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<p>保存SGDC算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">"pickled_algos/SGDClassifier_classifier5k.pickle"</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(SGDClassifier_classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">voted_classifier = VoteClassifier(classifier,</span><br><span class="line">                                 LinearSVC_classifier,</span><br><span class="line">                                 MNB_classifier,</span><br><span class="line">                                 BNB_classifier,</span><br><span class="line">                                 LogisticRegression_classifier)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentiment</span><span class="params">(text)</span>:</span></span><br><span class="line">    feats = find_features(text)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> voted_classifier.classify(feats)</span><br></pre></td></tr></table></figure>
<p>最终我们编写的模块长成这个样子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#File: sentiment_mod.py 只是一个文件名而已，可以按照自己的想法取，但应做到见名知意</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> nltk.classify.scikitlearn <span class="keyword">import</span> SklearnClassifier</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB,BernoulliNB</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression,SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC, LinearSVC,NuSVC</span><br><span class="line"><span class="keyword">from</span> nltk.classify <span class="keyword">import</span> ClassifierI</span><br><span class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mode</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以上许多类模块虽然在代码中看似并没有用到，可是在用pickle还原为相关实例在被外部调用执行的时候还是需要的。</span></span><br><span class="line"><span class="comment"># 这里由于我们之前已经训练好了几个分类器，并且已经将文档内容和文本特征等通过pickle持久化保存起来了，所以在此模块中直接用pickle还原就可以直接拿来用了，而不是再次训练。</span></span><br><span class="line"><span class="comment"># 并且该模块仅当同一路径下的pickled_algos文件夹及里面的各pickle文件同时存在时才可以正常使用，当然，项目中也要导入本模块需要使用的一些基础模块，如nltk等等。</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VoteClassifier</span><span class="params">(ClassifierI)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *classifiers)</span>:</span></span><br><span class="line">        self._classifiers = classifiers</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(self, features)</span>:</span></span><br><span class="line">        votes = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self._classifiers:</span><br><span class="line">            v = c.classify(features)</span><br><span class="line">            votes.append(v)</span><br><span class="line">        <span class="keyword">return</span> mode(votes)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">confidence</span><span class="params">(self,features)</span>:</span></span><br><span class="line">        votes = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self._classifiers:</span><br><span class="line">            v = c.classify(features)</span><br><span class="line">            votes.append(v)</span><br><span class="line">        </span><br><span class="line">        choice_votes = votes.count(mode(votes))</span><br><span class="line">        conf = choice_votes / len(votes)</span><br><span class="line">        <span class="keyword">return</span> conf </span><br><span class="line"></span><br><span class="line">documents_f = open(<span class="string">'pickled_algos/documents.pickle'</span>,<span class="string">"rb"</span>)</span><br><span class="line">documents = pickle.load(documents_f)</span><br><span class="line">documents_f.close()</span><br><span class="line"></span><br><span class="line">word_features5k_f = open(<span class="string">'pickled_algos/word_features5k.pickle'</span>,<span class="string">"rb"</span>)</span><br><span class="line">word_features = pickle.load(word_features5k_f)</span><br><span class="line">word_features5k_f.close()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_features</span><span class="params">(document)</span>:</span></span><br><span class="line">    words = nltk.word_tokenize(document)</span><br><span class="line">    features = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> word_features:</span><br><span class="line">        features[w] = (w <span class="keyword">in</span> words)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> features</span><br><span class="line"></span><br><span class="line">open_file = open(<span class="string">"pickled_algos/originalnaivebayes5k.pickle"</span>,<span class="string">"rb"</span>)</span><br><span class="line">classifier = pickle.load(open_file)</span><br><span class="line">open_file.close()</span><br><span class="line"></span><br><span class="line">open_file = open(<span class="string">"pickled_algos/MNB_classifier5k.pickle"</span>,<span class="string">"rb"</span>)</span><br><span class="line">MNB_classifier = pickle.load(open_file)</span><br><span class="line">open_file.close()</span><br><span class="line"></span><br><span class="line">open_file = open(<span class="string">"pickled_algos/BNB_classifier5k.pickle"</span>,<span class="string">"rb"</span>)</span><br><span class="line">BNB_classifier = pickle.load(open_file)</span><br><span class="line">open_file.close()</span><br><span class="line"></span><br><span class="line">open_file = open(<span class="string">"pickled_algos/LogisticRegression_classifier5k.pickle"</span>,<span class="string">"rb"</span>)</span><br><span class="line">LogisticRegression_classifier = pickle.load(open_file)</span><br><span class="line">open_file.close()</span><br><span class="line"></span><br><span class="line">open_file = open(<span class="string">"pickled_algos/LinearSVC_classifier5k.pickle"</span>,<span class="string">"rb"</span>)</span><br><span class="line">LinearSVC_classifier = pickle.load(open_file)</span><br><span class="line">open_file.close()</span><br><span class="line"></span><br><span class="line">open_file = open(<span class="string">"pickled_algos/SGDClassifier_classifier5k.pickle"</span>,<span class="string">"rb"</span>)</span><br><span class="line">SGDClassifier_classifier = pickle.load(open_file)</span><br><span class="line">open_file.close()</span><br><span class="line"></span><br><span class="line">voted_classifier = VoteClassifier(</span><br><span class="line">                                 classifier,</span><br><span class="line">                                 LinearSVC_classifier,</span><br><span class="line">                                 MNB_classifier,</span><br><span class="line">                                 BNB_classifier,</span><br><span class="line">                                 LogisticRegression_classifier)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentiment</span><span class="params">(text)</span>:</span></span><br><span class="line">    feats = find_features(text)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> voted_classifier.classify(feats),voted_classifier.confidence(feats)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save me as sentiment_mod.py</span></span><br></pre></td></tr></table></figure>
<p>下面来使用一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sentiment_mod <span class="keyword">as</span> s</span><br><span class="line"></span><br><span class="line">print(s.sentiment(<span class="string">"This movie was awesome! The acting was great, plot was wonderful, and there were pythons...so yea!"</span>))</span><br><span class="line"></span><br><span class="line">print(s.sentiment(<span class="string">"This movie was utter junk. There were absolutely 0 pythons. I don't see what the point was at all. Horrible movie, 0/10"</span>))</span><br></pre></td></tr></table></figure>
<pre><code>(&apos;pos&apos;, 1.0)
(&apos;neg&apos;, 1.0)
</code></pre><p>好吧，接下来的实践要使用Twitter 创建APP，可能还要使用个人网站，有点麻烦，所以接下来我只是看了看并没有照着实践。<br>总之，在这一系列的跟着敲代码的过程中，自己初步建立起了很浅的自然语言处理的概念~</p>
<h3 id="20-Twitter-Sentiment-Analysis"><a href="#20-Twitter-Sentiment-Analysis" class="headerlink" title="20. Twitter Sentiment Analysis()"></a>20. Twitter Sentiment Analysis()</h3><h3 id="21-Graphing-Live-Twitter-Sentiment"><a href="#21-Graphing-Live-Twitter-Sentiment" class="headerlink" title="21. Graphing Live Twitter Sentiment()"></a>21. Graphing Live Twitter Sentiment()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

      </div>
        
          <section class='meta' id="footer-meta">
            
              <time class="metatag time" itemprop="dateUpdated" datetime="2018-03-19T17:48:52+08:00" content="2018-03-19"><i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>
                &nbsp;2018-03-19
              </time>
            
            
                
                <div class="metatag tags"><a class="tag" href="/tags/Python/"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>&nbsp;Python</a></div> <div class="metatag tags"><a class="tag" href="/tags/自然语言处理/"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>&nbsp;自然语言处理</a></div> <div class="metatag tags"><a class="tag" href="/tags/NLTK/"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>&nbsp;NLTK</a></div>
            
            
              
  <div class='metatag share -mob-share-list'>
    <i class="left fas fa-share-alt fa-fw" aria-hidden="true"></i>
    <div class="-mob-share-list share-body">
      
        
          <a class="-mob-share-qq" title="QQ好友" rel="external nofollow noopener noreferrer"
            
            href="http://connect.qq.com/widget/shareqq/index.html?url=http://www.iamlightsmile.com/2018/03/19/learnNLTKbyWatchVideo/&title=learnNLTKbyWatchVideo | lightsmile's Blog&summary="
            
            >
            
              <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qq.png">
            
          </a>
        
      
        
          <a class="-mob-share-qzone" title="QQ空间" rel="external nofollow noopener noreferrer"
            
            href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://www.iamlightsmile.com/2018/03/19/learnNLTKbyWatchVideo/&title=learnNLTKbyWatchVideo | lightsmile's Blog&summary="
            
            >
            
              <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qzone.png">
            
          </a>
        
      
        
          <a class='qrcode' rel="external nofollow noopener noreferrer" href='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACtklEQVR42u3aQW4bQQwEQP//0wmQq6BVNzkTwUDpZEi2dmsPQ7rJn5/49effK3nn9f3XT19fz7//7orHXnh4eHijW3++8PPP7d/OSO118fDw8G7znotBcuubEvLu5hLqBwseHh7eV3l5a5s31m0/jIeHh/e7eM83lB/3SUOfP248PDy8b/GSQKH40rhszEhXshY8PDy8bt5U39B3f74438PDw8NbTNWTItFGtPvotrhbPDw8vAu8fGSVh7DPgPyd2TdHiTIeHh7egtce37OVqXzVoA0XPpQWPDw8vGu8ttndfLpZMshbcDw8PLx7vLYJzg/9WclpV7iiUoGHh4d3lDeLYtuFg3aoNuN92InAw8PDO8RLLpM3tbO1p1mMi4eHh/dd3n7ElbfURYhwKBrGw8PDu8Frj/v2ybUrXG0jHi1d4eHh4R3l5dFAO+LKQ9v8uB8233h4eHiHeO3Yvi0keTPdfk9ExcPDw7vGawfzbYM7CzKGaQoeHh7eZd5sQNWOx2aNex6ItIsIeHh4eBtefhzPRmL79n0VK+Ph4eFd4LVNc3vTbXlo1wtqJB4eHt6atykMyfE9fMZBWBwFvnh4eHgXePkIKi8bm6C2XeGK7goPDw/vAm+2LtAOus4GvsP/FfDw8PDWvHbYPwtkD6xPzdYF8PDw8K7x8kAhP+5nK61JA12UDTw8PLwLvPagb0dfeQN9qrS8jSHw8PDwDvHyX00O4qRs5I8gfyhRdIuHh4d3gXeszsSlYraSNSwMeHh4eId4ZxPRdhi2CR2GDDw8PLxDvLwYtO11XgByatu+4+Hh4d3jzQLZfNUgf1htAfjwV3h4eHhf5c2a703M0bbp9XwPDw8P77/w8q/eDLQ2RWtVGPDw8PCOhhEJJifd/k48PDy8e7xTA7D2AnnUuwmF8fDw8I7y/gICO3OoeM/f4gAAAABJRU5ErkJggg=='>
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/wechat.png">
          
          </a>
        
      
        
          <a class="-mob-share-weibo" title="微博" rel="external nofollow noopener noreferrer"
            
            href="http://service.weibo.com/share/share.php?url=http://www.iamlightsmile.com/2018/03/19/learnNLTKbyWatchVideo/&title=learnNLTKbyWatchVideo | lightsmile's Blog&summary="
            
            >
            
              <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/weibo.png">
            
          </a>
        
      
        
          <a class='qrcode' rel="external nofollow noopener noreferrer" href='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACtklEQVR42u3aQW4bQQwEQP//0wmQq6BVNzkTwUDpZEi2dmsPQ7rJn5/49effK3nn9f3XT19fz7//7orHXnh4eHijW3++8PPP7d/OSO118fDw8G7znotBcuubEvLu5hLqBwseHh7eV3l5a5s31m0/jIeHh/e7eM83lB/3SUOfP248PDy8b/GSQKH40rhszEhXshY8PDy8bt5U39B3f74438PDw8NbTNWTItFGtPvotrhbPDw8vAu8fGSVh7DPgPyd2TdHiTIeHh7egtce37OVqXzVoA0XPpQWPDw8vGu8ttndfLpZMshbcDw8PLx7vLYJzg/9WclpV7iiUoGHh4d3lDeLYtuFg3aoNuN92InAw8PDO8RLLpM3tbO1p1mMi4eHh/dd3n7ElbfURYhwKBrGw8PDu8Frj/v2ybUrXG0jHi1d4eHh4R3l5dFAO+LKQ9v8uB8233h4eHiHeO3Yvi0keTPdfk9ExcPDw7vGawfzbYM7CzKGaQoeHh7eZd5sQNWOx2aNex6ItIsIeHh4eBtefhzPRmL79n0VK+Ph4eFd4LVNc3vTbXlo1wtqJB4eHt6atykMyfE9fMZBWBwFvnh4eHgXePkIKi8bm6C2XeGK7goPDw/vAm+2LtAOus4GvsP/FfDw8PDWvHbYPwtkD6xPzdYF8PDw8K7x8kAhP+5nK61JA12UDTw8PLwLvPagb0dfeQN9qrS8jSHw8PDwDvHyX00O4qRs5I8gfyhRdIuHh4d3gXeszsSlYraSNSwMeHh4eId4ZxPRdhi2CR2GDDw8PLxDvLwYtO11XgByatu+4+Hh4d3jzQLZfNUgf1htAfjwV3h4eHhf5c2a703M0bbp9XwPDw8P77/w8q/eDLQ2RWtVGPDw8PCOhhEJJifd/k48PDy8e7xTA7D2AnnUuwmF8fDw8I7y/gICO3OoeM/f4gAAAABJRU5ErkJggg=='>
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qrcode.png">
          
          </a>
        
      
    </div>
  </div>


            
          </section>
        

        
            <div class="prev-next">
                
                    <section class="prev">
                        <span class="art-item-left">
                            <h6><i class="fas fa-chevron-left" aria-hidden="true"></i>&nbsp;上一页</h6>
                            <h4>
                                <a href="/2018/03/28/微信小程序探索随笔/" rel="prev" title="微信小程序的component">
                                  
                                      微信小程序的component
                                  
                                </a>
                            </h4>
                            
                                
                                <h6 class="tags">
                                    <a class="tag" href="/tags/微信小程序/"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>微信小程序</a>
                                </h6>
                            
                        </span>
                    </section>
                
                
                    <section class="next">
                        <span class="art-item-right" aria-hidden="true">
                            <h6>下一页&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                            <h4>
                                <a href="/2018/03/06/英文表达与写作练习宣告/" rel="prev" title="英文表达与写作练习宣告">
                                    
                                        英文表达与写作练习宣告
                                    
                                </a>
                            </h4>
                            
                        </span>
                    </section>
                
            </div>
        

    </section>

</article>

<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->


<br>

<!-- 显示推荐文章和评论 -->



  <article class="post white-box comments">
    <section class="article typo">

      
        

    <div class="recommended_posts">
        <h4><i class="fas fa-bookmark fa-fw" aria-hidden="true"></i>&nbsp;相关文章</h4>
        <ul>
            
                <li><a href="http://www.iamlightsmile.com/2018/04/06/Scrapy爬取知乎数据小试/">Scrapy爬取知乎数据小试</a></li>
            
                <li><a href="http://www.iamlightsmile.com/2018/03/28/微信小程序探索随笔/">微信小程序的component</a></li>
            
                <li><a href="http://www.iamlightsmile.com/2018/03/06/英文表达与写作练习宣告/">英文表达与写作练习宣告</a></li>
            
                <li><a href="http://www.iamlightsmile.com/2018/03/05/常见10种自然语言处理技术（转载）/">常见10种自然语言处理技术（转载）</a></li>
            
        </ul>
    </div>


      

      
    </section>
  </article>



<script>
    window.subData = {
        title: 'learnNLTKbyWatchVideo',
        tools: true
    }
</script>


        </div>
        <aside class='l_side'>
            
  
  
    
      
      
        <section class='author'>
  <div class='content pure'>
    
      <div class='avatar'>
        <img class='avatar' src='https://github.com/smilelight/images/raw/master/new_icon.jpg'/>
      </div>
    
    
      <div class='text'>
        
        
        
          <p><span id="jinrishici-sentence">lightsmile's Blog</span></p>
          <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
        
      </div>
    
    
      <div class="social-wrapper">
        
          
            <a href="mailto:iamlightsmile@qq.com" class="social flat-btn" target="_blank" rel="external"><i class="social fas fa-envelope" aria-hidden="true"></i></a>
          
        
          
            <a href="https://github.com/smilelight" class="social flat-btn" target="_blank" rel="external"><i class="social fab fa-github" aria-hidden="true"></i></a>
          
        
          
            <a href="https://music.163.com/m/user/home?id=515917285" class="social flat-btn" target="_blank" rel="external"><i class="social fas fa-music" aria-hidden="true"></i></a>
          
        
          
            <a href="https://www.zhihu.com/people/qian-xiao-80" class="social flat-btn" target="_blank" rel="external"><i class="social fab fa-zhihu" aria-hidden="true"></i></a>
          
        
      </div>
    
  </div>
</section>

      
    
  
    
      
      
        <section class='plain'>
  
<header class='pure'>
  <div><i class="fas fa-bullhorn fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;注意啦～</div>
  
    <a class="rightBtn" target="_blank"
    rel="external nofollow noopener noreferrer"
    href="https://xaoxuu.com/wiki/material-x/"
    title="https://xaoxuu.com/wiki/material-x/">
    <i class="fas fa-question-circle fa-fw"></i></a>
  
</header>

  <div class='content pure'>
    <p>本站使用 <a href="https://xaoxuu.com/wiki/material-x/">Material X</a> 作为主题，喜欢这个主题的朋友可以阅读文档进行安装哦，超喜欢的话还可以安利给身边的朋友哦～</p>

  </div>
</section>

      
    
  
    
      
      
        
  <section class='toc-wrapper'>
    
<header class='pure'>
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;文章目录</div>
  
    <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div>
  
</header>

    <div class='content pure'>
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#The-following-is-learning-from-the-video-NLTK-with-Python-3-for-Natural-Language-Processing"><span class="toc-text">The following is learning from the video:NLTK with Python 3 for Natural Language Processing.</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Tokenizing-words-and-entences-分词和分句"><span class="toc-text">1. Tokenizing words and entences(分词和分句)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Stop-Words-停用词"><span class="toc-text">2. Stop Words(停用词)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Stemming-提取词干"><span class="toc-text">3. Stemming(提取词干)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Part-of-speech-tagging-词性标注"><span class="toc-text">4. Part of speech tagging(词性标注)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-Chunking-短语识别"><span class="toc-text">5. Chunking(短语识别)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-Chinking-短语排除"><span class="toc-text">6. Chinking(短语排除)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-Named-Entity-Recognition-命名实体识别"><span class="toc-text">7. Named Entity Recognition(命名实体识别)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-Lemmatizing-词形还原"><span class="toc-text">8. Lemmatizing(词形还原)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-NLTK-Corpora-语料库"><span class="toc-text">9. NLTK Corpora(语料库)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-WordNet-一个英语词汇数据库"><span class="toc-text">10. WordNet(一个英语词汇数据库)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-Text-Classfication-文本分类"><span class="toc-text">11. Text Classfication(文本分类)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-Words-as-Features-for-Learning-用来学习的特征词汇"><span class="toc-text">12. Words as Features for Learning(用来学习的特征词汇)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-Naive-Bayes-朴素贝叶斯"><span class="toc-text">13. Naive Bayes(朴素贝叶斯)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-Save-Classifier-with-Pickle-使用Pickle保存分类器"><span class="toc-text">14. Save Classifier with Pickle(使用Pickle保存分类器)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-Scikit-Learn-incorporation"><span class="toc-text">15. Scikit-Learn incorporation()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-Combining-Algos-with-a-Vote"><span class="toc-text">16. Combining Algos with a Vote</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-Investigating-Bias"><span class="toc-text">17. Investigating Bias()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#18-Better-training-data"><span class="toc-text">18. Better training data()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#19-Sentiment-Analysis-Module"><span class="toc-text">19. Sentiment Analysis Module()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#20-Twitter-Sentiment-Analysis"><span class="toc-text">20. Twitter Sentiment Analysis()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#21-Graphing-Live-Twitter-Sentiment"><span class="toc-text">21. Graphing Live Twitter Sentiment()</span></a></li></ol></li></ol></li></ol>
    </div>
  </section>


      
    
  
    
      
      
        
  <section class='category'>
    
<header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;所有分类</div>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/Python/" href="/categories/Python/"><div class='name'>Python</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/lua/" href="/categories/lua/"><div class='name'>lua</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/哲学/" href="/categories/哲学/"><div class='name'>哲学</div><div class='badge'>(6)</div></a></li>
        
          <li><a class="flat-box" title="/categories/数学/" href="/categories/数学/"><div class='name'>数学</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/自然语言处理/" href="/categories/自然语言处理/"><div class='name'>自然语言处理</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/计算机/" href="/categories/计算机/"><div class='name'>计算机</div><div class='badge'>(2)</div></a></li>
        
      </ul>
    </div>
  </section>


      
    
  
    
      
      
        
  <section class='tagcloud'>
    
<header class='pure'>
  <div><i class="fas fa-fire fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;热门标签</div>
  
</header>

    <div class='content pure'>
      <a href="/tags/GitHub/" style="font-size: 14px; color: #999">GitHub</a> <a href="/tags/NLTK/" style="font-size: 14px; color: #999">NLTK</a> <a href="/tags/Python/" style="font-size: 20.67px; color: #6c6c6c">Python</a> <a href="/tags/Scrapy/" style="font-size: 14px; color: #999">Scrapy</a> <a href="/tags/github/" style="font-size: 14px; color: #999">github</a> <a href="/tags/ltp/" style="font-size: 14px; color: #999">ltp</a> <a href="/tags/lua/" style="font-size: 14px; color: #999">lua</a> <a href="/tags/markdown/" style="font-size: 14px; color: #999">markdown</a> <a href="/tags/哲学/" style="font-size: 24px; color: #555">哲学</a> <a href="/tags/图片绝对地址/" style="font-size: 14px; color: #999">图片绝对地址</a> <a href="/tags/微信小程序/" style="font-size: 14px; color: #999">微信小程序</a> <a href="/tags/抽象/" style="font-size: 14px; color: #999">抽象</a> <a href="/tags/数学/" style="font-size: 14px; color: #999">数学</a> <a href="/tags/概念/" style="font-size: 14px; color: #999">概念</a> <a href="/tags/浏览器插件/" style="font-size: 17.33px; color: #828282">浏览器插件</a> <a href="/tags/爬虫/" style="font-size: 14px; color: #999">爬虫</a> <a href="/tags/算法/" style="font-size: 17.33px; color: #828282">算法</a> <a href="/tags/统计学/" style="font-size: 14px; color: #999">统计学</a> <a href="/tags/自然语言处理/" style="font-size: 20.67px; color: #6c6c6c">自然语言处理</a>
    </div>
  </section>


      
    
  
    
      
      
        <section class='list'>
  
<header class='pure'>
  <div><i class="fas fa-medal fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;我的项目</div>
  
    <a class="rightBtn" target="_blank"
    rel="external nofollow noopener noreferrer"
    href="https://github.com/smilelight?tab=repositories"
    title="https://github.com/smilelight?tab=repositories">
    <i class="fas fa-arrow-right fa-fw"></i></a>
  
</header>

  <div class='content pure'>
    <ul class="entry">
      
        <li><a class="flat-box" title="https://github.com/smilelight/todolist/" href="https://github.com/smilelight/todolist/">
          <div class='name'>
            
              <i class="fas fa-cube fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;微计划日程管理
          </div>
          
            <div class='badge'>(微信小程序)</div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://github.com/smilelight/GithubImagePace/" href="https://github.com/smilelight/GithubImagePace/">
          <div class='name'>
            
              <i class="fas fa-cube fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;chrome插件
          </div>
          
            <div class='badge'>(chromium)</div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://github.com/smilelight/SchoolInfoPublishSystem/" href="https://github.com/smilelight/SchoolInfoPublishSystem/">
          <div class='name'>
            
              <i class="fas fa-heartbeat fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;校园信息发布系统
          </div>
          
            <div class='badge'>(Android)</div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://github.com/smilelight/MyShoppingWeb/" href="https://github.com/smilelight/MyShoppingWeb/">
          <div class='name'>
            
              <i class="fas fa-cube fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;网上购物系统
          </div>
          
            <div class='badge'>(aardio)</div>
          
        </a></li>
      
    </ul>
  </div>
</section>

      
    
  
    
      
      
        <section class='list'>
  
<header class='pure'>
  <div><i class="fas fa-link fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;特别链接</div>
  
</header>

  <div class='content pure'>
    <ul class="entry">
      
        <li><a class="flat-box" title="https://www.iamlightsmile.com/about/" href="https://www.iamlightsmile.com/about/">
          <div class='name'>
            
              <i class="fas fa-comment-dots fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;关于我 / 留言板
          </div>
          
        </a></li>
      
    </ul>
  </div>
</section>

      
    
  
    
      
      
        


  <section class='music'>
    
<header class='pure'>
  <div><i class="fas fa-compact-disc fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;最近在听</div>
  
    <a class="rightBtn" target="_blank"
    rel="external nofollow noopener noreferrer"
    href="https://music.163.com/m/user/home?id=515917285"
    title="https://music.163.com/m/user/home?id=515917285">
    <i class="far fa-heart fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.css">
  <div class="aplayer"
    data-theme="#1BCDFC"
    
    
    data-mode="circulation"
    data-server="netease"
    data-type="playlist"
    data-id="2384415913"
    data-volume="0.7">
  </div>
  <script src="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/meting@1.1.0/dist/Meting.min.js"></script>


    </div>
  </section>


      
    
  


        </aside>
        <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
    </div>
    <footer id="footer" class="clearfix">
  
    <div class="social-wrapper">
      
        
          <a href="mailto:iamlightsmile@qq.com" class="social fas fa-envelope flat-btn" target="_blank" rel="external"></a>
        
      
        
          <a href="https://github.com/smilelight" class="social fab fa-github flat-btn" target="_blank" rel="external"></a>
        
      
        
          <a href="https://music.163.com/m/user/home?id=515917285" class="social fas fa-music flat-btn" target="_blank" rel="external"></a>
        
      
        
          <a href="https://www.zhihu.com/people/qian-xiao-80" class="social fab fa-zhihu flat-btn" target="_blank" rel="external"></a>
        
      
    </div>
  
  <br>
  <div><p>博客内容遵循 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
  <div>本站使用 <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material X</a> 作为主题，总访问量为 <span id="busuanzi_value_site_pv"><i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span> 次。
  </div>
</footer>

    <script>setLoadingBarProgress(80);</script>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js"></script>

  <script>
    var GOOGLE_CUSTOM_SEARCH_API_KEY = "";
    var GOOGLE_CUSTOM_SEARCH_ENGINE_ID = "";
    var ALGOLIA_API_KEY = "";
    var ALGOLIA_APP_ID = "";
    var ALGOLIA_INDEX_NAME = "";
    var AZURE_SERVICE_NAME = "";
    var AZURE_INDEX_NAME = "";
    var AZURE_QUERY_KEY = "";
    var BAIDU_API_ID = "";
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/"||"/";
    if(!ROOT.endsWith('/'))ROOT += '/';
  </script>


  
    <script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
    <script type="text/javascript">
      $(function() {
        const $reveal = $('.reveal');
    		if ($reveal.length === 0) return;
    		const sr = ScrollReveal({ distance: 0 });
    		sr.reveal('.reveal');
      });
    </script>
  
  
    <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
    <script type="text/javascript">
      $(function() {
        Waves.attach('.flat-btn', ['waves-button']);
        Waves.attach('.float-btn', ['waves-button', 'waves-float']);
        Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
        Waves.attach('.flat-box', ['waves-block']);
        Waves.attach('.float-box', ['waves-block', 'waves-float']);
        Waves.attach('.waves-image');
        Waves.init();
      });
    </script>
  
  
    <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>
  
  
  


  
  
  
  
    
    <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@1.0/js/app.js"></script>
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@1.0/js/search.js"></script>
    
  






    <script>setLoadingBarProgress(100);</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
