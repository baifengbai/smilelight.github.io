<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  <title>Archives: 2018/3 | lightsmile&#39;s Blog</title>
  
  <meta name="keywords" content="Python,哲学,NLP,自然语言处理,lightsmile,李德方">
  
  
  <meta name="description" content="this is a description">
  

  <link rel="alternate" href="/atom.xml" title="lightsmile's Blog">

  <meta name="HandheldFriendly" content="True" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  
  
  <meta name="theme-color" content="#f24e32">
  
  <meta name="msapplication-TileColor" content="#f24e32">
  
  <meta name="msapplication-config" content="https://cdn.jsdelivr.net/gh/xaoxuu/assets@18.12.27/favicon/favicons/browserconfig.xml">
  
  
  <!-- link -->
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.6.3/css/all.min.css">

  
  
  <link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@18.12.27/favicon/favicon.ico"
   type="image/x-icon"
  
  
  
  >
  
  <link rel="icon" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@18.12.27/favicon/favicons/favicon-32x32.png"
   type="image/x-icon"
   sizes="32x32"
  
  
  >
  
  <link rel="apple-touch-icon" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@18.12.27/favicon/favicons/apple-touch-icon.png"
   type="image/png"
   sizes="180x180"
  
  
  >
  
  <link rel="mask-icon" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@18.12.27/favicon/favicons/safari-pinned-tab.svg"
  
  
  
  
   color="#f24e32">
  
  <link rel="manifest" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@18.12.27/favicon/favicons/site.webmanifest"
  
  
  
  
  >
  
  

  
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@1.0/css/style.css">
    
  

  



  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
    <!-- ga -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', '131799461', 'www.iamlightsmile.com');
      ga('send', 'pageview');
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  
  
</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="loading-bar-wrapper">
  <div id="loading-bar" class="pure"></div>
</div>

    <script>setLoadingBarProgress(20)</script>
    <header class="l_header pure">
	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" href='/' >
        
          lightsmile's Blog
        
      </a>
			<div class='menu'>
				<ul class='h-list'>
          
  					
  						<li>
								<a id="https:www.iamlightsmile.com"
								 class="nav flat-box" href="https://www.iamlightsmile.com/">
									<i class='fas fa-home fa-fw'></i>&nbsp;主页
								</a>
							</li>
      			
  						<li>
								<a id="home"
								 class="nav flat-box" href="/">
									<i class='fas fa-rss fa-fw'></i>&nbsp;博客
								</a>
							</li>
      			
  						<li>
								<a id="archives"
								 class="nav flat-box" href="/archives/">
									<i class='fas fa-archive fa-fw'></i>&nbsp;归档
								</a>
							</li>
      			
  						<li>
								<a id="friends"
								 class="nav flat-box" href="/friends/">
									<i class='fas fa-users fa-fw'></i>&nbsp;朋友
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="搜索" />
						<span class="icon"><i class="fas fa-search fa-fw"></i></span>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" href='javascript:void(0)'></a></li>
				<li class='s-toc'><a class="flat-btn fas fa-list fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu">
      <ul>
          
              
                  <li>
										<a id="https:www.iamlightsmile.com" class="nav flat-box" href="https://www.iamlightsmile.com/">
											<i class='fas fa-home fa-fw'></i>&nbsp;主页
										</a>
                  </li>
              
                  <li>
										<a id="home" class="nav flat-box" href="/">
											<i class='fas fa-rss fa-fw'></i>&nbsp;博客
										</a>
                  </li>
              
                  <li>
										<a id="archives" class="nav flat-box" href="/archives/">
											<i class='fas fa-archive fa-fw'></i>&nbsp;归档
										</a>
                  </li>
              
                  <li>
										<a id="friends" class="nav flat-box" href="/friends/">
											<i class='fas fa-users fa-fw'></i>&nbsp;朋友
										</a>
                  </li>
              
       
      </ul>
		</nav>
    </header>
	</aside>

    <script>setLoadingBarProgress(40);</script>
    <div class="l_body">
    <div class='container clearfix'>
        <div class='l_main'>
            
	
    <script>
        window.subData= { title:'year : 2018.3'}
    </script>


<section class="post-list">
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        <div class='post-wrapper'>
          <article class="post reveal ">
    
<section class='meta'>
  
  <div class="meta" id="header-meta">
    
      <h2 class="title">
          <a href="/2018/03/28/微信小程序探索随笔/">
              
                  微信小程序的component
              
          </a>
      </h2>
    

    
      <time class="metatag time">
        <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;2018-03-28
      </time>
    

    
      
    
    <div class='metatag cats'>
        <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;<a class="categories" href="/categories/计算机/">计算机</a>
    </div>


    

    

    

  </div>
</section>

    <section class="article typo">
        <ol>
<li><p>我发现无法直接在样式即wxss里通过color属性设置icon组件的颜色，是无效的，只能通过在wxml里设置它的color属性为js传入的变量值或者是通过变量值来控制具体的颜色值。</p>
</li>
<li><p>我们可以将微信小程序中的components组件视为一个对象，没错，它本来就是一个对象，只是相对而言，它的初始化方法和设置方式不同于在一般的js语言中，它的data属性里是这个对象建立时初始化时的数据，作用域和生命周期伴随着component对象实例，而properties属性效果类似，均可以在component对象内部的函数和方法中使用this.data获取到，只是相对而言，data的数据是组件内部的数据，它是属于组件本身的属性，从设计上讲不取决于外部的应用场景；而properties属性则是暴露在组件外部的属性，它的作用相当于一般的编程语言中我们在new一个对象时做的初始化工作如new People(name=”lightsmile”,sex = false)，也就是说组件的一些业务属性是要通过这些属性接口来实现的，它是根据场景所制订的，具体实例体现在如：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">order-by</span> <span class="attr">bindtap</span>=<span class="string">"handOrderTap"</span> <span class="attr">id</span>=<span class="string">"fuck"</span> <span class="attr">test</span>=<span class="string">"&#123;&#123;5&#125;&#125;"</span> <span class="attr">data-tes</span>=<span class="string">"&#123;&#123;test&#125;&#125;"</span> <span class="attr">data-fuck</span>=<span class="string">"fuck"</span> <span class="attr">data-order</span>=<span class="string">"&#123;&#123;orders&#125;&#125;"</span> <span class="attr">data-</span>&gt;</span><span class="tag">&lt;/<span class="name">order-by</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>中id是每个标签都具有的值，而以“data-”开头的数据都是这个页面中，暴露给触发事件的值，在事件处理函数中，可以通过如</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">handOrderTap(e) &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(e)</span><br><span class="line">    <span class="built_in">console</span>.log(e.currentTarget.id)</span><br><span class="line">    <span class="keyword">this</span>.fuck = <span class="keyword">this</span>.selectComponent(<span class="string">"#fuck"</span>)</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="keyword">this</span>.fuck.data)</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="keyword">this</span>.fuck.dataset)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>获取到e（event）事件的具体信息，这里的handOrderTag只是自定义的函数，e.target和e.currentTarget分别代表不同的对象。</p>
<p>其中target是指事件的原触发对象，而currentTarget是指当前事件的触发对象，这是与事件的冒泡捕获机制相关的。</p>
<p>而不以“data-”开头，也不是如class、id、style等其他的属性如在上例中属性名为test的是页面传递给组件对象的信息，这里的test对应着组件对象之前设定的test属性，即在2中提到的暴露的属性名</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/wxapp_component/Image1.png" alt="Image1" title="">
                </div>
                <div class="image-caption">Image1</div>
            </figure>
<p>而“=”号后面的“”和“”则均是属于当前页面的逻辑层Page对象内部的数据，即this.data.test和this.tata.orders（其中的this指代的是当前对象），也就是说，在与Component组件或页面Page对象对应的wxml中，其中的永远都是指的当前组件或页面对象，无法外指和内值，即在Component对应wxml中无法引用外部Page的对象（这个很合理，因为组件本来就是要被复用的，不应该出现还可以引用外部的数据的情况），Page对应的wxml中也无法引用内部Component对象的内部属性，而如果要使用内部的值，一种方法是内部定义触发的方法然后再使用如this.triggerEvent(‘change’, this)<br>触发外部的change事件，这样组件外部就可以使用bindchange=”方法名”进行handle处理了。<br>如下几个阶段：</p>
<pre><code>1. 在Page的wxml中使用组件order-by,绑定了自定义事件MyEvent，这样在MyEvent事件被触发时，Page对象的handleMyEvent方法就会被执行。
</code></pre><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/wxapp_component/Image2.png" alt="Image2" title="">
                </div>
                <div class="image-caption">Image2</div>
            </figure>
<pre><code>2. handleMyEvent方法的内容如下：
</code></pre><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/wxapp_component/Image3.png" alt="Image3" title="">
                </div>
                <div class="image-caption">Image3</div>
            </figure>
<pre><code>3.Component的wxml中的text组件绑定tap事件到Component对象的myEvent方法
</code></pre><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/wxapp_component/Image4.png" alt="Image4" title="">
                </div>
                <div class="image-caption">Image4</div>
            </figure>
<pre><code>4.myEvent方法的内容如下：
</code></pre><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/wxapp_component/Image5.png" alt="Image5" title="">
                </div>
                <div class="image-caption">Image5</div>
            </figure>
<p>因此整个的流程应当为：当我点击text文本的时候，会触发tap事件，这样它绑定的myEvent方法会被执行，然后方法内部又会主动引发MyEvent事件，这样在Page页面对其绑定的handleMyEvent方法会被执行，而该方法定义在Page对象内部。（注意不要搞混事件和方法，虽然我这里的名字比较混乱）控制台输出的结果为：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/wxapp_component/Image6.png" alt="Image6" title="">
                </div>
                <div class="image-caption">Image6</div>
            </figure>
<p>即先触发tap事件，再触发MyEvent自定义事件，下面我们来看一看内部传递的东西：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/wxapp_component/Image7.png" alt="Image7" title="">
                </div>
                <div class="image-caption">Image7</div>
            </figure>
<p>从中我们可以发现第一个事件e的currentTarget属性的dataset属性是一个空对象，对应着我们并没有在wxml的text组件内部填写“data-xx”属性，而第二个事件e的currentTarget属性的dataset属性是一个包含了fuck、order、tes三个属性的对象，尽管其中order和tes的内容为空（因为对应的数据在Page对象中没有，我错误的写成了Component对象内部的了，发现获取不到，这才有了这篇文章）。</p>
<p>因此一般情况下，我们可以通过这种事件的方式来实现数据的传递工作，并且 this.triggerEvent() 方法接收自定义事件名称外，还接收两个对象，eventDetail 和 eventOptions。这也就是说，我们完全可以不传递this，而传递任意自己定义的对象数据，比如在myEvent中我可以不传this，接着传e，我也可以定义只与业务相关的数据对象来处理，由于方法定义在页面或组件对象内部，可以访问内部数据，而通过事件传递后可以通过参数访问数据，以此就实现了组件向页面的数据传递工作。</p>
<p>当然，这样的一个特点是事件绑定是放在视图view层，而事件处理传递是放在逻辑js层，可能在做一些其他业务时还是需要相应的业务转化工作才可以，不够直接和方便，因为页面还是无法做到直接访问组件数据。</p>
<p>后来发现果然页面提供了这么一个方法：this.selectComponent(“#fuck”)<br>可以在页面js中使用selectComponent选择某个component组件对象的实例，在此之上可以继续访问到它的data属性、dataset属性和properties属性，分别对应的是组件的properties属性、data属性和properties属性，如下图所示：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/wxapp_component/Image8.png" alt="Image8" title="">
                </div>
                <div class="image-caption">Image8</div>
            </figure>
<p>这里我们将组件的id设为fuck，handleOrderTap方法的内容如下：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/wxapp_component/Image9.png" alt="Image9" title="">
                </div>
                <div class="image-caption">Image9</div>
            </figure>
<p>打印的内容为：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/wxapp_component/Image10.png" alt="Image10" title="">
                </div>
                <div class="image-caption">Image10</div>
            </figure>
<p>我们可以发现它的id是自己定义的fuck,而is是项目的绝对路径，还有上面提到的data、properties、dataset属性（显而易见，properties和data属性指向同一个属性对象）（然而，经过测试发现虽然内容相同，不过并非指向同一个对象，如下图所示：真是奇了怪了。。。）。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/wxapp_component/Image11.png" alt="Image11" title="">
                </div>
                <div class="image-caption">Image11</div>
            </figure>
<p>如果打开<strong>proto</strong>属性，会发现更多的东西，比如说方法：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/wxapp_component/Image12.png" alt="Image12" title="">
                </div>
                <div class="image-caption">Image12</div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/wxapp_component/Image13.png" alt="Image13" title="">
                </div>
                <div class="image-caption">Image13</div>
            </figure>
<p>通过this.fuck.loghaha()即可完成对方法的调用，当然了，这里获取完全可以写成let fuck = this.selectComponent(“#fuck”)，然后通过fuck.loghaha()来调用，这里简单沿袭了网上搜的文章的实例。以上，也算自己学习的小经历总结吧。</p>

        

        
            <div class="full-width auto-padding tags">
                
                    <a href="/tags/微信小程序/"><i class="fas fa-hashtag fa-fw"></i>微信小程序</a>
                
            </div>
        
    </section>
</article>

        </div>
      
    
      
        <div class='post-wrapper'>
          <article class="post reveal ">
    
<section class='meta'>
  
  <div class="meta" id="header-meta">
    
      <h2 class="title">
          <a href="/2018/03/19/learnNLTKbyWatchVideo/">
              
                  learnNLTKbyWatchVideo
              
          </a>
      </h2>
    

    
      <time class="metatag time">
        <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;2018-03-19
      </time>
    

    
      
    
    <div class='metatag cats'>
        <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;<a class="categories" href="/categories/计算机/">计算机</a>
    </div>


    

    

    

  </div>
</section>

    <section class="article typo">
        <h1 id="The-following-is-learning-from-the-video-NLTK-with-Python-3-for-Natural-Language-Processing"><a href="#The-following-is-learning-from-the-video-NLTK-with-Python-3-for-Natural-Language-Processing" class="headerlink" title="The following is learning from the video:NLTK with Python 3 for Natural Language Processing."></a>The following is learning from the video:NLTK with Python 3 for Natural Language Processing.</h1><p>You can watch the videos in YouTube,iliibili and the author’s website: <a href="http://pythonprogramming.net" target="_blank" rel="noopener">pythonprogramming.net</a></p>
<p>I use jupyter notebook to write and run the python code,the python version is 3.4.4.</p>
<p>Frist,we need to import the <code>nltk</code> module to use it</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> sent_tokenize,word_tokenize</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">r"hello,how are you! I am lightsmile. My github link is www.github.com/smilelight. My persoanl website is www.iamlightsmile.com"</span></span><br></pre></td></tr></table></figure>
<h3 id="1-Tokenizing-words-and-entences-分词和分句"><a href="#1-Tokenizing-words-and-entences-分词和分句" class="headerlink" title="1. Tokenizing words and entences(分词和分句)"></a>1. Tokenizing words and entences(分词和分句)</h3><p>use the <code>sent_tokenize</code> method to tokenize the texts to sentenses(分句)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sent_tokenize(text)</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;hello,how are you!&apos;,
 &apos;I am lightsmile.&apos;,
 &apos;My github link is www.github.com/smilelight.&apos;,
 &apos;My persoanl website is www.iamlightsmile.com&apos;]
</code></pre><p>use the <code>word_tokenize</code> method to tokenize the texts to words(分词)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">word_tokenize(text)</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;hello&apos;,
 &apos;,&apos;,
 &apos;how&apos;,
 &apos;are&apos;,
 &apos;you&apos;,
 &apos;!&apos;,
 &apos;I&apos;,
 &apos;am&apos;,
 &apos;lightsmile&apos;,
 &apos;.&apos;,
 &apos;My&apos;,
 &apos;github&apos;,
 &apos;link&apos;,
 &apos;is&apos;,
 &apos;www.github.com/smilelight&apos;,
 &apos;.&apos;,
 &apos;My&apos;,
 &apos;persoanl&apos;,
 &apos;website&apos;,
 &apos;is&apos;,
 &apos;www.iamlightsmile.com&apos;]
</code></pre><h3 id="2-Stop-Words-停用词"><a href="#2-Stop-Words-停用词" class="headerlink" title="2. Stop Words(停用词)"></a>2. Stop Words(停用词)</h3><p>Then,import the <code>stopwords</code>(停用词) from the <code>nltk.corpus</code> module</p>
<p>The stopwords are the words which are used commonly in the daliy life but usefulless for we to analyze the texts,so we need to remove them from the texts before we do the next steps.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">example_sentense = <span class="string">"This is an example showing off stop word filtration"</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">filter_sentense = [w <span class="keyword">for</span> w <span class="keyword">in</span> word_tokenize(example_sentense) <span class="keyword">if</span>  w <span class="keyword">not</span> <span class="keyword">in</span> stopwords.words(<span class="string">'english'</span>)]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">filter_sentense</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;This&apos;, &apos;example&apos;, &apos;showing&apos;, &apos;stop&apos;, &apos;word&apos;, &apos;filtration&apos;]
</code></pre><h3 id="3-Stemming-提取词干"><a href="#3-Stemming-提取词干" class="headerlink" title="3. Stemming(提取词干)"></a>3. Stemming(提取词干)</h3><p>Use <code>PorterStemmer()</code> to get the stems of words(提取词干)</p>
<p>In some situations there are different expressions which have the same meanings.For example,the words:good,better,well have the similar meanings in the most situations.So,on the purpose to simplify the texts,we can get the stems of words in the texts. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> PorterStemmer</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ps = PorterStemmer()</span><br><span class="line">example_words = [<span class="string">"python"</span>,<span class="string">"pythoner"</span>,<span class="string">"pythoning"</span>,<span class="string">"pythoned"</span>,<span class="string">"pythonly"</span>]</span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> example_words:</span><br><span class="line">    print(ps.stem(w))</span><br></pre></td></tr></table></figure>
<pre><code>python
python
python
python
pythonli
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">new_text = <span class="string">"It is very important to be pythonly while you are pythoning with python. All pythoners have pythoned poorly at least once."</span></span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> word_tokenize(new_text):</span><br><span class="line">    print(ps.stem(w))</span><br></pre></td></tr></table></figure>
<pre><code>It
is
veri
import
to
be
pythonli
while
you
are
python
with
python
.
all
python
have
python
poorli
at
least
onc
.
</code></pre><h3 id="4-Part-of-speech-tagging-词性标注"><a href="#4-Part-of-speech-tagging-词性标注" class="headerlink" title="4. Part of speech tagging(词性标注)"></a>4. Part of speech tagging(词性标注)</h3><p>Use pos_tag method to do part of speech tagging(词性标注)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tagged = nltk.pos_tag(word_tokenize(new_text))</span><br><span class="line">print(tagged)</span><br></pre></td></tr></table></figure>
<pre><code>[(&apos;It&apos;, &apos;PRP&apos;), (&apos;is&apos;, &apos;VBZ&apos;), (&apos;very&apos;, &apos;RB&apos;), (&apos;important&apos;, &apos;JJ&apos;), (&apos;to&apos;, &apos;TO&apos;), (&apos;be&apos;, &apos;VB&apos;), (&apos;pythonly&apos;, &apos;RB&apos;), (&apos;while&apos;, &apos;IN&apos;), (&apos;you&apos;, &apos;PRP&apos;), (&apos;are&apos;, &apos;VBP&apos;), (&apos;pythoning&apos;, &apos;VBG&apos;), (&apos;with&apos;, &apos;IN&apos;), (&apos;python&apos;, &apos;NN&apos;), (&apos;.&apos;, &apos;.&apos;), (&apos;All&apos;, &apos;DT&apos;), (&apos;pythoners&apos;, &apos;NNS&apos;), (&apos;have&apos;, &apos;VBP&apos;), (&apos;pythoned&apos;, &apos;VBN&apos;), (&apos;poorly&apos;, &apos;RB&apos;), (&apos;at&apos;, &apos;IN&apos;), (&apos;least&apos;, &apos;JJS&apos;), (&apos;once&apos;, &apos;RB&apos;), (&apos;.&apos;, &apos;.&apos;)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[w <span class="keyword">for</span> w,t <span class="keyword">in</span> tagged <span class="keyword">if</span> t == <span class="string">'RB'</span> ]</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;very&apos;, &apos;pythonly&apos;, &apos;poorly&apos;, &apos;once&apos;]
</code></pre><h3 id="5-Chunking-短语识别"><a href="#5-Chunking-短语识别" class="headerlink" title="5. Chunking(短语识别)"></a>5. Chunking(短语识别)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chunkGram = <span class="string">r"""Chunk: &#123;&lt;RB.?&gt;*&lt;VB.?&gt;*&lt;NNP&gt;*&lt;NN&gt;&#125;"""</span></span><br><span class="line">chunkParser = nltk.RegexpParser(chunkGram)</span><br><span class="line">chunked = chunkParser.parse(tagged)</span><br><span class="line">print(chunked)</span><br></pre></td></tr></table></figure>
<pre><code>(S
  It/PRP
  is/VBZ
  very/RB
  important/JJ
  to/TO
  be/VB
  pythonly/RB
  while/IN
  you/PRP
  are/VBP
  pythoning/VBG
  with/IN
  (Chunk python/NN)
  ./.
  All/DT
  pythoners/NNS
  have/VBP
  pythoned/VBN
  poorly/RB
  at/IN
  least/JJS
  once/RB
  ./.)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chunked.draw()</span><br></pre></td></tr></table></figure>
<h3 id="6-Chinking-短语排除"><a href="#6-Chinking-短语排除" class="headerlink" title="6. Chinking(短语排除)"></a>6. Chinking(短语排除)</h3><p>The chinking is used to chunk something expect the chinking things.It’s effect is to remove something.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">chinkGram = <span class="string">r"""Chunk: &#123;&lt;.*&gt;&#125;</span></span><br><span class="line"><span class="string">                                           Chink: &#125;&lt;NN&gt;&#123;"""</span></span><br><span class="line">chinkParser = nltk.RegexpParser(chinkGram)</span><br><span class="line">chinked = chinkParser.parse(tagged)</span><br><span class="line">print(chinked)</span><br></pre></td></tr></table></figure>
<pre><code>(S
  (Chunk It/PRP)
  (Chunk is/VBZ)
  (Chunk very/RB)
  (Chunk important/JJ)
  (Chunk to/TO)
  (Chunk be/VB)
  (Chunk pythonly/RB)
  (Chunk while/IN)
  (Chunk you/PRP)
  (Chunk are/VBP)
  (Chunk pythoning/VBG)
  (Chunk with/IN)
  (Chunk python/NN)
  (Chunk ./.)
  (Chunk All/DT)
  (Chunk pythoners/NNS)
  (Chunk have/VBP)
  (Chunk pythoned/VBN)
  (Chunk poorly/RB)
  (Chunk at/IN)
  (Chunk least/JJS)
  (Chunk once/RB)
  (Chunk ./.))
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chinked.draw()</span><br></pre></td></tr></table></figure>
<h3 id="7-Named-Entity-Recognition-命名实体识别"><a href="#7-Named-Entity-Recognition-命名实体识别" class="headerlink" title="7. Named Entity Recognition(命名实体识别)"></a>7. Named Entity Recognition(命名实体识别)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">new_text2 = <span class="string">"The Obama,president of the United States,is walking by the Danube with his families.They'll go back home at 7:00 a.m.."</span></span><br><span class="line">tagged2 = nltk.pos_tag(word_tokenize(new_text2))</span><br><span class="line">nameEnt = nltk.ne_chunk(tagged2)</span><br><span class="line">nameEnt.draw()</span><br></pre></td></tr></table></figure>
<h3 id="8-Lemmatizing-词形还原"><a href="#8-Lemmatizing-词形还原" class="headerlink" title="8. Lemmatizing(词形还原)"></a>8. Lemmatizing(词形还原)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line">lemmatizer = WordNetLemmatizer()</span><br><span class="line">entities = [<span class="string">"cats"</span>,<span class="string">"body"</span>,<span class="string">"shoes"</span>,<span class="string">"python"</span>,<span class="string">"shit"</span>,<span class="string">"park"</span>]</span><br><span class="line"><span class="keyword">for</span> entity <span class="keyword">in</span> entities:</span><br><span class="line">    print(lemmatizer.lemmatize(entity))</span><br></pre></td></tr></table></figure>
<pre><code>cat
body
shoe
python
shit
park
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nltk.__file__</span><br></pre></td></tr></table></figure>
<pre><code>&apos;C:\\Program Files\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py&apos;
</code></pre><h3 id="9-NLTK-Corpora-语料库"><a href="#9-NLTK-Corpora-语料库" class="headerlink" title="9. NLTK Corpora(语料库)"></a>9. NLTK Corpora(语料库)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> gutenberg</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> sent_tokenize</span><br><span class="line">sample = gutenberg.raw(<span class="string">'bible-kjv.txt'</span>)</span><br><span class="line">tok = sent_tokenize(sample)</span><br><span class="line">tok[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;[The King James Bible]\n\nThe Old Testament of the King James Bible\n\nThe First Book of Moses:  Called Genesis\n\n\n1:1 In the beginning God created the heaven and the earth.&apos;,
 &apos;1:2 And the earth was without form, and void; and darkness was upon\nthe face of the deep.&apos;,
 &apos;And the Spirit of God moved upon the face of the\nwaters.&apos;,
 &apos;1:3 And God said, Let there be light: and there was light.&apos;,
 &apos;1:4 And God saw the light, that it was good: and God divided the light\nfrom the darkness.&apos;]
</code></pre><h3 id="10-WordNet-一个英语词汇数据库"><a href="#10-WordNet-一个英语词汇数据库" class="headerlink" title="10. WordNet(一个英语词汇数据库)"></a>10. WordNet(一个英语词汇数据库)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> wordnet</span><br><span class="line">syns = wordnet.synsets(<span class="string">"program"</span>)</span><br><span class="line">syns</span><br></pre></td></tr></table></figure>
<pre><code>[Synset(&apos;plan.n.01&apos;),
 Synset(&apos;program.n.02&apos;),
 Synset(&apos;broadcast.n.02&apos;),
 Synset(&apos;platform.n.02&apos;),
 Synset(&apos;program.n.05&apos;),
 Synset(&apos;course_of_study.n.01&apos;),
 Synset(&apos;program.n.07&apos;),
 Synset(&apos;program.n.08&apos;),
 Synset(&apos;program.v.01&apos;),
 Synset(&apos;program.v.02&apos;)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">word = wordnet.synsets(<span class="string">'boy'</span>)</span><br><span class="line">synonyms =[]</span><br><span class="line">antonyms = []</span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> word:</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> w.lemmas():</span><br><span class="line">        synonyms.append(l.name())</span><br><span class="line">        <span class="keyword">if</span> l.antonyms():</span><br><span class="line">            <span class="keyword">for</span> a <span class="keyword">in</span> l.antonyms():</span><br><span class="line">                antonyms.append(a.name())</span><br><span class="line">print(set(synonyms))</span><br><span class="line">print(set(antonyms))</span><br></pre></td></tr></table></figure>
<pre><code>{&apos;male_child&apos;, &apos;son&apos;, &apos;boy&apos;}
{&apos;female_child&apos;, &apos;daughter&apos;, &apos;girl&apos;}
</code></pre><p>Use list comprehension(列表推导式)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">synonyms2 = set([l.name() <span class="keyword">for</span> w <span class="keyword">in</span> word <span class="keyword">for</span> l <span class="keyword">in</span> w.lemmas()])</span><br><span class="line">antonyms2 = set([a.name() <span class="keyword">for</span> w <span class="keyword">in</span> word <span class="keyword">for</span> l <span class="keyword">in</span> w.lemmas() <span class="keyword">for</span> a <span class="keyword">in</span> l.antonyms()])</span><br><span class="line">print(synonyms2)</span><br><span class="line">print(antonyms2)</span><br></pre></td></tr></table></figure>
<pre><code>{&apos;male_child&apos;, &apos;son&apos;, &apos;boy&apos;}
{&apos;female_child&apos;, &apos;daughter&apos;, &apos;girl&apos;}
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">word[<span class="number">0</span>][<span class="string">"boy"</span>].antosyns()</span><br></pre></td></tr></table></figure>
<pre><code>---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

&lt;ipython-input-77-93678c6743d6&gt; in &lt;module&gt;()
----&gt; 1 word[0][&quot;boy&quot;].antosyns()


TypeError: &apos;Synset&apos; object is not subscriptable
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat = wordnet.synset(<span class="string">"cat.n.01"</span>)</span><br><span class="line">dog = wordnet.synset(<span class="string">"dog.n.01"</span>)</span><br><span class="line">dog.wup_similarity(cat)</span><br></pre></td></tr></table></figure>
<pre><code>0.8571428571428571
</code></pre><h3 id="11-Text-Classfication-文本分类"><a href="#11-Text-Classfication-文本分类" class="headerlink" title="11. Text Classfication(文本分类)"></a>11. Text Classfication(文本分类)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> movie_reviews</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">documents = [(list(movie_reviews.words(fileid)),category)</span><br><span class="line">              <span class="keyword">for</span> category <span class="keyword">in</span> movie_reviews.categories()</span><br><span class="line">             <span class="keyword">for</span> fileid <span class="keyword">in</span> movie_reviews.fileids(category)]</span><br><span class="line">random.shuffle(documents)</span><br><span class="line"></span><br><span class="line">documents[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<pre><code>([&apos;did&apos;,
  &apos;you&apos;,
  &apos;ever&apos;,
  &apos;wonder&apos;,
  &apos;if&apos;,
  &apos;dennis&apos;,
  &apos;rodman&apos;,
  &apos;was&apos;,
  &apos;actually&apos;,
  &apos;from&apos;,
  &apos;this&apos;,
  &apos;planet&apos;,
  &apos;?&apos;,
  &apos;or&apos;,
  &apos;if&apos;,
  &apos;sylvester&apos;,
  &apos;stallone&apos;,
  &apos;was&apos;,
  &apos;some&apos;,
  &apos;kind&apos;,
  &apos;of&apos;,
  &apos;weird&apos;,
  &apos;extra&apos;,
  &apos;-&apos;,
  &apos;terrestrial&apos;,
  &apos;?&apos;,
  &apos;i&apos;,
  &apos;used&apos;,
  &apos;to&apos;,
  &apos;think&apos;,
  &apos;that&apos;,
  &apos;about&apos;,
  &apos;my&apos;,
  &apos;7th&apos;,
  &apos;grade&apos;,
  &apos;english&apos;,
  &apos;teacher&apos;,
  &apos;,&apos;,
  &apos;ms&apos;,
  &apos;.&apos;,
  &apos;carey&apos;,
  &apos;.&apos;,
  &apos;but&apos;,
  &apos;after&apos;,
  &apos;seeing&apos;,
  &apos;this&apos;,
  &apos;movie&apos;,
  &apos;,&apos;,
  &apos;they&apos;,
  &apos;may&apos;,
  &apos;have&apos;,
  &apos;confirmed&apos;,
  &apos;my&apos;,
  &apos;suspicions&apos;,
  &apos;.&apos;,
  &apos;as&apos;,
  &apos;the&apos;,
  &apos;story&apos;,
  &apos;goes&apos;,
  &apos;,&apos;,
  &apos;at&apos;,
  &apos;any&apos;,
  &apos;time&apos;,
  &apos;,&apos;,
  &apos;there&apos;,
  &apos;are&apos;,
  &apos;over&apos;,
  &apos;a&apos;,
  &apos;thousand&apos;,
  &apos;aliens&apos;,
  &apos;living&apos;,
  &apos;among&apos;,
  &apos;us&apos;,
  &apos;here&apos;,
  &apos;on&apos;,
  &apos;earth&apos;,
  &apos;.&apos;,
  &apos;the&apos;,
  &apos;men&apos;,
  &apos;in&apos;,
  &apos;black&apos;,
  &apos;(&apos;,
  &apos;mib&apos;,
  &apos;)&apos;,
  &apos;are&apos;,
  &apos;the&apos;,
  &apos;watchdogs&apos;,
  &apos;that&apos;,
  &apos;oversee&apos;,
  &apos;the&apos;,
  &apos;cosmic&apos;,
  &apos;citizens&apos;,
  &apos;,&apos;,
  &apos;guardians&apos;,
  &apos;of&apos;,
  &apos;our&apos;,
  &apos;beloved&apos;,
  &apos;planet&apos;,
  &apos;from&apos;,
  &apos;nasty&apos;,
  &apos;-&apos;,
  &apos;tempered&apos;,
  &apos;aliens&apos;,
  &apos;,&apos;,
  &apos;and&apos;,
  &apos;secret&apos;,
  &apos;service&apos;,
  &apos;to&apos;,
  &apos;the&apos;,
  &apos;stars&apos;,
  &apos;.&apos;,
  &apos;based&apos;,
  &apos;in&apos;,
  &apos;new&apos;,
  &apos;york&apos;,
  &apos;city&apos;,
  &apos;(&apos;,
  &apos;where&apos;,
  &apos;weird&apos;,
  &apos;is&apos;,
  &apos;the&apos;,
  &apos;norm&apos;,
  &apos;)&apos;,
  &apos;,&apos;,
  &apos;the&apos;,
  &apos;mib&apos;,
  &apos;organization&apos;,
  &apos;gives&apos;,
  &apos;human&apos;,
  &apos;form&apos;,
  &apos;to&apos;,
  &apos;our&apos;,
  &apos;space&apos;,
  &apos;-&apos;,
  &apos;faring&apos;,
  &apos;emigrants&apos;,
  &apos;so&apos;,
  &apos;that&apos;,
  &apos;they&apos;,
  &apos;may&apos;,
  &apos;walk&apos;,
  &apos;and&apos;,
  &apos;live&apos;,
  &apos;among&apos;,
  &apos;us&apos;,
  &apos;unnoticed&apos;,
  &apos;.&apos;,
  &apos;but&apos;,
  &apos;to&apos;,
  &apos;enforce&apos;,
  &apos;the&apos;,
  &apos;laws&apos;,
  &apos;of&apos;,
  &apos;earth&apos;,
  &apos;,&apos;,
  &apos;the&apos;,
  &apos;mib&apos;,
  &apos;carry&apos;,
  &apos;weapons&apos;,
  &apos;that&apos;,
  &apos;are&apos;,
  &apos;powerful&apos;,
  &apos;enough&apos;,
  &apos;to&apos;,
  &apos;meet&apos;,
  &apos;or&apos;,
  &apos;exceed&apos;,
  &apos;destruction&apos;,
  &apos;quotas&apos;,
  &apos;in&apos;,
  &apos;one&apos;,
  &apos;single&apos;,
  &apos;blast&apos;,
  &apos;.&apos;,
  &apos;they&apos;,
  &apos;carry&apos;,
  &apos;other&apos;,
  &apos;-&apos;,
  &apos;worldly&apos;,
  &apos;technology&apos;,
  &apos;to&apos;,
  &apos;erase&apos;,
  &apos;people&apos;,
  &quot;&apos;&quot;,
  &apos;s&apos;,
  &apos;short&apos;,
  &apos;-&apos;,
  &apos;term&apos;,
  &apos;memory&apos;,
  &apos;when&apos;,
  &apos;common&apos;,
  &apos;folk&apos;,
  &apos;see&apos;,
  &apos;the&apos;,
  &apos;mib&apos;,
  &apos;in&apos;,
  &apos;action&apos;,
  &apos;.&apos;,
  &apos;and&apos;,
  &apos;their&apos;,
  &apos;best&apos;,
  &apos;leads&apos;,
  &apos;on&apos;,
  &apos;cosmic&apos;,
  &apos;things&apos;,
  &apos;-&apos;,
  &apos;gone&apos;,
  &apos;-&apos;,
  &apos;awry&apos;,
  &apos;are&apos;,
  &apos;the&apos;,
  &apos;supermarket&apos;,
  &apos;tabloids&apos;,
  &apos;.&apos;,
  &apos;little&apos;,
  &apos;do&apos;,
  &apos;we&apos;,
  &apos;know&apos;,
  &apos;that&apos;,
  &apos;there&apos;,
  &apos;are&apos;,
  &apos;much&apos;,
  &apos;stronger&apos;,
  &apos;battles&apos;,
  &apos;of&apos;,
  &apos;good&apos;,
  &apos;v&apos;,
  &apos;.&apos;,
  &apos;evil&apos;,
  &apos;going&apos;,
  &apos;on&apos;,
  &apos;in&apos;,
  &apos;the&apos;,
  &apos;depths&apos;,
  &apos;of&apos;,
  &apos;space&apos;,
  &apos;.&apos;,
  &apos;one&apos;,
  &apos;of&apos;,
  &apos;the&apos;,
  &apos;aliens&apos;,
  &apos;-&apos;,
  &apos;as&apos;,
  &apos;-&apos;,
  &apos;human&apos;,
  &apos;on&apos;,
  &apos;this&apos;,
  &apos;planet&apos;,
  &apos;is&apos;,
  &apos;an&apos;,
  &apos;important&apos;,
  &apos;diplomat&apos;,
  &apos;that&apos;,
  &apos;is&apos;,
  &apos;carrying&apos;,
  &apos;something&apos;,
  &apos;very&apos;,
  &apos;precious&apos;,
  &apos;.&apos;,
  &apos;it&apos;,
  &apos;holds&apos;,
  &apos;the&apos;,
  &quot;&apos;&quot;,
  &apos;key&apos;,
  &quot;&apos;&quot;,
  &apos;,&apos;,
  &apos;literally&apos;,
  &apos;,&apos;,
  &apos;to&apos;,
  &apos;universal&apos;,
  &apos;peace&apos;,
  &apos;.&apos;,
  &apos;a&apos;,
  &apos;giant&apos;,
  &apos;cockroach&apos;,
  &apos;-&apos;,
  &apos;like&apos;,
  &apos;alien&apos;,
  &apos;soon&apos;,
  &apos;arrives&apos;,
  &apos;on&apos;,
  &apos;the&apos;,
  &apos;planet&apos;,
  &apos;and&apos;,
  &apos;steals&apos;,
  &apos;this&apos;,
  &quot;&apos;&quot;,
  &apos;key&apos;,
  &quot;&apos;&quot;,
  &apos;.&apos;,
  &apos;in&apos;,
  &apos;the&apos;,
  &apos;wrong&apos;,
  &apos;alien&apos;,
  &apos;hands&apos;,
  &apos;(&apos;,
  &apos;flippers&apos;,
  &apos;?&apos;,
  &apos;mandibles&apos;,
  &apos;?&apos;,
  &apos;tentacles&apos;,
  &apos;?&apos;,
  &apos;)&apos;,
  &apos;,&apos;,
  &apos;it&apos;,
  &apos;can&apos;,
  &apos;be&apos;,
  &apos;used&apos;,
  &apos;as&apos;,
  &apos;a&apos;,
  &apos;weapon&apos;,
  &apos;.&apos;,
  &apos;therefore&apos;,
  &apos;,&apos;,
  &apos;it&apos;,
  &apos;must&apos;,
  &apos;be&apos;,
  &apos;recovered&apos;,
  &apos;and&apos;,
  &apos;returned&apos;,
  &apos;to&apos;,
  &apos;it&apos;,
  &quot;&apos;&quot;,
  &apos;s&apos;,
  &apos;rightful&apos;,
  &apos;owners&apos;,
  &apos;.&apos;,
  &apos;otherwise&apos;,
  &apos;,&apos;,
  &apos;to&apos;,
  &apos;ensure&apos;,
  &apos;universal&apos;,
  &apos;safety&apos;,
  &apos;,&apos;,
  &apos;earth&apos;,
  &apos;will&apos;,
  &apos;be&apos;,
  &apos;destroyed&apos;,
  &apos;,&apos;,
  &apos;along&apos;,
  &apos;with&apos;,
  &apos;the&apos;,
  &quot;&apos;&quot;,
  &apos;key&apos;,
  &quot;&apos;&quot;,
  &apos;.&apos;,
  &apos;now&apos;,
  &apos;,&apos;,
  &apos;it&apos;,
  &quot;&apos;&quot;,
  &apos;s&apos;,
  &apos;the&apos;,
  &apos;mib&apos;,
  &apos;who&apos;,
  &apos;must&apos;,
  &apos;prevent&apos;,
  &apos;this&apos;,
  &apos;catastrophe&apos;,
  &apos;.&apos;,
  &apos;the&apos;,
  &apos;mib&apos;,
  &apos;agents&apos;,
  &apos;on&apos;,
  &apos;the&apos;,
  &apos;case&apos;,
  &apos;are&apos;,
  &apos;&quot;&apos;,
  &apos;k&apos;,
  &apos;&quot;&apos;,
  &apos;,&apos;,
  &apos;played&apos;,
  &apos;by&apos;,
  &apos;tommy&apos;,
  &apos;lee&apos;,
  &apos;jones&apos;,
  &apos;.&apos;,
  &apos;he&apos;,
  &apos;is&apos;,
  &apos;crustier&apos;,
  &apos;than&apos;,
  &apos;burnt&apos;,
  &apos;toast&apos;,
  &apos;and&apos;,
  &apos;even&apos;,
  &apos;more&apos;,
  &apos;serious&apos;,
  &apos;than&apos;,
  &apos;al&apos;,
  &apos;gore&apos;,
  &apos;.&apos;,
  &apos;the&apos;,
  &apos;stars&apos;,
  &apos;in&apos;,
  &apos;the&apos;,
  &apos;sky&apos;,
  &apos;no&apos;,
  &apos;longer&apos;,
  &apos;spark&apos;,
  &apos;wonder&apos;,
  &apos;in&apos;,
  &apos;his&apos;,
  &apos;eyes&apos;,
  &apos;.&apos;,
  &apos;he&apos;,
  &apos;is&apos;,
  &apos;accompanied&apos;,
  &apos;by&apos;,
  &apos;a&apos;,
  &apos;flippant&apos;,
  &apos;rookie&apos;,
  &apos;,&apos;,
  &apos;&quot;&apos;,
  &apos;j&apos;,
  &apos;&quot;&apos;,
  &apos;,&apos;,
  &apos;played&apos;,
  &apos;by&apos;,
  &apos;will&apos;,
  &apos;smith&apos;,
  &apos;.&apos;,
  &apos;but&apos;,
  &apos;,&apos;,
  &apos;despite&apos;,
  &apos;this&apos;,
  &apos;shoot&apos;,
  &apos;-&apos;,
  &apos;em&apos;,
  &apos;-&apos;,
  &apos;up&apos;,
  &apos;,&apos;,
  &apos;protect&apos;,
  &apos;-&apos;,
  &apos;earth&apos;,
  &apos;-&apos;,
  &apos;from&apos;,
  &apos;-&apos;,
  &apos;destruction&apos;,
  &apos;premise&apos;,
  &apos;,&apos;,
  &apos;this&apos;,
  &apos;is&apos;,
  &apos;nothing&apos;,
  &apos;at&apos;,
  &apos;all&apos;,
  &apos;like&apos;,
  &apos;a&apos;,
  &apos;typical&apos;,
  &apos;summer&apos;,
  &apos;action&apos;,
  &apos;movie&apos;,
  &apos;.&apos;,
  &apos;and&apos;,
  &apos;,&apos;,
  &apos;this&apos;,
  &apos;isn&apos;,
  &quot;&apos;&quot;,
  &apos;t&apos;,
  &apos;an&apos;,
  &apos;independence&apos;,
  &apos;day&apos;,
  &apos;knockoff&apos;,
  &apos;.&apos;,
  &apos;rather&apos;,
  &apos;,&apos;,
  &apos;this&apos;,
  &apos;is&apos;,
  &apos;a&apos;,
  &apos;stylishly&apos;,
  &apos;offbeat&apos;,
  &apos;sci&apos;,
  &apos;-&apos;,
  &apos;fi&apos;,
  &apos;comedy&apos;,
  &apos;that&apos;,
  &apos;pokes&apos;,
  &apos;fun&apos;,
  &apos;at&apos;,
  &apos;what&apos;,
  &apos;the&apos;,
  &apos;government&apos;,
  &apos;always&apos;,
  &apos;denies&apos;,
  &apos;?&apos;,
  &apos;that&apos;,
  &apos;there&apos;,
  &apos;are&apos;,
  &apos;real&apos;,
  &apos;aliens&apos;,
  &apos;that&apos;,
  &apos;live&apos;,
  &apos;here&apos;,
  &apos;,&apos;,
  &apos;and&apos;,
  &apos;that&apos;,
  &apos;the&apos;,
  &apos;government&apos;,
  &apos;does&apos;,
  &apos;its&apos;,
  &apos;darndest&apos;,
  &apos;to&apos;,
  &apos;cover&apos;,
  &apos;them&apos;,
  &apos;up&apos;,
  &apos;.&apos;,
  &apos;but&apos;,
  &apos;to&apos;,
  &apos;give&apos;,
  &apos;it&apos;,
  &apos;some&apos;,
  &apos;sense&apos;,
  &apos;of&apos;,
  &apos;excitement&apos;,
  &apos;and&apos;,
  &apos;to&apos;,
  &apos;keep&apos;,
  &apos;it&apos;,
  &apos;within&apos;,
  &apos;the&apos;,
  &apos;parameters&apos;,
  &apos;of&apos;,
  &apos;the&apos;,
  &apos;summer&apos;,
  &apos;movie&apos;,
  &apos;recipe&apos;,
  &apos;,&apos;,
  &apos;there&apos;,
  &apos;must&apos;,
  &apos;be&apos;,
  &apos;some&apos;,
  &apos;kind&apos;,
  &apos;of&apos;,
  &apos;earth&apos;,
  &apos;-&apos;,
  &apos;hangs&apos;,
  &apos;-&apos;,
  &apos;in&apos;,
  &apos;-&apos;,
  &apos;the&apos;,
  &apos;-&apos;,
  &apos;balance&apos;,
  &apos;scenario&apos;,
  &apos;.&apos;,
  &apos;yet&apos;,
  &apos;,&apos;,
  &apos;this&apos;,
  &apos;movie&apos;,
  &apos;is&apos;,
  &apos;very&apos;,
  &apos;appealing&apos;,
  &apos;.&apos;,
  &apos;the&apos;,
  &apos;abundance&apos;,
  &apos;of&apos;,
  &apos;wierdness&apos;,
  &apos;(&apos;,
  &apos;talking&apos;,
  &apos;aliens&apos;,
  &apos;,&apos;,
  &apos;pee&apos;,
  &apos;-&apos;,
  &apos;wee&apos;,
  &apos;atomizers&apos;,
  &apos;,&apos;,
  &apos;a&apos;,
  &apos;mortician&apos;,
  &apos;who&apos;,
  &quot;&apos;&quot;,
  &apos;lives&apos;,
  &quot;&apos;&quot;,
  &apos;for&apos;,
  &apos;her&apos;,
  &apos;work&apos;,
  &apos;,&apos;,
  &apos;and&apos;,
  &apos;lots&apos;,
  &apos;of&apos;,
  &apos;yucky&apos;,
  &apos;bugs&apos;,
  &apos;and&apos;,
  &apos;slime&apos;,
  &apos;-&apos;,
  &apos;splattering&apos;,
  &apos;galore&apos;,
  &apos;)&apos;,
  &apos;,&apos;,
  &apos;is&apos;,
  &apos;played&apos;,
  &apos;straight&apos;,
  &apos;,&apos;,
  &apos;like&apos;,
  &apos;as&apos;,
  &apos;if&apos;,
  &apos;this&apos;,
  &apos;were&apos;,
  &apos;normal&apos;,
  &apos;(&apos;,
  &apos;of&apos;,
  &apos;course&apos;,
  &apos;,&apos;,
  &apos;we&apos;,
  &apos;are&apos;,
  &apos;in&apos;,
  &apos;nyc&apos;,
  &apos;)&apos;,
  &apos;.&apos;,
  &apos;it&apos;,
  &apos;gives&apos;,
  &apos;it&apos;,
  &apos;a&apos;,
  &apos;deadpan&apos;,
  &apos;feel&apos;,
  &apos;,&apos;,
  &apos;which&apos;,
  &apos;makes&apos;,
  &apos;it&apos;,
  &apos;all&apos;,
  &apos;the&apos;,
  &apos;more&apos;,
  &apos;funnier&apos;,
  &apos;and&apos;,
  &apos;odder&apos;,
  &apos;.&apos;,
  &apos;jones&apos;,
  &apos;plays&apos;,
  &apos;the&apos;,
  &apos;venerable&apos;,
  &apos;seen&apos;,
  &apos;-&apos;,
  &apos;it&apos;,
  &apos;-&apos;,
  &apos;all&apos;,
  &apos;agent&apos;,
  &apos;with&apos;,
  &apos;seriousness&apos;,
  &apos;and&apos;,
  &apos;maturity&apos;,
  &apos;.&apos;,
  &apos;smith&apos;,
  &apos;is&apos;,
  &apos;likeable&apos;,
  &apos;and&apos;,
  &apos;makes&apos;,
  &apos;a&apos;,
  &apos;great&apos;,
  &apos;comic&apos;,
  &apos;partner&apos;,
  &apos;to&apos;,
  &apos;jones&apos;,
  &quot;&apos;&quot;,
  &apos;straight&apos;,
  &apos;man&apos;,
  &apos;routine&apos;,
  &apos;.&apos;,
  &apos;they&apos;,
  &apos;click&apos;,
  &apos;like&apos;,
  &apos;dorothy&apos;,
  &quot;&apos;&quot;,
  &apos;s&apos;,
  &apos;ruby&apos;,
  &apos;red&apos;,
  &apos;shoes&apos;,
  &apos;.&apos;,
  &apos;the&apos;,
  &apos;look&apos;,
  &apos;and&apos;,
  &apos;feel&apos;,
  &apos;of&apos;,
  &apos;the&apos;,
  &apos;movie&apos;,
  &apos;is&apos;,
  &apos;made&apos;,
  &apos;even&apos;,
  &apos;better&apos;,
  &apos;with&apos;,
  &apos;direction&apos;,
  &apos;from&apos;,
  &apos;barry&apos;,
  &apos;sonnenfeld&apos;,
  &apos;(&apos;,
  &apos;the&apos;,
  &apos;addam&apos;,
  &quot;&apos;&quot;,
  &apos;s&apos;,
  &apos;family&apos;,
  &apos;)&apos;,
  &apos;.&apos;,
  &apos;this&apos;,
  &apos;guy&apos;,
  &apos;has&apos;,
  &apos;a&apos;,
  &apos;knack&apos;,
  &apos;for&apos;,
  &quot;&apos;&quot;,
  &apos;gothic&apos;,
  &quot;&apos;&quot;,
  &apos;comedy&apos;,
  &apos;,&apos;,
  &apos;and&apos;,
  &apos;successfully&apos;,
  &apos;transfers&apos;,
  &apos;his&apos;,
  &apos;macabre&apos;,
  &apos;sense&apos;,
  &apos;of&apos;,
  &apos;humor&apos;,
  &apos;onto&apos;,
  &apos;the&apos;,
  &apos;screen&apos;,
  &apos;.&apos;,
  &apos;and&apos;,
  &apos;,&apos;,
  &apos;an&apos;,
  &apos;appropriate&apos;,
  &apos;dose&apos;,
  &apos;of&apos;,
  &apos;special&apos;,
  &apos;effects&apos;,
  &apos;helps&apos;,
  &apos;to&apos;,
  &apos;bolster&apos;,
  &apos;the&apos;,
  &apos;oddness&apos;,
  &apos;of&apos;,
  &apos;their&apos;,
  &apos;task&apos;,
  &apos;without&apos;,
  &apos;diverting&apos;,
  &apos;attention&apos;,
  &apos;from&apos;,
  &apos;the&apos;,
  &apos;human&apos;,
  &apos;actors&apos;,
  &apos;.&apos;,
  &apos;the&apos;,
  &apos;story&apos;,
  &apos;moves&apos;,
  &apos;well&apos;,
  &apos;,&apos;,
  &apos;and&apos;,
  &apos;before&apos;,
  &apos;you&apos;,
  &apos;know&apos;,
  &apos;it&apos;,
  &apos;,&apos;,
  &apos;the&apos;,
  &apos;end&apos;,
  &apos;credits&apos;,
  &apos;are&apos;,
  &apos;already&apos;,
  &apos;rolling&apos;,
  &apos;!&apos;,
  &apos;the&apos;,
  &apos;result&apos;,
  &apos;is&apos;,
  &apos;100&apos;,
  &apos;minutes&apos;,
  &apos;worth&apos;,
  &apos;of&apos;,
  &apos;fun&apos;,
  &apos;in&apos;,
  &apos;the&apos;,
  &apos;form&apos;,
  &apos;of&apos;,
  &apos;ewwwws&apos;,
  &apos;and&apos;,
  &apos;blechhhs&apos;,
  &apos;,&apos;,
  &apos;aaaahhhs&apos;,
  &apos;and&apos;,
  &apos;wows&apos;,
  &apos;.&apos;,
  &apos;let&apos;,
  &apos;the&apos;,
  &apos;men&apos;,
  &apos;in&apos;,
  &apos;black&apos;,
  &apos;protect&apos;,
  &apos;and&apos;,
  &apos;color&apos;,
  &apos;your&apos;,
  &apos;world&apos;,
  &apos;.&apos;],
 &apos;pos&apos;)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_words = [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> movie_reviews.words()]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_words</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;plot&apos;,
 &apos;:&apos;,
 &apos;two&apos;,
 &apos;teen&apos;,
 &apos;couples&apos;,
 &apos;go&apos;,
 &apos;to&apos;,
 &apos;a&apos;,
 &apos;church&apos;,
 &apos;party&apos;,
 &apos;,&apos;,
 &apos;drink&apos;,
 &apos;and&apos;,
 &apos;then&apos;,
 &apos;drive&apos;,
 &apos;.&apos;,
 &apos;they&apos;,
 &apos;get&apos;,
 &apos;into&apos;,
 &apos;an&apos;,
 &apos;accident&apos;,
 &apos;.&apos;,
 &apos;one&apos;,
 &apos;of&apos;,
 &apos;the&apos;,
 &apos;guys&apos;,
 &apos;dies&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;his&apos;,
 &apos;girlfriend&apos;,
 &apos;continues&apos;,
 &apos;to&apos;,
 &apos;see&apos;,
 &apos;him&apos;,
 &apos;in&apos;,
 &apos;her&apos;,
 &apos;life&apos;,
 &apos;,&apos;,
 &apos;and&apos;,
 &apos;has&apos;,
 &apos;nightmares&apos;,
 &apos;.&apos;,
 &apos;what&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;the&apos;,
 &apos;deal&apos;,
 &apos;?&apos;,
 &apos;watch&apos;,
 &apos;the&apos;,
 &apos;movie&apos;,
 &apos;and&apos;,
 &apos;&quot;&apos;,
 &apos;sorta&apos;,
 &apos;&quot;&apos;,
 &apos;find&apos;,
 &apos;out&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;critique&apos;,
 &apos;:&apos;,
 &apos;a&apos;,
 &apos;mind&apos;,
 &apos;-&apos;,
 &apos;fuck&apos;,
 &apos;movie&apos;,
 &apos;for&apos;,
 &apos;the&apos;,
 &apos;teen&apos;,
 &apos;generation&apos;,
 &apos;that&apos;,
 &apos;touches&apos;,
 &apos;on&apos;,
 &apos;a&apos;,
 &apos;very&apos;,
 &apos;cool&apos;,
 &apos;idea&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;presents&apos;,
 &apos;it&apos;,
 &apos;in&apos;,
 &apos;a&apos;,
 &apos;very&apos;,
 &apos;bad&apos;,
 &apos;package&apos;,
 &apos;.&apos;,
 &apos;which&apos;,
 &apos;is&apos;,
 &apos;what&apos;,
 &apos;makes&apos;,
 &apos;this&apos;,
 &apos;review&apos;,
 &apos;an&apos;,
 &apos;even&apos;,
 &apos;harder&apos;,
 &apos;one&apos;,
 &apos;to&apos;,
 &apos;write&apos;,
 &apos;,&apos;,
 &apos;since&apos;,
 &apos;i&apos;,
 &apos;generally&apos;,
 &apos;applaud&apos;,
 &apos;films&apos;,
 &apos;which&apos;,
 &apos;attempt&apos;,
 &apos;to&apos;,
 &apos;break&apos;,
 &apos;the&apos;,
 &apos;mold&apos;,
 &apos;,&apos;,
 &apos;mess&apos;,
 &apos;with&apos;,
 &apos;your&apos;,
 &apos;head&apos;,
 &apos;and&apos;,
 &apos;such&apos;,
 &apos;(&apos;,
 &apos;lost&apos;,
 &apos;highway&apos;,
 &apos;&amp;&apos;,
 &apos;memento&apos;,
 &apos;)&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;good&apos;,
 &apos;and&apos;,
 &apos;bad&apos;,
 &apos;ways&apos;,
 &apos;of&apos;,
 &apos;making&apos;,
 &apos;all&apos;,
 &apos;types&apos;,
 &apos;of&apos;,
 &apos;films&apos;,
 &apos;,&apos;,
 &apos;and&apos;,
 &apos;these&apos;,
 &apos;folks&apos;,
 &apos;just&apos;,
 &apos;didn&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;snag&apos;,
 &apos;this&apos;,
 &apos;one&apos;,
 &apos;correctly&apos;,
 &apos;.&apos;,
 &apos;they&apos;,
 &apos;seem&apos;,
 &apos;to&apos;,
 &apos;have&apos;,
 &apos;taken&apos;,
 &apos;this&apos;,
 &apos;pretty&apos;,
 &apos;neat&apos;,
 &apos;concept&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;executed&apos;,
 &apos;it&apos;,
 &apos;terribly&apos;,
 &apos;.&apos;,
 &apos;so&apos;,
 &apos;what&apos;,
 &apos;are&apos;,
 &apos;the&apos;,
 &apos;problems&apos;,
 &apos;with&apos;,
 &apos;the&apos;,
 &apos;movie&apos;,
 &apos;?&apos;,
 &apos;well&apos;,
 &apos;,&apos;,
 &apos;its&apos;,
 &apos;main&apos;,
 &apos;problem&apos;,
 &apos;is&apos;,
 &apos;that&apos;,
 &apos;it&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;simply&apos;,
 &apos;too&apos;,
 &apos;jumbled&apos;,
 &apos;.&apos;,
 &apos;it&apos;,
 &apos;starts&apos;,
 &apos;off&apos;,
 &apos;&quot;&apos;,
 &apos;normal&apos;,
 &apos;&quot;&apos;,
 &apos;but&apos;,
 &apos;then&apos;,
 &apos;downshifts&apos;,
 &apos;into&apos;,
 &apos;this&apos;,
 &apos;&quot;&apos;,
 &apos;fantasy&apos;,
 &apos;&quot;&apos;,
 &apos;world&apos;,
 &apos;in&apos;,
 &apos;which&apos;,
 &apos;you&apos;,
 &apos;,&apos;,
 &apos;as&apos;,
 &apos;an&apos;,
 &apos;audience&apos;,
 &apos;member&apos;,
 &apos;,&apos;,
 &apos;have&apos;,
 &apos;no&apos;,
 &apos;idea&apos;,
 &apos;what&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;going&apos;,
 &apos;on&apos;,
 &apos;.&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;dreams&apos;,
 &apos;,&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;characters&apos;,
 &apos;coming&apos;,
 &apos;back&apos;,
 &apos;from&apos;,
 &apos;the&apos;,
 &apos;dead&apos;,
 &apos;,&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;others&apos;,
 &apos;who&apos;,
 &apos;look&apos;,
 &apos;like&apos;,
 &apos;the&apos;,
 &apos;dead&apos;,
 &apos;,&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;strange&apos;,
 &apos;apparitions&apos;,
 &apos;,&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;disappearances&apos;,
 &apos;,&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;a&apos;,
 &apos;looooot&apos;,
 &apos;of&apos;,
 &apos;chase&apos;,
 &apos;scenes&apos;,
 &apos;,&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;tons&apos;,
 &apos;of&apos;,
 &apos;weird&apos;,
 &apos;things&apos;,
 &apos;that&apos;,
 &apos;happen&apos;,
 &apos;,&apos;,
 &apos;and&apos;,
 &apos;most&apos;,
 &apos;of&apos;,
 &apos;it&apos;,
 &apos;is&apos;,
 &apos;simply&apos;,
 &apos;not&apos;,
 &apos;explained&apos;,
 &apos;.&apos;,
 &apos;now&apos;,
 &apos;i&apos;,
 &apos;personally&apos;,
 &apos;don&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;mind&apos;,
 &apos;trying&apos;,
 &apos;to&apos;,
 &apos;unravel&apos;,
 &apos;a&apos;,
 &apos;film&apos;,
 &apos;every&apos;,
 &apos;now&apos;,
 &apos;and&apos;,
 &apos;then&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;when&apos;,
 &apos;all&apos;,
 &apos;it&apos;,
 &apos;does&apos;,
 &apos;is&apos;,
 &apos;give&apos;,
 &apos;me&apos;,
 &apos;the&apos;,
 &apos;same&apos;,
 &apos;clue&apos;,
 &apos;over&apos;,
 &apos;and&apos;,
 &apos;over&apos;,
 &apos;again&apos;,
 &apos;,&apos;,
 &apos;i&apos;,
 &apos;get&apos;,
 &apos;kind&apos;,
 &apos;of&apos;,
 &apos;fed&apos;,
 &apos;up&apos;,
 &apos;after&apos;,
 &apos;a&apos;,
 &apos;while&apos;,
 &apos;,&apos;,
 &apos;which&apos;,
 &apos;is&apos;,
 &apos;this&apos;,
 &apos;film&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;biggest&apos;,
 &apos;problem&apos;,
 &apos;.&apos;,
 &apos;it&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;obviously&apos;,
 &apos;got&apos;,
 &apos;this&apos;,
 &apos;big&apos;,
 &apos;secret&apos;,
 &apos;to&apos;,
 &apos;hide&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;it&apos;,
 &apos;seems&apos;,
 &apos;to&apos;,
 &apos;want&apos;,
 &apos;to&apos;,
 &apos;hide&apos;,
 &apos;it&apos;,
 &apos;completely&apos;,
 &apos;until&apos;,
 &apos;its&apos;,
 &apos;final&apos;,
 &apos;five&apos;,
 &apos;minutes&apos;,
 &apos;.&apos;,
 &apos;and&apos;,
 &apos;do&apos;,
 &apos;they&apos;,
 &apos;make&apos;,
 &apos;things&apos;,
 &apos;entertaining&apos;,
 &apos;,&apos;,
 &apos;thrilling&apos;,
 &apos;or&apos;,
 &apos;even&apos;,
 &apos;engaging&apos;,
 &apos;,&apos;,
 &apos;in&apos;,
 &apos;the&apos;,
 &apos;meantime&apos;,
 &apos;?&apos;,
 &apos;not&apos;,
 &apos;really&apos;,
 &apos;.&apos;,
 &apos;the&apos;,
 &apos;sad&apos;,
 &apos;part&apos;,
 &apos;is&apos;,
 &apos;that&apos;,
 &apos;the&apos;,
 &apos;arrow&apos;,
 &apos;and&apos;,
 &apos;i&apos;,
 &apos;both&apos;,
 &apos;dig&apos;,
 &apos;on&apos;,
 &apos;flicks&apos;,
 &apos;like&apos;,
 &apos;this&apos;,
 &apos;,&apos;,
 &apos;so&apos;,
 &apos;we&apos;,
 &apos;actually&apos;,
 &apos;figured&apos;,
 &apos;most&apos;,
 &apos;of&apos;,
 &apos;it&apos;,
 &apos;out&apos;,
 &apos;by&apos;,
 &apos;the&apos;,
 &apos;half&apos;,
 &apos;-&apos;,
 &apos;way&apos;,
 &apos;point&apos;,
 &apos;,&apos;,
 &apos;so&apos;,
 &apos;all&apos;,
 &apos;of&apos;,
 &apos;the&apos;,
 &apos;strangeness&apos;,
 &apos;after&apos;,
 &apos;that&apos;,
 &apos;did&apos;,
 &apos;start&apos;,
 &apos;to&apos;,
 &apos;make&apos;,
 &apos;a&apos;,
 &apos;little&apos;,
 &apos;bit&apos;,
 &apos;of&apos;,
 &apos;sense&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;it&apos;,
 &apos;still&apos;,
 &apos;didn&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;the&apos;,
 &apos;make&apos;,
 &apos;the&apos;,
 &apos;film&apos;,
 &apos;all&apos;,
 &apos;that&apos;,
 &apos;more&apos;,
 &apos;entertaining&apos;,
 &apos;.&apos;,
 &apos;i&apos;,
 &apos;guess&apos;,
 &apos;the&apos;,
 &apos;bottom&apos;,
 &apos;line&apos;,
 &apos;with&apos;,
 &apos;movies&apos;,
 &apos;like&apos;,
 &apos;this&apos;,
 &apos;is&apos;,
 &apos;that&apos;,
 &apos;you&apos;,
 &apos;should&apos;,
 &apos;always&apos;,
 &apos;make&apos;,
 &apos;sure&apos;,
 &apos;that&apos;,
 &apos;the&apos;,
 &apos;audience&apos;,
 &apos;is&apos;,
 &apos;&quot;&apos;,
 &apos;into&apos;,
 &apos;it&apos;,
 &apos;&quot;&apos;,
 &apos;even&apos;,
 &apos;before&apos;,
 &apos;they&apos;,
 &apos;are&apos;,
 &apos;given&apos;,
 &apos;the&apos;,
 &apos;secret&apos;,
 &apos;password&apos;,
 &apos;to&apos;,
 &apos;enter&apos;,
 &apos;your&apos;,
 &apos;world&apos;,
 &apos;of&apos;,
 &apos;understanding&apos;,
 &apos;.&apos;,
 &apos;i&apos;,
 &apos;mean&apos;,
 &apos;,&apos;,
 &apos;showing&apos;,
 &apos;melissa&apos;,
 &apos;sagemiller&apos;,
 &apos;running&apos;,
 &apos;away&apos;,
 &apos;from&apos;,
 &apos;visions&apos;,
 &apos;for&apos;,
 &apos;about&apos;,
 &apos;20&apos;,
 &apos;minutes&apos;,
 &apos;throughout&apos;,
 &apos;the&apos;,
 &apos;movie&apos;,
 &apos;is&apos;,
 &apos;just&apos;,
 &apos;plain&apos;,
 &apos;lazy&apos;,
 &apos;!&apos;,
 &apos;!&apos;,
 &apos;okay&apos;,
 &apos;,&apos;,
 &apos;we&apos;,
 &apos;get&apos;,
 &apos;it&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;there&apos;,
 &apos;are&apos;,
 &apos;people&apos;,
 &apos;chasing&apos;,
 &apos;her&apos;,
 &apos;and&apos;,
 &apos;we&apos;,
 &apos;don&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;know&apos;,
 &apos;who&apos;,
 &apos;they&apos;,
 &apos;are&apos;,
 &apos;.&apos;,
 &apos;do&apos;,
 &apos;we&apos;,
 &apos;really&apos;,
 &apos;need&apos;,
 &apos;to&apos;,
 &apos;see&apos;,
 &apos;it&apos;,
 &apos;over&apos;,
 &apos;and&apos;,
 &apos;over&apos;,
 &apos;again&apos;,
 &apos;?&apos;,
 &apos;how&apos;,
 &apos;about&apos;,
 &apos;giving&apos;,
 &apos;us&apos;,
 &apos;different&apos;,
 &apos;scenes&apos;,
 &apos;offering&apos;,
 &apos;further&apos;,
 &apos;insight&apos;,
 &apos;into&apos;,
 &apos;all&apos;,
 &apos;of&apos;,
 &apos;the&apos;,
 &apos;strangeness&apos;,
 &apos;going&apos;,
 &apos;down&apos;,
 &apos;in&apos;,
 &apos;the&apos;,
 &apos;movie&apos;,
 &apos;?&apos;,
 &apos;apparently&apos;,
 &apos;,&apos;,
 &apos;the&apos;,
 &apos;studio&apos;,
 &apos;took&apos;,
 &apos;this&apos;,
 &apos;film&apos;,
 &apos;away&apos;,
 &apos;from&apos;,
 &apos;its&apos;,
 &apos;director&apos;,
 &apos;and&apos;,
 &apos;chopped&apos;,
 &apos;it&apos;,
 &apos;up&apos;,
 &apos;themselves&apos;,
 &apos;,&apos;,
 &apos;and&apos;,
 &apos;it&apos;,
 &apos;shows&apos;,
 &apos;.&apos;,
 &apos;there&apos;,
 &apos;might&apos;,
 &quot;&apos;&quot;,
 &apos;ve&apos;,
 &apos;been&apos;,
 &apos;a&apos;,
 &apos;pretty&apos;,
 &apos;decent&apos;,
 &apos;teen&apos;,
 &apos;mind&apos;,
 &apos;-&apos;,
 &apos;fuck&apos;,
 &apos;movie&apos;,
 &apos;in&apos;,
 &apos;here&apos;,
 &apos;somewhere&apos;,
 &apos;,&apos;,
 &apos;but&apos;,
 &apos;i&apos;,
 &apos;guess&apos;,
 &apos;&quot;&apos;,
 &apos;the&apos;,
 &apos;suits&apos;,
 &apos;&quot;&apos;,
 &apos;decided&apos;,
 &apos;that&apos;,
 &apos;turning&apos;,
 &apos;it&apos;,
 &apos;into&apos;,
 &apos;a&apos;,
 &apos;music&apos;,
 &apos;video&apos;,
 &apos;with&apos;,
 &apos;little&apos;,
 &apos;edge&apos;,
 &apos;,&apos;,
 &apos;would&apos;,
 &apos;make&apos;,
 &apos;more&apos;,
 &apos;sense&apos;,
 &apos;.&apos;,
 &apos;the&apos;,
 &apos;actors&apos;,
 &apos;are&apos;,
 &apos;pretty&apos;,
 &apos;good&apos;,
 &apos;for&apos;,
 &apos;the&apos;,
 &apos;most&apos;,
 &apos;part&apos;,
 &apos;,&apos;,
 &apos;although&apos;,
 &apos;wes&apos;,
 &apos;bentley&apos;,
 &apos;just&apos;,
 &apos;seemed&apos;,
 &apos;to&apos;,
 &apos;be&apos;,
 &apos;playing&apos;,
 &apos;the&apos;,
 &apos;exact&apos;,
 &apos;same&apos;,
 &apos;character&apos;,
 &apos;that&apos;,
 &apos;he&apos;,
 &apos;did&apos;,
 &apos;in&apos;,
 &apos;american&apos;,
 &apos;beauty&apos;,
 &apos;,&apos;,
 &apos;only&apos;,
 &apos;in&apos;,
 &apos;a&apos;,
 &apos;new&apos;,
 &apos;neighborhood&apos;,
 &apos;.&apos;,
 &apos;but&apos;,
 &apos;my&apos;,
 &apos;biggest&apos;,
 &apos;kudos&apos;,
 &apos;go&apos;,
 &apos;out&apos;,
 &apos;to&apos;,
 &apos;sagemiller&apos;,
 &apos;,&apos;,
 &apos;who&apos;,
 &apos;holds&apos;,
 &apos;her&apos;,
 &apos;own&apos;,
 &apos;throughout&apos;,
 &apos;the&apos;,
 &apos;entire&apos;,
 &apos;film&apos;,
 &apos;,&apos;,
 &apos;and&apos;,
 &apos;actually&apos;,
 &apos;has&apos;,
 &apos;you&apos;,
 &apos;feeling&apos;,
 &apos;her&apos;,
 &apos;character&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;unraveling&apos;,
 &apos;.&apos;,
 &apos;overall&apos;,
 &apos;,&apos;,
 &apos;the&apos;,
 &apos;film&apos;,
 &apos;doesn&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;stick&apos;,
 &apos;because&apos;,
 &apos;it&apos;,
 &apos;doesn&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;entertain&apos;,
 &apos;,&apos;,
 &apos;it&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;confusing&apos;,
 &apos;,&apos;,
 &apos;it&apos;,
 &apos;rarely&apos;,
 &apos;excites&apos;,
 &apos;and&apos;,
 &apos;it&apos;,
 &apos;feels&apos;,
 &apos;pretty&apos;,
 &apos;redundant&apos;,
 &apos;for&apos;,
 &apos;most&apos;,
 &apos;of&apos;,
 &apos;its&apos;,
 &apos;runtime&apos;,
 &apos;,&apos;,
 &apos;despite&apos;,
 &apos;a&apos;,
 &apos;pretty&apos;,
 &apos;cool&apos;,
 &apos;ending&apos;,
 &apos;and&apos;,
 &apos;explanation&apos;,
 &apos;to&apos;,
 &apos;all&apos;,
 &apos;of&apos;,
 &apos;the&apos;,
 &apos;craziness&apos;,
 &apos;that&apos;,
 &apos;came&apos;,
 &apos;before&apos;,
 &apos;it&apos;,
 &apos;.&apos;,
 &apos;oh&apos;,
 &apos;,&apos;,
 &apos;and&apos;,
 &apos;by&apos;,
 &apos;the&apos;,
 &apos;way&apos;,
 &apos;,&apos;,
 &apos;this&apos;,
 &apos;is&apos;,
 &apos;not&apos;,
 &apos;a&apos;,
 &apos;horror&apos;,
 &apos;or&apos;,
 &apos;teen&apos;,
 &apos;slasher&apos;,
 &apos;flick&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;it&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;just&apos;,
 &apos;packaged&apos;,
 &apos;to&apos;,
 &apos;look&apos;,
 &apos;that&apos;,
 &apos;way&apos;,
 &apos;because&apos;,
 &apos;someone&apos;,
 &apos;is&apos;,
 &apos;apparently&apos;,
 &apos;assuming&apos;,
 &apos;that&apos;,
 &apos;the&apos;,
 &apos;genre&apos;,
 &apos;is&apos;,
 &apos;still&apos;,
 &apos;hot&apos;,
 &apos;with&apos;,
 &apos;the&apos;,
 &apos;kids&apos;,
 &apos;.&apos;,
 &apos;it&apos;,
 &apos;also&apos;,
 &apos;wrapped&apos;,
 &apos;production&apos;,
 &apos;two&apos;,
 &apos;years&apos;,
 &apos;ago&apos;,
 &apos;and&apos;,
 &apos;has&apos;,
 &apos;been&apos;,
 &apos;sitting&apos;,
 &apos;on&apos;,
 &apos;the&apos;,
 &apos;shelves&apos;,
 &apos;ever&apos;,
 &apos;since&apos;,
 &apos;.&apos;,
 &apos;whatever&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;skip&apos;,
 &apos;it&apos;,
 &apos;!&apos;,
 &apos;where&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;joblo&apos;,
 &apos;coming&apos;,
 &apos;from&apos;,
 &apos;?&apos;,
 &apos;a&apos;,
 &apos;nightmare&apos;,
 &apos;of&apos;,
 &apos;elm&apos;,
 &apos;street&apos;,
 &apos;3&apos;,
 &apos;(&apos;,
 &apos;7&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;blair&apos;,
 &apos;witch&apos;,
 &apos;2&apos;,
 &apos;(&apos;,
 &apos;7&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;the&apos;,
 &apos;crow&apos;,
 &apos;(&apos;,
 &apos;9&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;the&apos;,
 &apos;crow&apos;,
 &apos;:&apos;,
 &apos;salvation&apos;,
 &apos;(&apos;,
 &apos;4&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;lost&apos;,
 &apos;highway&apos;,
 &apos;(&apos;,
 &apos;10&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;memento&apos;,
 &apos;(&apos;,
 &apos;10&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;the&apos;,
 &apos;others&apos;,
 &apos;(&apos;,
 &apos;9&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;-&apos;,
 &apos;stir&apos;,
 &apos;of&apos;,
 &apos;echoes&apos;,
 &apos;(&apos;,
 &apos;8&apos;,
 &apos;/&apos;,
 &apos;10&apos;,
 &apos;)&apos;,
 &apos;the&apos;,
 &apos;happy&apos;,
 &apos;bastard&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;quick&apos;,
 &apos;movie&apos;,
 &apos;review&apos;,
 &apos;damn&apos;,
 &apos;that&apos;,
 &apos;y2k&apos;,
 &apos;bug&apos;,
 &apos;.&apos;,
 &apos;it&apos;,
 &quot;&apos;&quot;,
 &apos;s&apos;,
 &apos;got&apos;,
 &apos;a&apos;,
 &apos;head&apos;,
 &apos;start&apos;,
 &apos;in&apos;,
 &apos;this&apos;,
 &apos;movie&apos;,
 &apos;starring&apos;,
 &apos;jamie&apos;,
 &apos;lee&apos;,
 &apos;curtis&apos;,
 &apos;and&apos;,
 &apos;another&apos;,
 &apos;baldwin&apos;,
 &apos;brother&apos;,
 &apos;(&apos;,
 &apos;william&apos;,
 &apos;this&apos;,
 &apos;time&apos;,
 &apos;)&apos;,
 &apos;in&apos;,
 &apos;a&apos;,
 &apos;story&apos;,
 &apos;regarding&apos;,
 &apos;a&apos;,
 &apos;crew&apos;,
 &apos;of&apos;,
 &apos;a&apos;,
 &apos;tugboat&apos;,
 &apos;that&apos;,
 &apos;comes&apos;,
 &apos;across&apos;,
 &apos;a&apos;,
 &apos;deserted&apos;,
 &apos;russian&apos;,
 &apos;tech&apos;,
 &apos;ship&apos;,
 &apos;that&apos;,
 &apos;has&apos;,
 &apos;a&apos;,
 &apos;strangeness&apos;,
 &apos;to&apos;,
 &apos;it&apos;,
 &apos;when&apos;,
 &apos;they&apos;,
 &apos;kick&apos;,
 &apos;the&apos;,
 &apos;power&apos;,
 &apos;back&apos;,
 &apos;on&apos;,
 &apos;.&apos;,
 &apos;little&apos;,
 &apos;do&apos;,
 &apos;they&apos;,
 &apos;know&apos;,
 &apos;the&apos;,
 &apos;power&apos;,
 &apos;within&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;.&apos;,
 &apos;going&apos;,
 &apos;for&apos;,
 &apos;the&apos;,
 &apos;gore&apos;,
 &apos;and&apos;,
 &apos;bringing&apos;,
 &apos;on&apos;,
 &apos;a&apos;,
 &apos;few&apos;,
 &apos;action&apos;,
 &apos;sequences&apos;,
 &apos;here&apos;,
 &apos;and&apos;,
 &apos;there&apos;,
 &apos;,&apos;,
 &apos;virus&apos;,
 &apos;still&apos;,
 &apos;feels&apos;,
 &apos;very&apos;,
 &apos;empty&apos;,
 &apos;,&apos;,
 &apos;like&apos;,
 &apos;a&apos;,
 &apos;movie&apos;,
 &apos;going&apos;,
 &apos;for&apos;,
 &apos;all&apos;,
 &apos;flash&apos;,
 &apos;and&apos;,
 &apos;no&apos;,
 &apos;substance&apos;,
 &apos;.&apos;,
 &apos;we&apos;,
 &apos;don&apos;,
 &quot;&apos;&quot;,
 &apos;t&apos;,
 &apos;know&apos;,
 &apos;why&apos;,
 &apos;the&apos;,
 &apos;crew&apos;,
 &apos;was&apos;,
 &apos;really&apos;,
 &apos;out&apos;,
 &apos;in&apos;,
 ...]
</code></pre><p><strong>Warning</strong>:At the begining, I just writed the follow codes like this:<code>new_all_words = [w for w in all_words if w not in nltk.corpus.stopwords.words(&#39;english&#39;)</code>,however the code couldn’t complite successfully even I had been waiting for several minites. Finally, I found that the I/O operations can be 1583820 times, and the operation system read data from the hark disk again and again without saying any thing,it was so stupid.So when we programming,we should set the I/O resources as a variable if it will be used for several times. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stopwords = nltk.corpus.stopwords.words(<span class="string">'english'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new_all_words = [w <span class="keyword">for</span> w <span class="keyword">in</span> all_words <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new_all_words = [w <span class="keyword">for</span> w <span class="keyword">in</span> new_all_words <span class="keyword">if</span> w.isalpha()]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(all_words)</span><br></pre></td></tr></table></figure>
<pre><code>1583820
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(nltk.corpus.stopwords.words(<span class="string">'english'</span>))</span><br></pre></td></tr></table></figure>
<pre><code>179
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nltk.corpus.stopwords.words(<span class="string">'english'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;i&apos;,
 &apos;me&apos;,
 &apos;my&apos;,
 &apos;myself&apos;,
 &apos;we&apos;,
 &apos;our&apos;,
 &apos;ours&apos;,
 &apos;ourselves&apos;,
 &apos;you&apos;,
 &quot;you&apos;re&quot;,
 &quot;you&apos;ve&quot;,
 &quot;you&apos;ll&quot;,
 &quot;you&apos;d&quot;,
 &apos;your&apos;,
 &apos;yours&apos;,
 &apos;yourself&apos;,
 &apos;yourselves&apos;,
 &apos;he&apos;,
 &apos;him&apos;,
 &apos;his&apos;,
 &apos;himself&apos;,
 &apos;she&apos;,
 &quot;she&apos;s&quot;,
 &apos;her&apos;,
 &apos;hers&apos;,
 &apos;herself&apos;,
 &apos;it&apos;,
 &quot;it&apos;s&quot;,
 &apos;its&apos;,
 &apos;itself&apos;,
 &apos;they&apos;,
 &apos;them&apos;,
 &apos;their&apos;,
 &apos;theirs&apos;,
 &apos;themselves&apos;,
 &apos;what&apos;,
 &apos;which&apos;,
 &apos;who&apos;,
 &apos;whom&apos;,
 &apos;this&apos;,
 &apos;that&apos;,
 &quot;that&apos;ll&quot;,
 &apos;these&apos;,
 &apos;those&apos;,
 &apos;am&apos;,
 &apos;is&apos;,
 &apos;are&apos;,
 &apos;was&apos;,
 &apos;were&apos;,
 &apos;be&apos;,
 &apos;been&apos;,
 &apos;being&apos;,
 &apos;have&apos;,
 &apos;has&apos;,
 &apos;had&apos;,
 &apos;having&apos;,
 &apos;do&apos;,
 &apos;does&apos;,
 &apos;did&apos;,
 &apos;doing&apos;,
 &apos;a&apos;,
 &apos;an&apos;,
 &apos;the&apos;,
 &apos;and&apos;,
 &apos;but&apos;,
 &apos;if&apos;,
 &apos;or&apos;,
 &apos;because&apos;,
 &apos;as&apos;,
 &apos;until&apos;,
 &apos;while&apos;,
 &apos;of&apos;,
 &apos;at&apos;,
 &apos;by&apos;,
 &apos;for&apos;,
 &apos;with&apos;,
 &apos;about&apos;,
 &apos;against&apos;,
 &apos;between&apos;,
 &apos;into&apos;,
 &apos;through&apos;,
 &apos;during&apos;,
 &apos;before&apos;,
 &apos;after&apos;,
 &apos;above&apos;,
 &apos;below&apos;,
 &apos;to&apos;,
 &apos;from&apos;,
 &apos;up&apos;,
 &apos;down&apos;,
 &apos;in&apos;,
 &apos;out&apos;,
 &apos;on&apos;,
 &apos;off&apos;,
 &apos;over&apos;,
 &apos;under&apos;,
 &apos;again&apos;,
 &apos;further&apos;,
 &apos;then&apos;,
 &apos;once&apos;,
 &apos;here&apos;,
 &apos;there&apos;,
 &apos;when&apos;,
 &apos;where&apos;,
 &apos;why&apos;,
 &apos;how&apos;,
 &apos;all&apos;,
 &apos;any&apos;,
 &apos;both&apos;,
 &apos;each&apos;,
 &apos;few&apos;,
 &apos;more&apos;,
 &apos;most&apos;,
 &apos;other&apos;,
 &apos;some&apos;,
 &apos;such&apos;,
 &apos;no&apos;,
 &apos;nor&apos;,
 &apos;not&apos;,
 &apos;only&apos;,
 &apos;own&apos;,
 &apos;same&apos;,
 &apos;so&apos;,
 &apos;than&apos;,
 &apos;too&apos;,
 &apos;very&apos;,
 &apos;s&apos;,
 &apos;t&apos;,
 &apos;can&apos;,
 &apos;will&apos;,
 &apos;just&apos;,
 &apos;don&apos;,
 &quot;don&apos;t&quot;,
 &apos;should&apos;,
 &quot;should&apos;ve&quot;,
 &apos;now&apos;,
 &apos;d&apos;,
 &apos;ll&apos;,
 &apos;m&apos;,
 &apos;o&apos;,
 &apos;re&apos;,
 &apos;ve&apos;,
 &apos;y&apos;,
 &apos;ain&apos;,
 &apos;aren&apos;,
 &quot;aren&apos;t&quot;,
 &apos;couldn&apos;,
 &quot;couldn&apos;t&quot;,
 &apos;didn&apos;,
 &quot;didn&apos;t&quot;,
 &apos;doesn&apos;,
 &quot;doesn&apos;t&quot;,
 &apos;hadn&apos;,
 &quot;hadn&apos;t&quot;,
 &apos;hasn&apos;,
 &quot;hasn&apos;t&quot;,
 &apos;haven&apos;,
 &quot;haven&apos;t&quot;,
 &apos;isn&apos;,
 &quot;isn&apos;t&quot;,
 &apos;ma&apos;,
 &apos;mightn&apos;,
 &quot;mightn&apos;t&quot;,
 &apos;mustn&apos;,
 &quot;mustn&apos;t&quot;,
 &apos;needn&apos;,
 &quot;needn&apos;t&quot;,
 &apos;shan&apos;,
 &quot;shan&apos;t&quot;,
 &apos;shouldn&apos;,
 &quot;shouldn&apos;t&quot;,
 &apos;wasn&apos;,
 &quot;wasn&apos;t&quot;,
 &apos;weren&apos;,
 &quot;weren&apos;t&quot;,
 &apos;won&apos;,
 &quot;won&apos;t&quot;,
 &apos;wouldn&apos;,
 &quot;wouldn&apos;t&quot;]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">words_freqlist = nltk.FreqDist(new_all_words)</span><br><span class="line">print(words_freqlist.most_common(<span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<pre><code>[(&apos;film&apos;, 9517), (&apos;one&apos;, 5852), (&apos;movie&apos;, 5771), (&apos;like&apos;, 3690), (&apos;even&apos;, 2565), (&apos;good&apos;, 2411), (&apos;time&apos;, 2411), (&apos;story&apos;, 2169), (&apos;would&apos;, 2109), (&apos;much&apos;, 2049)]
</code></pre><h3 id="12-Words-as-Features-for-Learning-用来学习的特征词汇"><a href="#12-Words-as-Features-for-Learning-用来学习的特征词汇" class="headerlink" title="12. Words as Features for Learning(用来学习的特征词汇)"></a>12. Words as Features for Learning(用来学习的特征词汇)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">word_features = list(words_freqlist.keys())[:<span class="number">3000</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_features</span><span class="params">(document)</span>:</span></span><br><span class="line">    words = set(document)</span><br><span class="line">    features = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> word_features:</span><br><span class="line">        features[w] = (w <span class="keyword">in</span> words)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> features</span><br><span class="line">featuresets = [(find_features(rev), category) <span class="keyword">for</span> (rev, category) <span class="keyword">in</span> documents]</span><br></pre></td></tr></table></figure>
<h3 id="13-Naive-Bayes-朴素贝叶斯"><a href="#13-Naive-Bayes-朴素贝叶斯" class="headerlink" title="13. Naive Bayes(朴素贝叶斯)"></a>13. Naive Bayes(朴素贝叶斯)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">training_set = featuresets[:<span class="number">1900</span>]</span><br><span class="line">testing_set = featuresets[<span class="number">1900</span>:]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">classifier = nltk.NaiveBayesClassifier.train(training_set)</span><br><span class="line">print(<span class="string">"Naive Bayes Algo accuracy:"</span>,(nltk.classify.accuracy(classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Naive Bayes Algo accuracy: 84.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classifier.show_most_informative_features(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Most Informative Features
                   sucks = True              neg : pos    =      8.7 : 1.0
                  annual = True              pos : neg    =      8.2 : 1.0
                 frances = True              pos : neg    =      8.2 : 1.0
           unimaginative = True              neg : pos    =      7.8 : 1.0
                 idiotic = True              neg : pos    =      7.3 : 1.0
              schumacher = True              neg : pos    =      7.1 : 1.0
                    mena = True              neg : pos    =      7.1 : 1.0
               atrocious = True              neg : pos    =      7.1 : 1.0
             silverstone = True              neg : pos    =      7.1 : 1.0
                  suvari = True              neg : pos    =      7.1 : 1.0
                  turkey = True              neg : pos    =      6.7 : 1.0
                  regard = True              pos : neg    =      6.5 : 1.0
                 kidding = True              neg : pos    =      6.4 : 1.0
                  crappy = True              neg : pos    =      6.4 : 1.0
                  shoddy = True              neg : pos    =      6.4 : 1.0
</code></pre><h3 id="14-Save-Classifier-with-Pickle-使用Pickle保存分类器"><a href="#14-Save-Classifier-with-Pickle-使用Pickle保存分类器" class="headerlink" title="14. Save Classifier with Pickle(使用Pickle保存分类器)"></a>14. Save Classifier with Pickle(使用Pickle保存分类器)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">'naivebayes.pickle'</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">classifier_f = open(<span class="string">'naivebayes.pickle'</span>,<span class="string">"rb"</span>)</span><br><span class="line">classifier = pickle.load(classifier_f)</span><br><span class="line">classifier_f.close()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Naive Bayes Algo accuracy:"</span>,(nltk.classify.accuracy(classifier,testing_set))*<span class="number">100</span>)</span><br><span class="line">classifier.show_most_informative_features(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Naive Bayes Algo accuracy: 84.0
Most Informative Features
                   sucks = True              neg : pos    =      8.7 : 1.0
                  annual = True              pos : neg    =      8.2 : 1.0
                 frances = True              pos : neg    =      8.2 : 1.0
           unimaginative = True              neg : pos    =      7.8 : 1.0
                 idiotic = True              neg : pos    =      7.3 : 1.0
              schumacher = True              neg : pos    =      7.1 : 1.0
                    mena = True              neg : pos    =      7.1 : 1.0
               atrocious = True              neg : pos    =      7.1 : 1.0
             silverstone = True              neg : pos    =      7.1 : 1.0
                  suvari = True              neg : pos    =      7.1 : 1.0
                  turkey = True              neg : pos    =      6.7 : 1.0
                  regard = True              pos : neg    =      6.5 : 1.0
                 kidding = True              neg : pos    =      6.4 : 1.0
                  crappy = True              neg : pos    =      6.4 : 1.0
                  shoddy = True              neg : pos    =      6.4 : 1.0
</code></pre><p>training again</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">random.shuffle(documents)</span><br><span class="line">all_words = [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> movie_reviews.words()]</span><br><span class="line">new_all_words = [w <span class="keyword">for</span> w <span class="keyword">in</span> all_words <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</span><br><span class="line">new_all_words = [w <span class="keyword">for</span> w <span class="keyword">in</span> new_all_words <span class="keyword">if</span> w.isalpha()]</span><br><span class="line">words_freqlist = nltk.FreqDist(new_all_words)</span><br><span class="line">word_features = list(words_freqlist.keys())[:<span class="number">3000</span>]</span><br><span class="line">training_set = featuresets[:<span class="number">1900</span>]</span><br><span class="line">testing_set = featuresets[<span class="number">1900</span>:]</span><br><span class="line">classifier = nltk.NaiveBayesClassifier.train(training_set)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Naive Bayes Algo accuracy:"</span>,(nltk.classify.accuracy(classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Naive Bayes Algo accuracy: 84.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">classifier_f = open(<span class="string">'naivebayes.pickle'</span>,<span class="string">"rb"</span>)</span><br><span class="line">classifier = pickle.load(classifier_f)</span><br><span class="line">classifier_f.close()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Naive Bayes Algo accuracy:"</span>,(nltk.classify.accuracy(classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Naive Bayes Algo accuracy: 84.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Naive Bayes Algo accuracy:"</span>,(nltk.classify.accuracy(classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Naive Bayes Algo accuracy: 84.0
</code></pre><h3 id="15-Scikit-Learn-incorporation"><a href="#15-Scikit-Learn-incorporation" class="headerlink" title="15. Scikit-Learn incorporation()"></a>15. Scikit-Learn incorporation()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.classify.scikitlearn <span class="keyword">import</span> SklearnClassifier</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB, GaussianNB, BernoulliNB</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MNB_classifier = SklearnClassifier(MultinomialNB())</span><br><span class="line">MNB_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"MNB_classifier accuracy percent:"</span>,(nltk.classify.accuracy(MNB_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>MNB_classifier accuracy percent: 82.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这段代码有问题，不可以运行。</span></span><br><span class="line">GNB_classifier = SklearnClassifier(GaussianNB())</span><br><span class="line">GNB_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"GNB_classifier accuracy percent:"</span>,(nltk.classify.accuracy(GNB_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

&lt;ipython-input-149-dbf69e211330&gt; in &lt;module&gt;()
      1 GNB_classifier = SklearnClassifier(GaussianNB())
----&gt; 2 GNB_classifier.train(training_set)
      3 print(&quot;GNB_classifier accuracy percent:&quot;,(nltk.classify.accuracy(GNB_classifier,testing_set))*100)


C:\Program Files\Anaconda3\lib\site-packages\nltk\classify\scikitlearn.py in train(self, labeled_featuresets)
    117         X = self._vectorizer.fit_transform(X)
    118         y = self._encoder.fit_transform(y)
--&gt; 119         self._clf.fit(X, y)
    120 
    121         return self


C:\Program Files\Anaconda3\lib\site-packages\sklearn\naive_bayes.py in fit(self, X, y, sample_weight)
    180             Returns self.
    181         &quot;&quot;&quot;
--&gt; 182         X, y = check_X_y(X, y)
    183         return self._partial_fit(X, y, np.unique(y), _refit=True,
    184                                  sample_weight=sample_weight)


C:\Program Files\Anaconda3\lib\site-packages\sklearn\utils\validation.py in check_X_y(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)
    519     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,
    520                     ensure_2d, allow_nd, ensure_min_samples,
--&gt; 521                     ensure_min_features, warn_on_dtype, estimator)
    522     if multi_output:
    523         y = check_array(y, &apos;csr&apos;, force_all_finite=True, ensure_2d=False,


C:\Program Files\Anaconda3\lib\site-packages\sklearn\utils\validation.py in check_array(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)
    378     if sp.issparse(array):
    379         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,
--&gt; 380                                       force_all_finite)
    381     else:
    382         array = np.array(array, dtype=dtype, order=order, copy=copy)


C:\Program Files\Anaconda3\lib\site-packages\sklearn\utils\validation.py in _ensure_sparse_format(spmatrix, accept_sparse, dtype, copy, force_all_finite)
    241     &quot;&quot;&quot;
    242     if accept_sparse in [None, False]:
--&gt; 243         raise TypeError(&apos;A sparse matrix was passed, but dense &apos;
    244                         &apos;data is required. Use X.toarray() to &apos;
    245                         &apos;convert to a dense numpy array.&apos;)


TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">BNB_classifier = SklearnClassifier(BernoulliNB())</span><br><span class="line">BNB_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"BNB_classifier accuracy percent:"</span>,(nltk.classify.accuracy(BNB_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>BNB_classifier accuracy percent: 84.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression, SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC, LinearSVC, NuSVC</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LogisticRegression_classifier = SklearnClassifier(LogisticRegression())</span><br><span class="line">LogisticRegression_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"LogisticRegression_classifier accuracy percent:"</span>,(nltk.classify.accuracy(LogisticRegression_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>LogisticRegression_classifier accuracy percent: 82.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SGDClassifier_classifier = SklearnClassifier(SGDClassifier())</span><br><span class="line">SGDClassifier_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"SGDClassifier_classifier accuracy percent:"</span>,(nltk.classify.accuracy(SGDClassifier_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>SGDClassifier_classifier accuracy percent: 82.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SVC_classifier = SklearnClassifier(SVC())</span><br><span class="line">SVC_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"SVC_classifier accuracy percent:"</span>,(nltk.classify.accuracy(SVC_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>SVC_classifier accuracy percent: 82.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LinearSVC_classifier = SklearnClassifier(LinearSVC())</span><br><span class="line">LinearSVC_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"LinearSVC_classifier accuracy percent:"</span>,(nltk.classify.accuracy(LinearSVC_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>LinearSVC_classifier accuracy percent: 80.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NuSVC_classifier = SklearnClassifier(NuSVC())</span><br><span class="line">NuSVC_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"NuSVC_classifier accuracy percent:"</span>,(nltk.classify.accuracy(NuSVC_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>NuSVC_classifier accuracy percent: 82.0
</code></pre><h3 id="16-Combining-Algos-with-a-Vote"><a href="#16-Combining-Algos-with-a-Vote" class="headerlink" title="16. Combining Algos with a Vote"></a>16. Combining Algos with a Vote</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.classify <span class="keyword">import</span> ClassifierI</span><br><span class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mode</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VoteClassifier</span><span class="params">(ClassifierI)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *classifiers)</span>:</span></span><br><span class="line">        self._classifiers = classifiers</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(self, features)</span>:</span></span><br><span class="line">        votes = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self._classifiers:</span><br><span class="line">            v = c.classify(features)</span><br><span class="line">            votes.append(v)</span><br><span class="line">        <span class="keyword">return</span> mode(votes)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">confidence</span><span class="params">(self,features)</span>:</span></span><br><span class="line">        votes = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self._classifiers:</span><br><span class="line">            v = c.classify(features)</span><br><span class="line">            votes.append(v)</span><br><span class="line">        </span><br><span class="line">        choice_votes = votes.count(mode(votes))</span><br><span class="line">        conf = choice_votes / len(votes)</span><br><span class="line">        <span class="keyword">return</span> conf</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">voted_classifier = VoteClassifier(classifier,</span><br><span class="line">                                  MNB_classifier,</span><br><span class="line">                                  BNB_classifier,</span><br><span class="line">                                  LogisticRegression_classifier,</span><br><span class="line">                                  SGDClassifier_classifier,</span><br><span class="line">                                 <span class="comment">#SVC_classifier,视频中没有这个，况且如果不注释掉就会报统计错误，说有两个相同的值。</span></span><br><span class="line">                                 <span class="comment">#如： http://blog.csdn.net/dongfuguo/article/details/50163757 中 mode错误一般</span></span><br><span class="line">                                 LinearSVC_classifier,</span><br><span class="line">                                 NuSVC_classifier)</span><br><span class="line">print(<span class="string">"voted_classifier accuracy percent:"</span>,(nltk.classify.accuracy(voted_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>voted_classifier accuracy percent: 81.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">0</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">0</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: neg Confidence %: 100.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">1</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">1</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: pos Confidence %: 100.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">2</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">2</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: pos Confidence %: 100.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">3</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">3</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: neg Confidence %: 87.5
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">4</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">4</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: pos Confidence %: 100.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">5</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">5</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: neg Confidence %: 75.0
</code></pre><h3 id="17-Investigating-Bias"><a href="#17-Investigating-Bias" class="headerlink" title="17. Investigating Bias()"></a>17. Investigating Bias()</h3><h3 id="18-Better-training-data"><a href="#18-Better-training-data" class="headerlink" title="18. Better training data()"></a>18. Better training data()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">short_pos = open(<span class="string">"short_reviews/positive.txt"</span>,<span class="string">"r"</span>,encoding=<span class="string">"unicode-escape"</span>).read()</span><br><span class="line">short_neg = open(<span class="string">"short_reviews/negative.txt"</span>,<span class="string">"r"</span>,encoding=<span class="string">"unicode-escape"</span>).read()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">short_pos[:<span class="number">300</span>]</span><br></pre></td></tr></table></figure>
<pre><code>&apos;the rock is destined to be the 21st century\&apos;s new &quot; conan &quot; and that he\&apos;s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \nthe gorgeously elaborate continuation of &quot; the lord of the rings &quot; trilogy is so huge that a column of words cannot adequ&apos;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">documents = []</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># map(lambda r : document.append(r,'pos'), [r for r in short_pos.split('\n')])</span></span><br><span class="line"><span class="comment"># 本来想通过类似foreach实现类似的功能，不过好像并不能成功，目前原因还不清楚。</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">documents.extend([(r,<span class="string">"pos"</span>) <span class="keyword">for</span> r <span class="keyword">in</span> short_pos.split(<span class="string">'\n'</span>)])</span><br><span class="line"><span class="comment"># 和下面语句的作用是一样的，不过不知道哪个效率更高一些</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> short_pos.split(<span class="string">'\n'</span>):</span><br><span class="line">    documents.append((r,<span class="string">'pos'</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">documents[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<pre><code>(&apos;the rock is destined to be the 21st century\&apos;s new &quot; conan &quot; and that he\&apos;s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . &apos;,
 &apos;pos&apos;)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">documents.extend([(r,<span class="string">"neg"</span>) <span class="keyword">for</span> r <span class="keyword">in</span> short_neg.split(<span class="string">'\n'</span>)])</span><br><span class="line"><span class="comment"># 和下面语句的作用是一样的，不过不知道哪个效率更高一些</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> short_neg.split(<span class="string">'\n'</span>):</span><br><span class="line">    documents.append(w.lower())</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="comment"># 这里之所以再次导入，仅仅是因为我是几次使用这个notebook，懒得运行前面的cell了。</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_words = []</span><br><span class="line">short_pos_words = nltk.word_tokenize(short_pos)</span><br><span class="line">short_neg_words = nltk.word_tokenize(short_neg)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_words.extend([w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> short_pos_words])</span><br><span class="line">all_words.extend([w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> short_neg_words])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以上代码应该也可以写成：</span></span><br><span class="line">all_words = [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> short_pos_words] + [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> short_pos_words]</span><br><span class="line"><span class="comment">#甚至是这样：</span></span><br><span class="line">all_words = [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> short_pos_words+short_neg_words]</span><br><span class="line"><span class="comment"># 不过如果先：</span></span><br><span class="line">all_words = short_pos_words + short_neg_words</span><br><span class="line"><span class="comment"># 再：</span></span><br><span class="line">all_words = [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> all_words]</span><br><span class="line"><span class="comment"># 可能效率更高一些吧？</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stopwords = nltk.corpus.stopwords.words(<span class="string">'english'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_words = [w <span class="keyword">for</span> w <span class="keyword">in</span> all_words <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</span><br><span class="line"><span class="comment"># 我自己添加的去除停用词等无关信息，以使得特征提取和训练的效率更高</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_words = nltk.FreqDist(all_words)</span><br><span class="line">word_features = list(all_words.keys())[:<span class="number">5000</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_features</span><span class="params">(document)</span>:</span></span><br><span class="line">    words = nltk.word_tokenize(document)</span><br><span class="line">    features = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> word_features:</span><br><span class="line">        features[w] = (w <span class="keyword">in</span> words)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> features</span><br><span class="line">featuresets = [(find_features(rev), category) <span class="keyword">for</span> (rev, category) <span class="keyword">in</span> documents]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">random.shuffle(featuresets)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">training_set = featuresets[:<span class="number">10000</span>]</span><br><span class="line">testing_set = featuresets[<span class="number">10000</span>:]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">classifier = nltk.NaiveBayesClassifier.train(training_set)</span><br><span class="line">print(<span class="string">"Naive Bayes Algo accuracy:"</span>,(nltk.classify.accuracy(classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Naive Bayes Algo accuracy: 68.82530120481928
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.classify.scikitlearn <span class="keyword">import</span> SklearnClassifier</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB, GaussianNB, BernoulliNB</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MNB_classifier = SklearnClassifier(MultinomialNB())</span><br><span class="line">MNB_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"MNB_classifier accuracy percent:"</span>,(nltk.classify.accuracy(MNB_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>MNB_classifier accuracy percent: 67.46987951807229
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这段代码有问题，不可以运行</span></span><br><span class="line">GNB_classifier = SklearnClassifier(GaussianNB())</span><br><span class="line">GNB_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"GNB_classifier accuracy percent:"</span>,(nltk.classify.accuracy(GNB_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">BNB_classifier = SklearnClassifier(BernoulliNB())</span><br><span class="line">BNB_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"BNB_classifier accuracy percent:"</span>,(nltk.classify.accuracy(BNB_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>BNB_classifier accuracy percent: 68.97590361445783
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression, SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC, LinearSVC, NuSVC</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LogisticRegression_classifier = SklearnClassifier(LogisticRegression())</span><br><span class="line">LogisticRegression_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"LogisticRegression_classifier accuracy percent:"</span>,(nltk.classify.accuracy(LogisticRegression_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>LogisticRegression_classifier accuracy percent: 70.78313253012048
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SGDClassifier_classifier = SklearnClassifier(SGDClassifier())</span><br><span class="line">SGDClassifier_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"SGDClassifier_classifier accuracy percent:"</span>,(nltk.classify.accuracy(SGDClassifier_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>SGDClassifier_classifier accuracy percent: 66.1144578313253
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SVC_classifier = SklearnClassifier(SVC())</span><br><span class="line">SVC_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"SVC_classifier accuracy percent:"</span>,(nltk.classify.accuracy(SVC_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>SVC_classifier accuracy percent: 49.096385542168676
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LinearSVC_classifier = SklearnClassifier(LinearSVC())</span><br><span class="line">LinearSVC_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"LinearSVC_classifier accuracy percent:"</span>,(nltk.classify.accuracy(LinearSVC_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>LinearSVC_classifier accuracy percent: 70.48192771084338
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NuSVC_classifier = SklearnClassifier(NuSVC())</span><br><span class="line">NuSVC_classifier.train(training_set)</span><br><span class="line">print(<span class="string">"NuSVC_classifier accuracy percent:"</span>,(nltk.classify.accuracy(NuSVC_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>NuSVC_classifier accuracy percent: 69.7289156626506
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.classify <span class="keyword">import</span> ClassifierI</span><br><span class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mode</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VoteClassifier</span><span class="params">(ClassifierI)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *classifiers)</span>:</span></span><br><span class="line">        self._classifiers = classifiers</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(self, features)</span>:</span></span><br><span class="line">        votes = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self._classifiers:</span><br><span class="line">            v = c.classify(features)</span><br><span class="line">            votes.append(v)</span><br><span class="line">        <span class="keyword">return</span> mode(votes)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">confidence</span><span class="params">(self,features)</span>:</span></span><br><span class="line">        votes = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self._classifiers:</span><br><span class="line">            v = c.classify(features)</span><br><span class="line">            votes.append(v)</span><br><span class="line">        </span><br><span class="line">        choice_votes = votes.count(mode(votes))</span><br><span class="line">        conf = choice_votes / len(votes)</span><br><span class="line">        <span class="keyword">return</span> conf</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">voted_classifier = VoteClassifier(classifier,</span><br><span class="line">                                  MNB_classifier,</span><br><span class="line">                                  BNB_classifier,</span><br><span class="line">                                  LogisticRegression_classifier,</span><br><span class="line">                                  SGDClassifier_classifier,</span><br><span class="line">                                 <span class="comment">#SVC_classifier,视频中没有这个，况且如果不注释掉就会报统计错误，说有两个相同的值。</span></span><br><span class="line">                                 <span class="comment">#如： http://blog.csdn.net/dongfuguo/article/details/50163757 中 mode错误一般</span></span><br><span class="line">                                 LinearSVC_classifier,</span><br><span class="line">                                 NuSVC_classifier)</span><br><span class="line">print(<span class="string">"voted_classifier accuracy percent:"</span>,(nltk.classify.accuracy(voted_classifier,testing_set))*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>voted_classifier accuracy percent: 69.42771084337349
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Classification:"</span>,voted_classifier.classify(testing_set[<span class="number">0</span>][<span class="number">0</span>]),<span class="string">"Confidence %:"</span>,voted_classifier.confidence(testing_set[<span class="number">0</span>][<span class="number">0</span>])*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Classification: pos Confidence %: 100.0
</code></pre><h3 id="19-Sentiment-Analysis-Module"><a href="#19-Sentiment-Analysis-Module" class="headerlink" title="19. Sentiment Analysis Module()"></a>19. Sentiment Analysis Module()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_words = []</span><br><span class="line">documents = []</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allowed_word_types = [<span class="string">"J"</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> short_pos.split(<span class="string">'\n'</span>):</span><br><span class="line">    documents.append((p,<span class="string">"pos"</span>))</span><br><span class="line">    words = nltk.word_tokenize(p)</span><br><span class="line">    pos = nltk.pos_tag(words)</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> pos:</span><br><span class="line">        <span class="keyword">if</span> w[<span class="number">1</span>][<span class="number">0</span>] <span class="keyword">in</span> allowed_word_types:</span><br><span class="line">            all_words.append(w[<span class="number">0</span>].lower())</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> short_neg.split(<span class="string">'\n'</span>):</span><br><span class="line">    documents.append((p,<span class="string">"neg"</span>))</span><br><span class="line">    words = nltk.word_tokenize(p)</span><br><span class="line">    neg = nltk.pos_tag(words)</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> neg:</span><br><span class="line">        <span class="keyword">if</span> w[<span class="number">1</span>][<span class="number">0</span>] <span class="keyword">in</span> allowed_word_types:</span><br><span class="line">            all_words.append(w[<span class="number">0</span>].lower())</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br></pre></td></tr></table></figure>
<p>提醒一下：直接运行以下的cell 会报错，应该先创建一个pickled_algos文件夹，然后再运行cell</p>
<p>保存文档</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_documents = open(<span class="string">'pickled_algos/documents.pickle'</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(documents, save_documents)</span><br><span class="line">save_documents.close()</span><br></pre></td></tr></table></figure>
<p>保存文本特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_words = nltk.FreqDist(all_words)</span><br><span class="line">word_features = list(all_words.keys())[:<span class="number">5000</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_word_features = open(<span class="string">'pickled_algos/word_features5k.pickle'</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(word_features,save_word_features)</span><br><span class="line">save_word_features.close()</span><br></pre></td></tr></table></figure>
<p>保存朴素贝叶斯算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">"pickled_algos/originalnaivebayes5k.pickle"</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<p>保存MultinomialNB算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">"pickled_algos/MNB_classifier5k.pickle"</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(MNB_classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<p>保存BernoulliNB算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">"pickled_algos/BNB_classifier5k.pickle"</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(BNB_classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<p>保存LogisticRegression算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">"pickled_algos/LogisticRegression_classifier5k.pickle"</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(LogisticRegression_classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<p>保存LinearSVC算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">"pickled_algos/LinearSVC_classifier5k.pickle"</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(LinearSVC_classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<p>保存SGDC算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save_classifier = open(<span class="string">"pickled_algos/SGDClassifier_classifier5k.pickle"</span>,<span class="string">"wb"</span>)</span><br><span class="line">pickle.dump(SGDClassifier_classifier,save_classifier)</span><br><span class="line">save_classifier.close()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">voted_classifier = VoteClassifier(classifier,</span><br><span class="line">                                 LinearSVC_classifier,</span><br><span class="line">                                 MNB_classifier,</span><br><span class="line">                                 BNB_classifier,</span><br><span class="line">                                 LogisticRegression_classifier)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentiment</span><span class="params">(text)</span>:</span></span><br><span class="line">    feats = find_features(text)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> voted_classifier.classify(feats)</span><br></pre></td></tr></table></figure>
<p>最终我们编写的模块长成这个样子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#File: sentiment_mod.py 只是一个文件名而已，可以按照自己的想法取，但应做到见名知意</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> nltk.classify.scikitlearn <span class="keyword">import</span> SklearnClassifier</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB,BernoulliNB</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression,SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC, LinearSVC,NuSVC</span><br><span class="line"><span class="keyword">from</span> nltk.classify <span class="keyword">import</span> ClassifierI</span><br><span class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mode</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以上许多类模块虽然在代码中看似并没有用到，可是在用pickle还原为相关实例在被外部调用执行的时候还是需要的。</span></span><br><span class="line"><span class="comment"># 这里由于我们之前已经训练好了几个分类器，并且已经将文档内容和文本特征等通过pickle持久化保存起来了，所以在此模块中直接用pickle还原就可以直接拿来用了，而不是再次训练。</span></span><br><span class="line"><span class="comment"># 并且该模块仅当同一路径下的pickled_algos文件夹及里面的各pickle文件同时存在时才可以正常使用，当然，项目中也要导入本模块需要使用的一些基础模块，如nltk等等。</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VoteClassifier</span><span class="params">(ClassifierI)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *classifiers)</span>:</span></span><br><span class="line">        self._classifiers = classifiers</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(self, features)</span>:</span></span><br><span class="line">        votes = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self._classifiers:</span><br><span class="line">            v = c.classify(features)</span><br><span class="line">            votes.append(v)</span><br><span class="line">        <span class="keyword">return</span> mode(votes)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">confidence</span><span class="params">(self,features)</span>:</span></span><br><span class="line">        votes = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self._classifiers:</span><br><span class="line">            v = c.classify(features)</span><br><span class="line">            votes.append(v)</span><br><span class="line">        </span><br><span class="line">        choice_votes = votes.count(mode(votes))</span><br><span class="line">        conf = choice_votes / len(votes)</span><br><span class="line">        <span class="keyword">return</span> conf </span><br><span class="line"></span><br><span class="line">documents_f = open(<span class="string">'pickled_algos/documents.pickle'</span>,<span class="string">"rb"</span>)</span><br><span class="line">documents = pickle.load(documents_f)</span><br><span class="line">documents_f.close()</span><br><span class="line"></span><br><span class="line">word_features5k_f = open(<span class="string">'pickled_algos/word_features5k.pickle'</span>,<span class="string">"rb"</span>)</span><br><span class="line">word_features = pickle.load(word_features5k_f)</span><br><span class="line">word_features5k_f.close()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_features</span><span class="params">(document)</span>:</span></span><br><span class="line">    words = nltk.word_tokenize(document)</span><br><span class="line">    features = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> word_features:</span><br><span class="line">        features[w] = (w <span class="keyword">in</span> words)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> features</span><br><span class="line"></span><br><span class="line">open_file = open(<span class="string">"pickled_algos/originalnaivebayes5k.pickle"</span>,<span class="string">"rb"</span>)</span><br><span class="line">classifier = pickle.load(open_file)</span><br><span class="line">open_file.close()</span><br><span class="line"></span><br><span class="line">open_file = open(<span class="string">"pickled_algos/MNB_classifier5k.pickle"</span>,<span class="string">"rb"</span>)</span><br><span class="line">MNB_classifier = pickle.load(open_file)</span><br><span class="line">open_file.close()</span><br><span class="line"></span><br><span class="line">open_file = open(<span class="string">"pickled_algos/BNB_classifier5k.pickle"</span>,<span class="string">"rb"</span>)</span><br><span class="line">BNB_classifier = pickle.load(open_file)</span><br><span class="line">open_file.close()</span><br><span class="line"></span><br><span class="line">open_file = open(<span class="string">"pickled_algos/LogisticRegression_classifier5k.pickle"</span>,<span class="string">"rb"</span>)</span><br><span class="line">LogisticRegression_classifier = pickle.load(open_file)</span><br><span class="line">open_file.close()</span><br><span class="line"></span><br><span class="line">open_file = open(<span class="string">"pickled_algos/LinearSVC_classifier5k.pickle"</span>,<span class="string">"rb"</span>)</span><br><span class="line">LinearSVC_classifier = pickle.load(open_file)</span><br><span class="line">open_file.close()</span><br><span class="line"></span><br><span class="line">open_file = open(<span class="string">"pickled_algos/SGDClassifier_classifier5k.pickle"</span>,<span class="string">"rb"</span>)</span><br><span class="line">SGDClassifier_classifier = pickle.load(open_file)</span><br><span class="line">open_file.close()</span><br><span class="line"></span><br><span class="line">voted_classifier = VoteClassifier(</span><br><span class="line">                                 classifier,</span><br><span class="line">                                 LinearSVC_classifier,</span><br><span class="line">                                 MNB_classifier,</span><br><span class="line">                                 BNB_classifier,</span><br><span class="line">                                 LogisticRegression_classifier)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentiment</span><span class="params">(text)</span>:</span></span><br><span class="line">    feats = find_features(text)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> voted_classifier.classify(feats),voted_classifier.confidence(feats)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save me as sentiment_mod.py</span></span><br></pre></td></tr></table></figure>
<p>下面来使用一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sentiment_mod <span class="keyword">as</span> s</span><br><span class="line"></span><br><span class="line">print(s.sentiment(<span class="string">"This movie was awesome! The acting was great, plot was wonderful, and there were pythons...so yea!"</span>))</span><br><span class="line"></span><br><span class="line">print(s.sentiment(<span class="string">"This movie was utter junk. There were absolutely 0 pythons. I don't see what the point was at all. Horrible movie, 0/10"</span>))</span><br></pre></td></tr></table></figure>
<pre><code>(&apos;pos&apos;, 1.0)
(&apos;neg&apos;, 1.0)
</code></pre><p>好吧，接下来的实践要使用Twitter 创建APP，可能还要使用个人网站，有点麻烦，所以接下来我只是看了看并没有照着实践。<br>总之，在这一系列的跟着敲代码的过程中，自己初步建立起了很浅的自然语言处理的概念~</p>
<h3 id="20-Twitter-Sentiment-Analysis"><a href="#20-Twitter-Sentiment-Analysis" class="headerlink" title="20. Twitter Sentiment Analysis()"></a>20. Twitter Sentiment Analysis()</h3><h3 id="21-Graphing-Live-Twitter-Sentiment"><a href="#21-Graphing-Live-Twitter-Sentiment" class="headerlink" title="21. Graphing Live Twitter Sentiment()"></a>21. Graphing Live Twitter Sentiment()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

        

        
            <div class="full-width auto-padding tags">
                
                    <a href="/tags/Python/"><i class="fas fa-hashtag fa-fw"></i>Python</a>
                
                    <a href="/tags/自然语言处理/"><i class="fas fa-hashtag fa-fw"></i>自然语言处理</a>
                
                    <a href="/tags/NLTK/"><i class="fas fa-hashtag fa-fw"></i>NLTK</a>
                
            </div>
        
    </section>
</article>

        </div>
      
    
      
        <div class='post-wrapper'>
          <article class="post reveal ">
    
<section class='meta'>
  
  <div class="meta" id="header-meta">
    
      <h2 class="title">
          <a href="/2018/03/06/英文表达与写作练习宣告/">
              
                  英文表达与写作练习宣告
              
          </a>
      </h2>
    

    
      <time class="metatag time">
        <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;2018-03-06
      </time>
    

    
      

    

    

    

  </div>
</section>

    <section class="article typo">
        <p><code>汉语版</code>:为了更好的提高自己的英文表达和写作能力，我决定在以后的技术博客中尽可能的使用英文。仅在此声明！</p>
<p><code>我的英文版</code>:In order to improve my English express and writing ablility,I decide that I’ll use English to write my tecnoligy blogs as possible.The statesment is above.</p>
<p><code>有道翻译英语版</code>:In order to improve my English expression and writing ability, I decided to use English as much as possible in future technical blogs.<br>Only in this statement!</p>
<p><code>学习笔记</code>:</p>
<ul>
<li>expression :n,表达</li>
<li>alility:n,能力</li>
<li>decided to do something:决定做某事</li>
<li>as much as possible:尽可能多的</li>
<li>technical:adj,技术的</li>
</ul>

        

        
    </section>
</article>

        </div>
      
    
      
        <div class='post-wrapper'>
          <article class="post reveal ">
    
<section class='meta'>
  
  <div class="meta" id="header-meta">
    
      <h2 class="title">
          <a href="/2018/03/05/常见10种自然语言处理技术（转载）/">
              
                  常见10种自然语言处理技术（转载）
              
          </a>
      </h2>
    

    
      <time class="metatag time">
        <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;2018-03-05
      </time>
    

    
      
    
    <div class='metatag cats'>
        <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;<a class="categories" href="/categories/自然语言处理/">自然语言处理</a>
    </div>


    

    

    

  </div>
</section>

    <section class="article typo">
        <p><a href="https://www.felayman.com/articles/2018/02/28/1519818174444.html" title="点击查看原文" target="_blank" rel="noopener">原文</a></p>
<p><a href="https://www.analyticsvidhya.com/blog/2017/10/essential-nlp-guide-data-scientists-top-10-nlp-tasks/" target="_blank" rel="noopener">该作者也是翻译的外文，英文原文链接</a></p>
<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>自然语言处理（NLP）是一种艺术与科学的结合，旨在从文本数据中提取信息。在它的帮助下，我们从文本中提炼出适用于计算机算法的信息。从自动翻译、文本分类到情绪分析，自然语言处理成为所有数据科学家的必备技能之一。</p>
<p>常见的10个NLP任务如下：</p>
<ol>
<li><code>词干提取</code></li>
<li><code>词形还原</code></li>
<li><code>词向量化</code></li>
<li><code>词性标注</code></li>
<li><code>命名实体消岐</code></li>
<li><code>命名实体识别</code></li>
<li><code>情感分析</code></li>
<li><code>文本语义相似分析</code></li>
<li><code>语种辨识</code></li>
<li><code>文本总结</code></li>
</ol>
<h3 id="以下将详细展开："><a href="#以下将详细展开：" class="headerlink" title="以下将详细展开："></a>以下将详细展开：</h3><h1 id="1-词干提取"><a href="#1-词干提取" class="headerlink" title="1.词干提取"></a>1.词干提取</h1><p>什么是词干提取？词干提取是将词语去除变化或衍生形式，转换为词干或原型形式的过程。词干提取的目标是将相关词语还原为同样的词干，哪怕词干并非词典的词目。例如，英文中:</p>
<ol>
<li>beautiful和beautifully的词干同为beauti</li>
<li>Good,better和best 的词干分别为good,better和best。</li>
</ol>
<p>相关论文：<a href="https://tartarus.org/martin/PorterStemmer/def.txt" target="_blank" rel="noopener">Martin Porter的波特词干算法原文</a></p>
<p>相关算法：<a href="https://bitbucket.org/mchaput/stemming/src/5c242aa592a6d4f0e9a0b2e1afdca4fd757b8e8a/stemming/porter2.py?at=default&amp;fileviewer=file-view-default" target="_blank" rel="noopener">Porter2词干算法的Python实现</a></p>
<p>程序实现：Porter2算法做词干提取的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!pip install stemming</span></span><br><span class="line"><span class="keyword">from</span> stemming.porter2 <span class="keyword">import</span> stem</span><br><span class="line">stem(<span class="string">"casually"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="2-词形还原"><a href="#2-词形还原" class="headerlink" title="2. 词形还原"></a>2. 词形还原</h1><p>什么是词形还原？ 词形还原是将一组词语还原为词源或词典的词目形式的过程。还原过程考虑到了POS问题，即词语在句中的语义，词语对相邻语句的语义等。例如，英语中：</p>
<ol>
<li>beautiful和beautifully被分别还原为beautiful和beautifully。</li>
<li>good, better和best被分别还原为good, good和good</li>
</ol>
<p>相关论文1: <a href="http://www.ijrat.org/downloads/icatest2015/ICATEST-2015127.pdf" target="_blank" rel="noopener">这篇文章详细讨论了词形还原的不同方法。想要了解传统词形还原的工作原理必读。</a></p>
<p>相关论文2: <a href="https://academic.oup.com/dsh/article-abstract/doi/10.1093/llc/fqw034/2669790/Lemmatization-for-variation-rich-languages-using" target="_blank" rel="noopener">这篇论文非常出色，讨论了运用深度学习对变化丰富的语种做词形还原时会遇到的问题。</a></p>
<p>数据集: <a href="https://catalog.ldc.upenn.edu/ldc99t42" target="_blank" rel="noopener">这里是Treebank-3数据集的链接，你可以使用它创建一个自己的词形还原工具。</a></p>
<p>程序实现：下面给出了在spacy上的英语词形还原代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!pip install spacy</span></span><br><span class="line"><span class="comment">#python -m spacy download en</span></span><br><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp=spacy.load(<span class="string">"en"</span>)</span><br><span class="line">doc=<span class="string">"good better best"</span></span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> nlp(doc):</span><br><span class="line">    print(token,token.lemma_)</span><br></pre></td></tr></table></figure>
<h1 id="3-词向量化"><a href="#3-词向量化" class="headerlink" title="3. 词向量化"></a>3. 词向量化</h1><p>什么是词向量化？词向量化是用一组实数构成的向量代表自然语言的叫法。这种技术非常实用，因为电脑无法处理自然语言。词向量化可以捕捉到自然语言和实数间的本质关系。通过词向量化，一个词语或者一段短语可以用一个定维的向量表示，例如向量的长度可以为100。</p>
<p>例如：<code>Man</code>这个词语可以用一个五维向量表示。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E5%B8%B8%E8%A7%8110%E7%A7%8D%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/word-vector.png" alt="Man" title="">
                </div>
                <div class="image-caption">Man</div>
            </figure>
<p>这里的每个数字代表了词语在某个特定方向上的量级。<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E5%B8%B8%E8%A7%8110%E7%A7%8D%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/Word-Vectors.png" alt="word-vectors" title="">
                </div>
                <div class="image-caption">word-vectors</div>
            </figure></p>
<p>相关博文：<a href="https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/" target="_blank" rel="noopener">这篇文章详细解释了词向量化</a></p>
<p>相关论文：<a href="https://www.analyticsvidhya.com/blog/2017/10/essential-nlp-guide-data-scientists-top-10-nlp-tasks/" target="_blank" rel="noopener">这篇论文解释了词向量化的细节。深入理解词向量化必读。</a></p>
<p>相关工具：<a href="https://ronxin.github.io/wevi/" target="_blank" rel="noopener">这是个基于浏览器的词向量可视化工具。</a></p>
<p>预训练词向量：<a href="https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md?spm=a2c4e.11153959.blogcont236723.10.1a815c301CEF2o&amp;file=pretrained-vectors.md" target="_blank" rel="noopener">这里有一份facebook的预训练词向量列表，包含294种语言。</a></p>
<p><a href="https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit" target="_blank" rel="noopener">这里可以下载google news的预训练词向量。</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!pip install gensim</span></span><br><span class="line"><span class="keyword">from</span> gensim.models.keyedvectors <span class="keyword">import</span> KeyedVectors</span><br><span class="line">word_vectors=KeyedVectors.load_word2vec_format(<span class="string">'GoogleNews-vectors-negative300.bin'</span>,binary=<span class="keyword">True</span>)</span><br><span class="line">word_vectors[<span class="string">'human'</span>]</span><br></pre></td></tr></table></figure>
<p>程序实现：这段代码可以用gensim训练你自己的词向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sentence=[[<span class="string">'first'</span>,<span class="string">'sentence'</span>],[<span class="string">'second'</span>,<span class="string">'sentence'</span>]]</span><br><span class="line">model = gensim.models.Word2Vec(sentence, min_count=<span class="number">1</span>,size=<span class="number">300</span>,workers=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<h1 id="4-词性标注"><a href="#4-词性标注" class="headerlink" title="4.词性标注"></a>4.词性标注</h1><p>什么事词性标注？简单来说，词性标注是对句子中的词语标注为名字、动词、形容词、副词等的过程。例如，对句子“Ashok killed the snake with a stick”，词性标注会识别：</p>
<ul>
<li>Ashok 代词</li>
<li>killed 动词</li>
<li>the 限定词</li>
<li>snake 名词</li>
<li>with 连词</li>
<li>a 限定词</li>
<li>stick 名词</li>
<li>. 标点</li>
</ul>
<p>论文1：<a href="https://aclweb.org/anthology/N16-1031.pdf" target="_blank" rel="noopener">choi aptly的这篇《The Last Gist to theState-of-the-Art 》介绍了一种叫动态特征归纳的新方法。这是目前词性标注最先进的方法。</a></p>
<p>论文2：<a href="https://transacl.org/ojs/index.php/tacl/article/viewFile/837/192" target="_blank" rel="noopener">这篇文章介绍了通过隐马尔科夫模型做无监督词性标注学习的方法。</a></p>
<p>程序实现：这段代码可以在spacy上做词性标注</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!pip install spacy</span></span><br><span class="line"><span class="comment">#!python -m spacy download en </span></span><br><span class="line">nlp=spacy.load(<span class="string">'en'</span>)</span><br><span class="line">sentence=<span class="string">"Ashok killed the snake with a stick"</span></span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> nlp(sentence):</span><br><span class="line">   print(token,token.pos_)</span><br></pre></td></tr></table></figure>
<h1 id="5-命名实体消歧"><a href="#5-命名实体消歧" class="headerlink" title="5. 命名实体消歧"></a>5. 命名实体消歧</h1><p>什么是命名实体消岐？命名实体消岐是对句子中的提到的实体识别的过程。例如，对句子“Apple earned a revenue of 200 Billion USD in 2016”，命名实体消岐会推断出句子中的Apple是苹果公司而不是指一种水果。一般来说，命名实体要求有一个实体知识库，能够将句子中提到的实体和知识库联系起来。</p>
<p>论文1：<a href="https://arxiv.org/pdf/1504.07678.pdf" target="_blank" rel="noopener">Huang的这篇论文运用了基于深度神经网络和知识库的深层语义关联模型，在命名实体消岐上达到了领先水平。</a></p>
<p>论文2：<a href="https://arxiv.org/pdf/1704.04920.pdf" target="_blank" rel="noopener">Ganea and Hofmann的这篇文章运用了局部神经关注模型和词向量化，没有人为设置特征。</a></p>
<h1 id="6-命名实体识别"><a href="#6-命名实体识别" class="headerlink" title="6. 命名实体识别"></a>6. 命名实体识别</h1><p>体识别是识别一个句子中有特定意义的实体并将其区分为人名，机构名，日期，地名，时间等类别的任务。例如，一个NER会将一个这样的句子：</p>
<blockquote>
<p>“Ram of Apple Inc. travelled to Sydney on 5th October 2017”</p>
</blockquote>
<p>返回如下的结果：</p>
<blockquote>
<p>Ram<br>of<br>Apple ORG<br>Inc. ORG<br>travelled<br>to<br>Sydney GPE<br>on<br>5th DATE<br>October DATE<br>2017 DATE</p>
</blockquote>
<p>这里，ORG代表机构组织名，GPE代表地名。</p>
<p>然而，当NER被用在不同于该NER被训练的数据领域时，即使是最先进的NER也往往表现不佳。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E5%B8%B8%E8%A7%8110%E7%A7%8D%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/ner.png" alt="ner" title="">
                </div>
                <div class="image-caption">ner</div>
            </figure>
<p>论文：<a href="https://arxiv.org/pdf/1603.01360.pdf" target="_blank" rel="noopener">这篇优秀的论文使用双向LSTM（长短期记忆网络）神经网络结合监督学习和非监督学习方法，在4种语言领域实现了命名实体识别的最新成果。</a></p>
<p>程序实现：以下使用spacy执行命名实体识别。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp=spacy.load(<span class="string">'en'</span>)sentence=<span class="string">"Ram of Apple Inc. travelled to Sydney on 5th October 2017"</span></span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> nlp(sentence):</span><br><span class="line">   print(token, token.ent_type_)</span><br></pre></td></tr></table></figure>
<h1 id="7-情感分析"><a href="#7-情感分析" class="headerlink" title="7. 情感分析"></a>7. 情感分析</h1><p>什么是情感分析？情感分析是一种广泛的主观分析，它使用自然语言处理技术来识别客户评论的语义情感，语句表达的情绪正负面以及通过语音分析或书面文字判断其表达的情感等等。例如：</p>
<p>“我不喜欢巧克力冰淇淋”—是对该冰淇淋的负面评价。</p>
<p>“我并不讨厌巧克力冰激凌”—可以被认为是一种中性的评价。</p>
<p>从使用LSTMs和Word嵌入来计算一个句子中的正负词数开始，有很多方法都可以用来进行情感分析。</p>
<p>博文1：<a href="https://www.analyticsvidhya.com/blog/2016/02/step-step-guide-building-sentiment-analysis-model-graphlab/" target="_blank" rel="noopener">本文重点对电影推文进行情感分析。</a></p>
<p>博文2：<a href="https://www.analyticsvidhya.com/blog/2017/01/sentiment-analysis-of-twitter-posts-on-chennai-floods-using-python/" target="_blank" rel="noopener">本文重点对印度金奈洪水期间的推文进行情感分析。</a></p>
<p>论文1：<a href="https://arxiv.org/pdf/1305.6143.pdf" target="_blank" rel="noopener">本文采用朴素贝叶斯的监督学习方法对IMDB评论进行分类。</a></p>
<p>论文2：<a href="http://www.cs.cmu.edu/~yohanj/research/papers/WSDM11.pdf" target="_blank" rel="noopener">本文利用LDA的无监督学习方法来识别用户生成评论的观点和情感。本文在解决注释评论短缺的问题上表现突出。</a></p>
<p>资料库：<a href="https://github.com/xiamx/awesome-sentiment-analysis" target="_blank" rel="noopener">这是一个很好的包含相关研究论文和各种语言情感分析程序实现的资料库。</a></p>
<p>数据集1<a href="http://www.cs.jhu.edu/~mdredze/datasets/sentiment/" target="_blank" rel="noopener">：多域情感数据集版本2.0</a></p>
<p>数据集2：<a href="http://www.sananalytics.com/lab/twitter-sentiment/" target="_blank" rel="noopener">Twitter情感分析数据集</a></p>
<p>竞赛：<a href="https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews" target="_blank" rel="noopener">一个非常好的比赛，你可以检查你的模型在烂番茄电影评论的情感分析任务中的表现。</a></p>
<h1 id="8-语义文本相似度"><a href="#8-语义文本相似度" class="headerlink" title="8. 语义文本相似度"></a>8. 语义文本相似度</h1><p>什么是语义文本相似度分析？语义文本相似度分析是对两段文本的意义和本质之间的相似度进行分析的过程。注意，相似性与相关性是不同的。</p>
<p>例如：</p>
<blockquote>
<p>汽车和公共汽车是相似的，但是汽车和燃料是相关的。</p>
</blockquote>
<p>论文1：<a href="https://pdfs.semanticscholar.org/5b5c/a878c534aee3882a038ef9e82f46e102131b.pdf" target="_blank" rel="noopener">本文详细介绍了文本相似度测量的不同方法。是一篇可以一站式了解目前所有方法的必读文章。</a></p>
<p>论文2：<a href="http://casa.disi.unitn.it/~moschitt/since2013/2015_SIGIR_Severyn_LearningRankShort.pdf" target="_blank" rel="noopener">本文介绍了用CNN神经网络去比对两个短文本。</a></p>
<p>论文3：<a href="https://nlp.stanford.edu/pubs/tai-socher-manning-acl2015.pdf" target="_blank" rel="noopener">本文利用Tree-LSTMs方法得到了文本的语义相关和语义分类的最新成果。</a></p>
<h1 id="9-语言识别"><a href="#9-语言识别" class="headerlink" title="9. 语言识别"></a>9. 语言识别</h1><p>什么是语言识别？语言识别指的是将不同语言的文本区分出来。其利用语言的统计和语法属性来执行此任务。语言识别也可以被认为是文本分类的特殊情况。</p>
<p>博文：<a href="https://fasttext.cc/blog/2017/10/02/blog-post.html" target="_blank" rel="noopener">在这篇由fastText撰写的博文中介绍了一种新的工具，其可以在1MB的内存使用情况下识别170种语言。</a></p>
<p>论文1：<a href="http://www.ep.liu.se/ecp/131/021/ecp17131021.pdf" target="_blank" rel="noopener">本文讨论了285种语言的7种语言识别方法。</a></p>
<p>论文2：<a href="https://repositorio.uam.es/bitstream/handle/10486/666848/automatic_lopez-moreno_ICASSP_2014_ps.pdf?sequence=1" target="_blank" rel="noopener">本文描述了如何使用深度神经网络来实现自动语言识别的最新成果。</a></p>
<h1 id="10-文本摘要"><a href="#10-文本摘要" class="headerlink" title="10. 文本摘要"></a>10. 文本摘要</h1><p>什么是文本摘要？文本摘要是通过识别文本的重点并使用这些要点创建摘要来缩短文本的过程。文本摘要的目的是在不改变文本含义的前提下最大限度地缩短文本。</p>
<p>论文1：<a href="https://arxiv.org/pdf/1509.00685.pdf" target="_blank" rel="noopener">本文描述了基于神经注意模型的抽象语句梗概方法。</a></p>
<p>论文2：<a href="https://arxiv.org/pdf/1602.06023.pdf" target="_blank" rel="noopener">本文描述了使用序列到序列的RNN在文本摘要中达到的最新结果。</a></p>
<p>资料库：<a href="https://github.com/tensorflow/models/tree/master/research/textsum" target="_blank" rel="noopener">Google Brain团队的这个资料库拥有使用为文本摘要定制的序列到序列模型的代码。该模型在Gigaword数据集上进行训练。</a></p>
<p>应用程序：<a href="https://www.reddit.com/r/autotldr/comments/31b9fm/faq_autotldr_bot/" target="_blank" rel="noopener">Reddit的autotldr机器人使用文本摘要来梗概从文章到帖子的各种评论。这个功能在Reddit用户中非常有名。</a></p>
<p>程序实现：以下是如何用gensim包快速实现文本摘要。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fromgensim.summarization <span class="keyword">import</span> summarize</span><br><span class="line">sentence=<span class="string">"Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document. Technologies that can make a coherent summary take into account variables such as length, writing style and syntax.Automatic data summarization is part of machine learning and data mining. The main idea of summarization is to find a subset of data which contains the information of the entire set. Such techniques are widely used in industry today. Search engines are an example; others include summarization of documents, image collections and videos. Document summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images. For surveillance videos, one might want to extract the important events from the uneventful context.There are two general approaches to automatic summarization: extraction and abstraction. Extractive methods work by selecting a subset of existing words, phrases, or sentences in the original text to form the summary. In contrast, abstractive methods build an internal semantic representation and then use natural language generation techniques to create a summary that is closer to what a human might express. Such a summary might include verbal innovations. Research to date has focused primarily on extractive methods, which are appropriate for image collection summarization and video summarization."</span></span><br><span class="line">summarize(sentence)</span><br></pre></td></tr></table></figure>
<h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>以上所有是最流行的NLP任务以及相关的博客、研究论文、资料库、应用等资源。</p>
<p>祝你学习愉快！</p>

        

        
            <div class="full-width auto-padding tags">
                
                    <a href="/tags/自然语言处理/"><i class="fas fa-hashtag fa-fw"></i>自然语言处理</a>
                
            </div>
        
    </section>
</article>

        </div>
      
    
      
        <div class='post-wrapper'>
          <article class="post reveal ">
    
<section class='meta'>
  
  <div class="meta" id="header-meta">
    
      <h2 class="title">
          <a href="/2018/03/05/朕的感情史-编程语言篇！/">
              
                  朕的感情史-编程语言篇！
              
          </a>
      </h2>
    

    
      <time class="metatag time">
        <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;2018-03-05
      </time>
    

    
      

    

    

    

  </div>
</section>

    <section class="article typo">
        <p>对于每一个有理想有追求的程序猿而言，他们可以没有对象，但是不能没有自己的喜欢的语言。</p>
<p>古言道：兄弟诚可贵，老婆价更高。若为编程故（指死亡之die~），躲也躲不掉。</p>
<p>好吧，接下来我要正式介绍一下朕的后宫！</p>
<p><code>第一任</code>：<code>C++</code></p>
<p>大一学习编程语言最开始上手的就是C++，不过学了半天也没学出个所以然来，经常挣扎于混杂的概念之中，却又缺少电脑无法有效开展实战编程。后来随着考试结束，我和她的感情也就慢慢的越来越淡了。</p>
<p>好吧，不过呢，作为系统编程和游戏开发的无可替代的语言，她的高性能与开发效率综合而言目前怕是所有所有的都比不上。</p>
<p>大部分企业面试笔试好像都会问到C++，感觉不会点C++真的不配说自己是程序员，但是我觉得人生苦短，何必找死呢。感觉C++是我等屁民不可轻易染指的高冷女神。</p>
<p><code>第二任</code>：<code>C</code></p>
<p>为了更好的学习C++，曾经又跑去学了C，因为我觉得她是C++的姐姐吧。不过还是由于驱动力不足之类的原因吧，最终也没能学出个卵子，不过也在某种程度上理解了C++相对于C而言做的改进，例如多态、名称空间、类等对于结构化的编程还是挺有用的吧。</p>
<p>C语言也可以做的很吊，但是由于语言的设计里本身并没有许多高级概念，所以用起来不是很直接方便，搞系统编程或者其他对效率要求极高的才会用吧。看上去没有C++的高冷，但是也不好追，并且语言特性相对低级，自己本身不太喜欢。</p>
<p><code>第三任</code>：<code>Java</code></p>
<p>Java这门语言其实真的是相当不错的。如所有的类都有一个共同的基类，只能继承自一个父类，其他的通过接口来实现，相对于C++的名称空间来说要好不少。</p>
<p>Java的语言世界里，程序总是在一个个实例化的类或类本身中的属性和方法中穿梭，某种程度上来说其实挺好的。相比C++而言，普通的人很容易上手并能培养起初步良好的编程习惯。</p>
<p>我在Java实验课程中手撸一个什么系统，在此过程中，初步培养起了软件编程的极初始的经验体会。后来学习Android过程中，由于也要用到Java，所以功底还算可以。</p>
<p>但是在定义和使用的过程中，还是会感觉到比较冗杂，当然规矩多了某种程度上也算好事。那些之后在JVM之上出现的其他语言，也是同样在JVM上运行程序，但是相对而言可能更简洁、更少束缚、更强表现力，如Scala、Kotlin等等。</p>
<p>曾经问我家邻居学软件怎么入手，他说你就学Java吧。Java语言在企业级应用系统开发中的主导地位怕是很难被动摇的。</p>
<p>无论什么时候，Java都是一个值得选择拥抱的小姐姐。</p>
<p><code>第四任</code>：<code>C#</code></p>
<p>C#开发最初的目的可能是微软用于应对Java吧。</p>
<p>C#这门语言在面向对象的语言家族中还是很不错的，某些设计理念比Java还要先进。然而正如以前的VBScript等更多的是被捆绑在Windows操作系统中，不开源，在某种程度上也算束缚了它的发展进步。虽说现在开源了，但是由于Java已经占领了大部分市场，C#的份额还是挺小的了。</p>
<p>因课结缘，课完缘尽。<br>定位和Java类似，但是对Java更有好感。</p>
<p><code>第五任</code>：<code>Lua</code></p>
<p>不得不说，Lua真的是个好语言，只是之前没怎么好好学，并且它上手极为简单容易。现在的话，很少接触，因为基本上用不到。对于它的C源码还是有必要看一下的。感觉很有好感的小妹妹。</p>
<p><code>第六任</code>：<code>Python</code></p>
<p>Python的设计哲学现在看来真的是极好，这些年的发展壮大足以说明一切，在大部分编程应用领域里几乎都有了它的身影。极强的代码阅读性，上手很容易。于我而言，她现在是一个贤妻良母型的。</p>
<p><code>第七任</code>：<code>Ruby</code></p>
<p>Python和Ruby各领风骚，许多爱好者各爱各的好。Ruby我以前也学过一下下，Ruby好像是基于对象的，里面啥都是对象。相对而言，用法超级灵活，而且比较简洁炫酷，但是可能因为用的少，我看着Ruby代码好像阅读起来不是很爽，比Python而言差远了。开发效率极高，Ruby on Rails嘛，但是好像项目做大之后就会受限于它的运行效率。现在也早就分了。感觉Ruby和我三观不符，私人感觉Ruby是一个比较追求时尚新颖的女生，比较开放外向。</p>
<p><code>第八任</code>：<code>Scala</code></p>
<p>我曾经学习过很短时间的Scala，网上的说法是学习起来很复杂，我当时感觉还不错，后来因为用不到也没在学了，可能还是不太感兴趣吧。也是一个不错的小姐姐，但是如果太专情于此，怕是不好吃饭。。。</p>
<p><code>第九任</code>：<code>aardio</code></p>
<p>最爱，没有之一。虽然它生于Windows，长于Windows，最终也将死于Windows，但是这还是无法阻挠我对它的喜爱，况且正是由于仅限于Windows平台，她的美才更加表现出来。她的不开源我也理解，是我我也不开源，正是一鹤校长非常爱她，才不允许其他误解开源精神的染指搞事情。</p>
<p>动态语言，快速开发，名称空间、类，句法灵活，调用简单，几行代码就可以实现复杂的功能，并且很方便的就可以开发出控制台、桌面、网络、后台程序，可以方便与其他语言实现互相调用。</p>
<p>自从无意间了解到这门语言之后，感觉一下子就被吸引到了，因为她当时完全符合我对编程语言的所有需求，他妈的当时把老纸激动坏了，差点一宿没睡着。当时学了编程两年多，都写不出个什么桌面程序来，用Java写的太丑，用C#开发的还得运行在.Net框架上。一点成就感都没有，我对可视化的界面还是很执着的。</p>
<p>后来花钱报了班，看视频学习，有时会在群里探讨问题，有时会直接向校长询问，感觉真的很值。后来我数据库实验、编译原理实验、操作系统实验等等全都是用的aardio语言，因为用起来实在是太爽了。</p>
<p>于我而言，aardio是我的初恋，是我第一门喜欢上的语言，虽然现在由于没有需求已经暂停和她失去了联系，但是我会永远喜欢她！</p>
<p><code>第十任</code>：<code>Processing</code></p>
<p>Processing这门语言用来做艺术设计以及自然模拟都是很不错的，并且跨平台，可以生成可执行程序，本身使用Java语言写的，同时也有JavaScript版和Python版，也是用不到所以没在用了。在我看来，像是一个很可爱的萝莉。</p>
<p><code>第十一任</code>：<code>JavaScript</code></p>
<p>个人感觉，JavaScript最屌了。它的语言哲学相对来说和我的三观最为符合，原型继承，闭包等等概念都很不错。随着es6的出现，它的语法规范感觉十分高级，个人十分喜欢，在某种程度上，部分设计已经超越了aardio（感觉aardio是集许多好的语言的特性于一身）。事件驱动、非阻塞I/O、回调的NodeJs感觉也很棒。是一个我非常想深入学习的语言，对我来说是一个极具诱惑力的女神。</p>
<p><code>第十二任</code>：<code>Racket</code></p>
<p>Racket是Scheme的一种方言，而Scheme则是Lisp的一种方言，语言中处处都是函数式编程，感觉非常新颖且高大上，但是程序复杂起来了之后阅读体验极差，远远比不上Python。接下来打算有时间接触一下下，多吸取里面的先进思想。</p>
<p><code>第十三任</code>：<code>Julia</code></p>
<p>2018/3/5刚接触Julia语言，感觉真的挺厉害的，元编程，并行计算，超高性能，语法像Python、用法像Lisp、速度像C，渍渍，真是厉害了~</p>
<p><code>第十四任</code>：<code>？</code></p>
<p><code>第十五任</code>：<code>？</code></p>
<p><code>第十六任</code>：<code>？</code></p>
<p><code>第十七任</code>：<code>？</code></p>
<p>……</p>
<p>接下来的语言还没出现或者还没接触到，可能今后才会冒出来，或者是我自己设计定义实现的吧……</p>

        

        
    </section>
</article>

        </div>
      
    
      
        <div class='post-wrapper'>
          <article class="post reveal ">
    
<section class='meta'>
  
  <div class="meta" id="header-meta">
    
      <h2 class="title">
          <a href="/2018/03/04/Python学习笔记（1）骚操作之Unicode编码/">
              
                  Python学习笔记（1）骚操作之Unicode编码
              
          </a>
      </h2>
    

    
      <time class="metatag time">
        <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;2018-03-04
      </time>
    

    
      
    
    <div class='metatag cats'>
        <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;<a class="categories" href="/categories/Python/">Python</a>
    </div>


    

    

    

  </div>
</section>

    <section class="article typo">
        <p>Python3内部使用的是Unicode编码，所以在变量定义的时候或许可以搞点事情。<br>例如创建一个文件,名为：<code>人.py</code>，里面的代码是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> 人<span class="params">(object)</span>:</span></span><br><span class="line">    性别 = <span class="string">"男"</span></span><br></pre></td></tr></table></figure></p>
<p>然后同目录下创建一个<code>test.py</code>文件，里面内容为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> 人 <span class="keyword">import</span> 人</span><br><span class="line">李明 = 人()</span><br><span class="line">print(李明.性别)</span><br></pre></td></tr></table></figure></p>
<p>结果输出：<code>男</code>，是不是有点骚~</p>

        

        
            <div class="full-width auto-padding tags">
                
                    <a href="/tags/Python/"><i class="fas fa-hashtag fa-fw"></i>Python</a>
                
            </div>
        
    </section>
</article>

        </div>
      
    
      
        <div class='post-wrapper'>
          <article class="post reveal ">
    
<section class='meta'>
  
  <div class="meta" id="header-meta">
    
      <h2 class="title">
          <a href="/2018/03/04/《和谐辩证法》笔记与心得（3）吾之平衡辩证法/">
              
                  《和谐辩证法》笔记与心得（3）吾之平衡辩证法
              
          </a>
      </h2>
    

    
      <time class="metatag time">
        <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;2018-03-04
      </time>
    

    
      
    
    <div class='metatag cats'>
        <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;<a class="categories" href="/categories/哲学/">哲学</a>
    </div>


    

    

    

  </div>
</section>

    <section class="article typo">
        <ol>
<li>吾之所见为，宇宙的发展其实就是<strong>能量间从不平衡状态到平衡状态的迁移</strong>罢了。</li>
<li>事物的稳定与不稳定两种状态可理解为运动之趋势变化抑或不变耳。</li>
<li>事物总是从不平衡的状态朝向平衡的状态运动和发展的，而之所以运动不止，发展不断，则是由于外界的作用又使得事物可能从平衡又趋于不平衡。</li>
<li>事物内部或事物之间的平衡或不平衡的状态实际上就是指在没有外物的作用下，事物之间或事物内部各要素之间能否保持稳定而不变化的状态，对应的是时刻，状态或趋势。而运动或静止对应的是时间，过程或阶段。平衡或不平衡是决定事物或事物之间运动以相互作用的决定因素，而运动与静止则是从不平衡态向平衡态迁移或平衡态迁移到不平衡态的实现过程。</li>
<li>然而吾仍不解的是宇宙之始态为何，宇宙之终态又为何，同时为什么能量非要从不平衡态迁移到平衡态。</li>
<li>举例如：生产关系之调整是生产关系与生产力从不平衡到平衡的过程；生产力之进步是生产力与人类生存发展不平衡到平衡的过程；人类之生存发展是理想与现实之不平衡到平衡的过程；但理想之追求非平衡，而是贪念和占有，故此之平衡终为不可持续之平衡，故马克思理想之共产主义社会终究不会实现与持久，缘何？人类与大自然和环境之极大不平衡也。<br>当然，最好的结果自然是人类延续，欲望无休止，继续开采资源直至到其他星球为止。最坏的结果当为人类自掘坟墓、自取灭亡。</li>
</ol>

        

        
            <div class="full-width auto-padding tags">
                
                    <a href="/tags/哲学/"><i class="fas fa-hashtag fa-fw"></i>哲学</a>
                
            </div>
        
    </section>
</article>

        </div>
      
    
      
        <div class='post-wrapper'>
          <article class="post reveal ">
    
<section class='meta'>
  
  <div class="meta" id="header-meta">
    
      <h2 class="title">
          <a href="/2018/03/04/《和谐辩证法》笔记与心得（2）能量供求之己见/">
              
                  《和谐辩证法》笔记与心得（2）能量供求之己见
              
          </a>
      </h2>
    

    
      <time class="metatag time">
        <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;2018-03-04
      </time>
    

    
      
    
    <div class='metatag cats'>
        <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;<a class="categories" href="/categories/哲学/">哲学</a>
    </div>


    

    

    

  </div>
</section>

    <section class="article typo">
        <ol>
<li>本书作者以为存在两种性质不同的能量作用方式，即：1.单向能量供求关系2.双向能量供求关系。<br>同时存在三种不同的能量供求结果，即：1.能量相容2.能量冲突3.能量中立。</li>
<li>单向能量供求关系可形成能量链，链条上的每一节都存在能量的转换与运动形式的转换。</li>
<li>而双向能量供求关系则表现为单两者之间的相互吸引或者相互对抗、相互满足或者相互伤害。</li>
</ol>
<p>然吾不以为然，因为事物之间的彼此联系实际上就是说存在着相互作用的关系，彼此可以影响对方的运动和发展。</p>
<p>所以可以说<strong>“凡事皆为众因之果，万物齐作众果之因”</strong>。</p>
<p>吾以为凡世间种种因缘之变化，皆能量相互作用之结果。能量自然成链，无限接力也。然天下间万事万物皆作能量之一小环，有供有求，无时无刻不相互作用耳。作者之见，实为取何其浩大之细微，沧海之一粟，往来之一瞬。然后取关联以相接，得知为链，然作者岂不明乎：双向能量供求关系岂非特殊两者之链而成环哉！</p>
<p>如下图：<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E8%83%BD%E9%87%8F%E4%BE%9B%E6%B1%821.png" alt="能量供求1" title="">
                </div>
                <div class="image-caption">能量供求1</div>
            </figure>,此即细微也。圆圈指能量体或物质外显或抽象之概念，而这指向圆环的箭头其实也是外界相加于圆圈之能量，而自圆环外指的箭头当为圆环向外界其他能量体施加之能量。</p>
<p>本书作者之单向能量链为：<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E8%83%BD%E9%87%8F%E4%BE%9B%E6%B1%822.png" alt="能量供求2" title="">
                </div>
                <div class="image-caption">能量供求2</div>
            </figure>。</p>
<p>而双向能量供求关系为：<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E8%83%BD%E9%87%8F%E4%BE%9B%E6%B1%823.png" alt="能量供求3" title="">
                </div>
                <div class="image-caption">能量供求3</div>
            </figure>。</p>
<p>岂不过度抽象与特殊化乎。所谓单向或双向在我看来无非作用程度不同罢了。</p>
<p>所谓“大道至简”，因而绝非有两种存在。</p>
<p>同时参考吾之运动与静止理解，可得，万事万物，都会直接或者间接地影响和改变某一事物内在的结构和内容或其作为要素与整体及整体的其他要素之关系，从而推动事物的运动和发展。</p>
<p>若拿函数方程来粗浅理解，如三个变量X，Y，Z，有函数方程组：<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E8%83%BD%E9%87%8F%E4%BE%9B%E6%B1%824.png" alt="能量供求4" title="">
                </div>
                <div class="image-caption">能量供求4</div>
            </figure>。</p>
<p>三个方程三个未知量，若是再知道初态X0 、Y0、Z0，那么从逻辑上或许总是可以得到依次的相互对应的X，Y，Z的值的。</p>
<p>然而现实是现实中的未知量实在是太多了，同时函数关系式也太复杂了，所以理论来说实际上是不可能得到准确的解的。然而我们通过观察现实中某些量或许是线性的，也就是说两者之间是线性联系或者呈现出其他的联系函数，正是在这个基础上，我们的认识才更加深化和进步。</p>
<p>故而可理解为世间或宇宙或许为能量之一个奇大无比之网，而我们万物无非其中一个小小结罢了。</p>
<p>同时关于三种能量供求结果，我的想法是可以从物理学上机械能做功的角度。</p>
<p>（机械宏观运动中）物体运动有其方向，即速度是一个矢量，而外力平行于该方向上的分力，若方向一致则做正功，推动事物原有方向上的发展。若相反，则做负功。阻碍事物原有方向的发展，甚至使方向发生180度变化。而垂直于运动方向上的力不做功，但仍有改变方向之效用，因而能量相容即外界之能量作用于事物产生的运动状态与物质本身、当前运动状态相一致则为相容。相反则为冲突。垂直则为中立，并非无用，可起到改变方向之作用，但中立应该是特殊状态，且仅一瞬的状态，因为运动方向一旦改变而作用方向不变，即产生非中立关系，因而是不可持续的，若是站在物理力学之坐公交度，则不存在此状态。</p>

        

        
            <div class="full-width auto-padding tags">
                
                    <a href="/tags/哲学/"><i class="fas fa-hashtag fa-fw"></i>哲学</a>
                
            </div>
        
    </section>
</article>

        </div>
      
    
      
        <div class='post-wrapper'>
          <article class="post reveal ">
    
<section class='meta'>
  
  <div class="meta" id="header-meta">
    
      <h2 class="title">
          <a href="/2018/03/04/《和谐辩证法》笔记与心得（1）物质运动与静止之己见/">
              
                  《和谐辩证法》笔记与心得（1）物质运动与静止之己见
              
          </a>
      </h2>
    

    
      <time class="metatag time">
        <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;2018-03-04
      </time>
    

    
      
    
    <div class='metatag cats'>
        <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;<a class="categories" href="/categories/哲学/">哲学</a>
    </div>


    

    

    

  </div>
</section>

    <section class="article typo">
        <p>对应p35<br>吾以为马克思之运动与静止之观点与本书作者之运动与静止之观点均有偏颇之处，或者各有所见。然吾之角度或许不同于二者乎。</p>
<p>马克思云运动之绝对而静止之相对，而本书作者云运动与静止均绝对。<br>恩格斯之运动绝对体现在：1.任何事物都是运动的2.任何事物在任何时候都是运动的。</p>
<p>而本书作者之运动与静止之界限取决于事物是否在特定能量下作为一个整体的运动变化，同时还伴随着其特定能量的释放。</p>
<p>而吾之运动静止观在于两方面：1.事物内部各要素之间联系是否发生改变，事物的结构与内容是否发生变化2.事物作为一个整体的要素是否与其他要素之间的联系是否发生改变，以及因此导致的整体的结构及内容的变化。</p>
<p>然而事物作为一个整体而言，其要素的划分方式并非绝对的，而是相对的，同时该事物作为一个要素而言，可以和别的事物组成一整体，而这种组合也是多变的，多样的。具体含义为：一个事物根据不同的角度可以被划分为多种不同的要素的有机组合，如abcd可以分为a、b、c、d或者ab、cd或者abc、d等等，同时这一事物可以和其他事物组成不同的多样的整体，如a和b可以组合成ab而a和c可以组合成ac，此外同为ab与ba尽管内容相同，但内部要素之间结构不同，因而算是不同事物。</p>
<p>故吾看来，事物之运动或静止取决于以上两方面，同时他们的根本属性并非绝对性而在于其相对性，运动是相对的，静止也是相对的。这里的相对并非事物与事物之间的相对，而是事物与角度之间的相对。</p>

        

        
            <div class="full-width auto-padding tags">
                
                    <a href="/tags/哲学/"><i class="fas fa-hashtag fa-fw"></i>哲学</a>
                
            </div>
        
    </section>
</article>

        </div>
      
    
      
        <div class='post-wrapper'>
          <article class="post reveal ">
    
<section class='meta'>
  
  <div class="meta" id="header-meta">
    
      <h2 class="title">
          <a href="/2018/03/04/《智慧之根》笔记与心得（2）事物之结构浅解/">
              
                  《智慧之根》笔记与心得（2）事物之结构浅解
              
          </a>
      </h2>
    

    
      <time class="metatag time">
        <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;2018-03-04
      </time>
    

    
      
    
    <div class='metatag cats'>
        <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;<a class="categories" href="/categories/哲学/">哲学</a>
    </div>


    

    

    

  </div>
</section>

    <section class="article typo">
        <p>&emsp;&emsp;吾以为，事物之结构该当如下：（注意：这里的事物应当是能量的物质外显，抑或人们的抽象之概念，然吾之推测当人们所不明之结构也当如此）</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E7%BB%93%E6%9E%841.png" alt="结构1" title="">
                </div>
                <div class="image-caption">结构1</div>
            </figure>
<p>&emsp;&emsp;联系需要联系者，因为联系是联系者之间的联系。联系者具体地说就是具体事物，抽象地说就是联系环节，因而联系环节就是指抽象的联系者。<br>联系的基本环节包括：系统和要素、结构和功能、形势和内容、本质和现象、原因和结果、内因和外因、质与量、肯定与否定。</p>
<h1 id="一-系统和要素"><a href="#一-系统和要素" class="headerlink" title="一 系统和要素"></a>一 <code>系统</code>和<code>要素</code></h1><ol>
<li>任何系统本身既是个系统，又处于更大的系统之中。系统是由要素构成的，因而相对于更大系统而言的某一具体事物又成为构成更大系统的要素。</li>
<li>系统是由一定数量相互联系的要素资格，有特定结构、性质和功能的有机整体。</li>
</ol>
<p>如上图中，可将这个大的系统结构的某个要素视为四个该要素之要素组成之系统（整体）：<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E7%BB%93%E6%9E%842.png" alt="系统" title="">
                </div>
                <div class="image-caption">系统</div>
            </figure>，<br>四个要素之要素可视为相对这个要素（系统）之要素（部分）：<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E7%BB%93%E6%9E%843.png" alt="要素" title="">
                </div>
                <div class="image-caption">要素</div>
            </figure>，应当注意系统与要素之间的相对性。无论系统还是要素都是相对的。</p>
<h1 id="二-结构和功能"><a href="#二-结构和功能" class="headerlink" title="二 结构和功能"></a>二 <code>结构</code>和<code>功能</code></h1><ol>
<li>宇宙万物不仅作为系统由一定要素所构成，而且构成一事物的要素因其相互联系而构成特定的结构，从而具有特定的功能。</li>
<li>结构是事物内在要素的联结方式。结构不仅具有整体性，也具有相对稳定性（根据皮亚杰的观点，结构的各要素互相制约、互为条件且不受外界因素的影响），因而具有转换型（结构的各要素可按一定规则互相替换而不改变结构本身）。注：关于相对稳定性，吾不以为然，吾以为结构之间的要素的关联是要受到外界的干预影响的。</li>
<li>功能是事物由其结构而产生的对外部对象或环境的作用能力，或者说，是事物通过对外部对象或环境的作用而表现出来的性能。</li>
<li>结构与功能之区别：结构属于事物内部的内部联系，而功能则是一事物通过与另一事物发生外部联系而产生或体现出来。</li>
</ol>
<p>如最上图，这个大的系统的最上面的那个要素的结构<br>是蓝色部分，： <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E7%BB%93%E6%9E%844.png" alt="结构" title="">
                </div>
                <div class="image-caption">结构</div>
            </figure>，而这个要素的功能<br>是绿色部分： <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E7%BB%93%E6%9E%845.png" alt="功能" title="">
                </div>
                <div class="image-caption">功能</div>
            </figure>。</p>
<h1 id="三-形式与内容"><a href="#三-形式与内容" class="headerlink" title="三 形式与内容"></a>三 <code>形式</code>与<code>内容</code></h1><ol>
<li>结构作为事物内在要素的联结方式也就是事物的形式，要素就是事物的形式所依存的内容。</li>
<li>所谓内容就是构成事物的一切内在要素的总和。内容有两大类：一是实体方面的（部分、成分），一是属性方面的（内在矛盾、发展趋势）。</li>
<li>所谓形式就是把食物的内在要素组合起来的结构。</li>
<li>形式和内容是有区别的，内容是事物存在的基础，相对于形式来说，它是“实”，是形式这张网上的“结”；形式则是事物存在的结构，相对于内容来说，它是“虚”，是编织内容的“网”。因此，内容和形式的关系可以说是实（结）与虚（网）的关系。</li>
</ol>
<p>如最上图，这个大的系统的最上面的那个要素的内容<br>即粉红色部分：<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E7%BB%93%E6%9E%846.png" alt="内容" title="">
                </div>
                <div class="image-caption">内容</div>
            </figure>，而形式实则为对应功能之结构，只不过形式对应的是内容，其实（形式与结构）实质一样，但对应之物不同，故侧重角度略有不同：<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E7%BB%93%E6%9E%847.png" alt="形式" title="">
                </div>
                <div class="image-caption">形式</div>
            </figure>。</p>
<h1 id="四-本质和现象"><a href="#四-本质和现象" class="headerlink" title="四 本质和现象"></a>四 <code>本质</code>和<code>现象</code></h1><ol>
<li>现象是事物显现于外的形象或面貌。它是事物本质的诸方面表现，其实质是外部联系，就是说，一事物如果不与一定量的其他事物发生联系或相互作用，就没有现象可言。</li>
<li>本质是事物深藏于内的根本性质，其实质是事物内在的根本要素之必然联系，它是由事物的根本矛盾或特殊矛盾决定的。<br>3.就本质与性质的关系来说，本质通常是就个体事物之为其自身而言的，性质是就个体的类属而言的。虽然本质与性质都很抽象，但性质比本质更抽象。</li>
<li>就本质与结构（形式）的关系来说，结构（形式）相对于功能也相对于要素（内容）而言，但本质仅相对于现象而言。现象不等于功能和要素，所以本质也不同于结构（形式）。本质和结构都很抽象，但相比而言，本质比结构更抽象（结构较本质更具体）。</li>
<li>从根本上说，本质与结构（形式）是一致的。</li>
<li>本质与结构（形式）的一致，在于他们都不能脱离要素（内容）而独立存在。</li>
<li>就本质与规律、趋势（必然性）的关系来说：三者虽然都是抽象的，但本质是从相对静态的角度来深刻认识事物的，他所要揭示的是事物之为事物的当前规定性；而规律和趋势（必然性）则是从相对动态的角度来深刻把握事物的，他所要解释的是事物未来的进程和归宿。不过，本质与规律和趋势（必然性0也是一致的：本质决定规律和趋势（必然性），规律和趋势（必然性）反映本质。就是说，一个事物的本质是怎么样的，其发展的进程（规律）和结局（趋势或必然性）就是怎么样的。</li>
</ol>
<p>如最上图，系统之现象当如<br>： <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E7%BB%93%E6%9E%848.png" alt="现象" title="">
                </div>
                <div class="image-caption">现象</div>
            </figure>，，吾以为现象当为系统呈现出的外部状态。</p>
<p>系统之本质当如： <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/smilelight/images/raw/master/%E7%BB%93%E6%9E%849.png" alt="本质" title="">
                </div>
                <div class="image-caption">本质</div>
            </figure>。</p>
<p>如此，圆圈和线条就构成了事物结构之四个基本环节。<br>即：</p>
<ol>
<li>圆圈（外）与圆圈（内）构成<code>系统</code>与<code>要素</code>。</li>
<li>圆圈（外）与线条（内）构成<code>现象</code>与<code>本质</code>。</li>
<li>线条（内）与线条（外）构成<code>结构</code>与<code>功能</code>。</li>
<li>线条（内）与圆圈（内）构成<code>形式</code>与<code>内容</code>。</li>
</ol>
<p>从以上可知，圆圈内与线条外不构成直接联系。</p>
<h1 id="联系的基本形式"><a href="#联系的基本形式" class="headerlink" title="联系的基本形式"></a>联系的基本形式</h1><ol>
<li>联系的环节是要解决联系的主题承担者问题。显然，没有联系的环节，联系是无法想象的，是不可能存在的。但现实事物中的联系，不仅需要作为联系者的联系环节，也需要联系的形式。联系的形式就是要解决事物时怎样联系的问题。</li>
<li>联系的具体形式无限多样，但其基本形式是有限的。联系的基本形式，依其复杂程度可分为两类：相对简单的联系形式和相对复杂的联系形式。</li>
<li>相对简单的联系形式——内部联系和外部联系、纵向联系和横向联系、直接联系和间接联系。</li>
<li>相对复杂的联系形式——必然联系和偶然联系、因果联系和非因果联系。</li>
<li>所谓必然联系，就是事物在发展过程中所表现出的确定不移的趋势，它是事物内在的直接的本质的稳定的联系。必然联系的首要特征是确定性或稳定性，因为必然联系或必然性根源于事物的根本矛盾。也正因为如此，必然联系在事物存在的全局或发展的全程中居于支配地位。</li>
<li>所谓偶然联系，就是事物在发展过程中所表现出的并非确定不移的趋势（可以出现，也可以不出现；可以早出现，也可以晚出现；可以这样出现，也可以那样出现），它是事物外在的非本质的不稳定的联系。偶然联系的首要特征是不确定性或不稳定性，因为偶然联系或偶然性根源于事物的非根本矛盾或外部矛盾。也正因为如此，偶然联系在事物存在的全局或发展的全程中居于被支配的地位。</li>
<li>偶然联系和必然联系不仅同时存在于一个事物的发展过程之中，而且二者都有其具体形式。偶然联系（偶然现象）的具体形式在事物发展过程的开始、中间和结果三个基本阶段中都可能出现或存在。必然联系的具体形式主要有：有先后的历时性必然联系（因果联系）与无先后的共时性必然联系（函数关系）。</li>
<li>要知道某一事物或现象是原因还是结果，必须把它放在特定关系中才行。</li>
<li>可以把原因定义为能引起（能生）一定事物的事物（实体、状态、性质、过程），而结果可以定义为被一定事物引起（所生）的事物（实体、状态、性质、过程）。</li>
<li>因果联系有两个基本特征：（1）先后性（2）必然性。</li>
<li>因果联系是有先后性的必然联系。</li>
<li>世界万物是处于普遍联系之中的，没有孤立存在的事物。但普遍联系的事物之联系的环节和形式是多样性的，联系的类型也是多样的。联系的基本类型主要有：局部联系与全局联系，暂时联系与长久联系，简单联系与复杂联系，紧密联系与松散联系，客观联系与主观联系，主要联系（本质的联系）与次要联系（非本质的联系），等等。</li>
</ol>

        

        
            <div class="full-width auto-padding tags">
                
                    <a href="/tags/哲学/"><i class="fas fa-hashtag fa-fw"></i>哲学</a>
                
            </div>
        
    </section>
</article>

        </div>
      
    
</section>


    <br>
    <div class="prev-next">
        <div class="prev-next">
            
            <p class="current">
                1 / 2
            </p>
            
                <a class="next" rel="next" href="/archives/2018/03/page/2/">
                    <section class="post next">
                        &nbsp;下一页&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i>
                    </section>
                </a>
            

        </div>
    </div>



<!-- 根据主题中的设置决定是否在archive中针对摘要部分的MathJax公式加载mathjax.js文件 -->






        </div>
        <aside class='l_side'>
            
  
  
    
      
      
        <section class='author'>
  <div class='content pure'>
    
      <div class='avatar'>
        <img class='avatar' src='https://github.com/smilelight/images/raw/master/new_icon.jpg'/>
      </div>
    
    
      <div class='text'>
        
        
        
          <p><span id="jinrishici-sentence">lightsmile's Blog</span></p>
          <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
        
      </div>
    
    
      <div class="social-wrapper">
        
          
            <a href="mailto:iamlightsmile@qq.com" class="social flat-btn" target="_blank" rel="external"><i class="social fas fa-envelope" aria-hidden="true"></i></a>
          
        
          
            <a href="https://github.com/smilelight" class="social flat-btn" target="_blank" rel="external"><i class="social fab fa-github" aria-hidden="true"></i></a>
          
        
          
            <a href="https://music.163.com/m/user/home?id=515917285" class="social flat-btn" target="_blank" rel="external"><i class="social fas fa-music" aria-hidden="true"></i></a>
          
        
          
            <a href="https://www.zhihu.com/people/qian-xiao-80" class="social flat-btn" target="_blank" rel="external"><i class="social fab fa-zhihu" aria-hidden="true"></i></a>
          
        
      </div>
    
  </div>
</section>

      
    
  
    
      
      
        <section class='plain'>
  
<header class='pure'>
  <div><i class="fas fa-bullhorn fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;注意啦～</div>
  
    <a class="rightBtn" target="_blank"
    rel="external nofollow noopener noreferrer"
    href="https://xaoxuu.com/wiki/material-x/"
    title="https://xaoxuu.com/wiki/material-x/">
    <i class="fas fa-question-circle fa-fw"></i></a>
  
</header>

  <div class='content pure'>
    <p>本站使用 <a href="https://xaoxuu.com/wiki/material-x/">Material X</a> 作为主题，喜欢这个主题的朋友可以阅读文档进行安装哦，超喜欢的话还可以安利给身边的朋友哦～</p>

  </div>
</section>

      
    
  
    
      
      
        

      
    
  
    
      
      
        
  <section class='category'>
    
<header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;所有分类</div>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/Python/" href="/categories/Python/"><div class='name'>Python</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/lua/" href="/categories/lua/"><div class='name'>lua</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/哲学/" href="/categories/哲学/"><div class='name'>哲学</div><div class='badge'>(6)</div></a></li>
        
          <li><a class="flat-box" title="/categories/数学/" href="/categories/数学/"><div class='name'>数学</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/自然语言处理/" href="/categories/自然语言处理/"><div class='name'>自然语言处理</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/计算机/" href="/categories/计算机/"><div class='name'>计算机</div><div class='badge'>(2)</div></a></li>
        
      </ul>
    </div>
  </section>


      
    
  
    
      
      
        
  <section class='tagcloud'>
    
<header class='pure'>
  <div><i class="fas fa-fire fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;热门标签</div>
  
</header>

    <div class='content pure'>
      <a href="/tags/GitHub/" style="font-size: 14px; color: #999">GitHub</a> <a href="/tags/NLTK/" style="font-size: 14px; color: #999">NLTK</a> <a href="/tags/Python/" style="font-size: 20.67px; color: #6c6c6c">Python</a> <a href="/tags/Scrapy/" style="font-size: 14px; color: #999">Scrapy</a> <a href="/tags/github/" style="font-size: 14px; color: #999">github</a> <a href="/tags/ltp/" style="font-size: 14px; color: #999">ltp</a> <a href="/tags/lua/" style="font-size: 14px; color: #999">lua</a> <a href="/tags/markdown/" style="font-size: 14px; color: #999">markdown</a> <a href="/tags/哲学/" style="font-size: 24px; color: #555">哲学</a> <a href="/tags/图片绝对地址/" style="font-size: 14px; color: #999">图片绝对地址</a> <a href="/tags/微信小程序/" style="font-size: 14px; color: #999">微信小程序</a> <a href="/tags/抽象/" style="font-size: 14px; color: #999">抽象</a> <a href="/tags/数学/" style="font-size: 14px; color: #999">数学</a> <a href="/tags/概念/" style="font-size: 14px; color: #999">概念</a> <a href="/tags/浏览器插件/" style="font-size: 17.33px; color: #828282">浏览器插件</a> <a href="/tags/爬虫/" style="font-size: 14px; color: #999">爬虫</a> <a href="/tags/算法/" style="font-size: 17.33px; color: #828282">算法</a> <a href="/tags/统计学/" style="font-size: 14px; color: #999">统计学</a> <a href="/tags/自然语言处理/" style="font-size: 20.67px; color: #6c6c6c">自然语言处理</a>
    </div>
  </section>


      
    
  
    
      
      
        <section class='list'>
  
<header class='pure'>
  <div><i class="fas fa-medal fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;我的项目</div>
  
    <a class="rightBtn" target="_blank"
    rel="external nofollow noopener noreferrer"
    href="https://github.com/smilelight?tab=repositories"
    title="https://github.com/smilelight?tab=repositories">
    <i class="fas fa-arrow-right fa-fw"></i></a>
  
</header>

  <div class='content pure'>
    <ul class="entry">
      
        <li><a class="flat-box" title="https://github.com/smilelight/todolist/" href="https://github.com/smilelight/todolist/">
          <div class='name'>
            
              <i class="fas fa-cube fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;微计划日程管理
          </div>
          
            <div class='badge'>(微信小程序)</div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://github.com/smilelight/GithubImagePace/" href="https://github.com/smilelight/GithubImagePace/">
          <div class='name'>
            
              <i class="fas fa-cube fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;chrome插件
          </div>
          
            <div class='badge'>(chromium)</div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://github.com/smilelight/SchoolInfoPublishSystem/" href="https://github.com/smilelight/SchoolInfoPublishSystem/">
          <div class='name'>
            
              <i class="fas fa-heartbeat fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;校园信息发布系统
          </div>
          
            <div class='badge'>(Android)</div>
          
        </a></li>
      
        <li><a class="flat-box" title="https://github.com/smilelight/MyShoppingWeb/" href="https://github.com/smilelight/MyShoppingWeb/">
          <div class='name'>
            
              <i class="fas fa-cube fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;网上购物系统
          </div>
          
            <div class='badge'>(aardio)</div>
          
        </a></li>
      
    </ul>
  </div>
</section>

      
    
  
    
      
      
        <section class='list'>
  
<header class='pure'>
  <div><i class="fas fa-link fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;特别链接</div>
  
</header>

  <div class='content pure'>
    <ul class="entry">
      
        <li><a class="flat-box" title="https://www.iamlightsmile.com/about/" href="https://www.iamlightsmile.com/about/">
          <div class='name'>
            
              <i class="fas fa-comment-dots fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;关于我 / 留言板
          </div>
          
        </a></li>
      
    </ul>
  </div>
</section>

      
    
  
    
      
      
        



      
    
  


        </aside>
        <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
    </div>
    <footer id="footer" class="clearfix">
  
    <div class="social-wrapper">
      
        
          <a href="mailto:iamlightsmile@qq.com" class="social fas fa-envelope flat-btn" target="_blank" rel="external"></a>
        
      
        
          <a href="https://github.com/smilelight" class="social fab fa-github flat-btn" target="_blank" rel="external"></a>
        
      
        
          <a href="https://music.163.com/m/user/home?id=515917285" class="social fas fa-music flat-btn" target="_blank" rel="external"></a>
        
      
        
          <a href="https://www.zhihu.com/people/qian-xiao-80" class="social fab fa-zhihu flat-btn" target="_blank" rel="external"></a>
        
      
    </div>
  
  <br>
  <div><p>博客内容遵循 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
  <div>本站使用 <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material X</a> 作为主题，总访问量为 <span id="busuanzi_value_site_pv"><i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span> 次。
  </div>
</footer>

    <script>setLoadingBarProgress(80);</script>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js"></script>

  <script>
    var GOOGLE_CUSTOM_SEARCH_API_KEY = "";
    var GOOGLE_CUSTOM_SEARCH_ENGINE_ID = "";
    var ALGOLIA_API_KEY = "";
    var ALGOLIA_APP_ID = "";
    var ALGOLIA_INDEX_NAME = "";
    var AZURE_SERVICE_NAME = "";
    var AZURE_INDEX_NAME = "";
    var AZURE_QUERY_KEY = "";
    var BAIDU_API_ID = "";
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/"||"/";
    if(!ROOT.endsWith('/'))ROOT += '/';
  </script>


  
    <script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
    <script type="text/javascript">
      $(function() {
        const $reveal = $('.reveal');
    		if ($reveal.length === 0) return;
    		const sr = ScrollReveal({ distance: 0 });
    		sr.reveal('.reveal');
      });
    </script>
  
  
    <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
    <script type="text/javascript">
      $(function() {
        Waves.attach('.flat-btn', ['waves-button']);
        Waves.attach('.float-btn', ['waves-button', 'waves-float']);
        Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
        Waves.attach('.flat-box', ['waves-block']);
        Waves.attach('.float-box', ['waves-block', 'waves-float']);
        Waves.attach('.waves-image');
        Waves.init();
      });
    </script>
  
  
    <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>
  
  
  


  
  
  
  
    
    <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@1.0/js/app.js"></script>
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@1.0/js/search.js"></script>
    
  






    <script>setLoadingBarProgress(100);</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
